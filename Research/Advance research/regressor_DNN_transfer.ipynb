{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_coordinates = {\n",
    "    \"1-1\": (0, 0), \"1-2\": (0.6, 0), \"1-3\": (1.2, 0), \"1-4\": (1.8, 0), \"1-5\": (2.4, 0), \"1-6\": (3.0, 0),\"1-7\": (3.6, 0), \"1-8\": (4.2, 0), \"1-9\": (4.8, 0), \"1-10\": (5.4, 0), \"1-11\": (6.0, 0),\n",
    "    \"2-1\": (0, 0.6), \"2-11\": (6.0, 0.6),\n",
    "    \"3-1\": (0, 1.2), \"3-11\": (6.0, 1.2),\n",
    "    \"4-1\": (0, 1.8), \"4-11\": (6.0, 1.8),\n",
    "    \"5-1\": (0, 2.4), \"5-11\": (6.0, 2.4),\n",
    "    \"6-1\": (0, 3.0), \"6-2\": (0.6, 3.0), \"6-3\": (1.2, 3.0), \"6-4\": (1.8, 3.0), \"6-5\": (2.4, 3.0),\"6-6\": (3.0, 3.0), \"6-7\": (3.6, 3.0), \"6-8\": (4.2, 3.0), \"6-9\": (4.8, 3.0), \"6-10\": (5.4, 3.0), \"6-11\": (6.0, 3.0),\n",
    "    \"7-1\": (0, 3.6), \"7-11\": (6.0, 3.6),\n",
    "    \"8-1\": (0, 4.2), \"8-11\": (6.0, 4.2),\n",
    "    \"9-1\": (0, 4.8), \"9-11\": (6.0, 4.8),\n",
    "    \"10-1\": (0, 5.4), \"10-11\": (6.0, 5.4),\n",
    "    \"11-1\": (0, 6.0), \"11-2\": (0.6, 6.0), \"11-3\": (1.2, 6.0), \"11-4\": (1.8, 6.0), \"11-5\": (2.4, 6.0),\"11-6\": (3.0, 6.0), \"11-7\": (3.6, 6.0), \"11-8\": (4.2, 6.0), \"11-9\": (4.8, 6.0), \"11-10\": (5.4, 6.0), \"11-11\": (6.0, 6.0)\n",
    "}\n",
    "label_mapping = {\n",
    "    '11': '1-1','10': '1-2','9': '1-3','8': '1-4','7': '1-5','6': '1-6','5': '1-7','4': '1-8','3': '1-9','2': '1-10','1': '1-11',\n",
    "    '12': '2-1','30': '2-11',\n",
    "    '13': '3-1','29': '3-11',\n",
    "    '14': '4-1','28': '4-11',\n",
    "    '15': '5-1','27': '5-11',\n",
    "    '16': '6-1','17': '6-2','18': '6-3','19': '6-4','20': '6-5','21': '6-6','22': '6-7','23': '6-8','24': '6-9','25': '6-10','26': '6-11',\n",
    "    '49': '7-1','31': '7-11',\n",
    "    '48': '8-1','32': '8-11',\n",
    "    '47': '9-1','33': '9-11',\n",
    "    '46': '10-1','34': '10-11',\n",
    "    '45': '11-1','44': '11-2','43': '11-3','42': '11-4','41': '11-5','40': '11-6','39': '11-7','38': '11-8','37': '11-9','36': '11-10','35': '11-11'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import joblib  # 用於保存模型\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Label',\n",
    "                        'AP1_Distance (mm)','AP4_Distance (mm)',\n",
    "                        'AP1_StdDev (mm)','AP4_StdDev (mm)',\n",
    "                        'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi']  \n",
    "\n",
    "X_testing_selected_columns = [\n",
    "                        'AP1_Distance (mm)','AP4_Distance (mm)',\n",
    "                        'AP1_StdDev (mm)','AP4_StdDev (mm)',\n",
    "                        'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi']  \n",
    "\n",
    "label_column = 'Label'\n",
    "target_column = 'Label'\n",
    "\n",
    "\n",
    "#  'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi'\n",
    "# 'AP1_Distance (mm)','AP2_Distance (mm)','AP3_Distance (mm)','AP4_Distance (mm)',\n",
    "# 'AP1_StdDev (mm)','AP2_StdDev (mm)','AP3_StdDev (mm)','AP4_StdDev (mm)',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = 'AP1&AP4'\n",
    "root = 'AP1 AP4 best (MDE_0.0093Accuracy_0.9919 )'\n",
    "\n",
    "dataamount = 20\n",
    "N_val = 4\n",
    "\n",
    "N_train = dataamount # 訓練集每個類別至少要有 N_train 筆資料\n",
    "test_val_ratio = 1  # 剩餘資料中，50% 作為驗證集，50% 作為測試集\n",
    "\n",
    "weekrepresent = [['0','0'],['0','1'],['1','2'],['2','3'],['3','4'],['4','5']]\n",
    "alldatadate = ['2024_12_21','2024_12_27','2025_01_03','2025_01_10','2025_02_28']\n",
    "number_of_week = len(alldatadate)\n",
    "\n",
    "ALL_trainingtime = []\n",
    "ALL_loss = []\n",
    "ALL_accuracy = []\n",
    "ALL_mean_mde = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,185</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)             │         \u001b[38;5;34m3,185\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,467</span> (79.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,467\u001b[0m (79.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,185</span> (12.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,185\u001b[0m (12.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,280</span> (67.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,280\u001b[0m (67.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AP1_Distance (mm)  AP4_Distance (mm)  AP1_Rssi  AP2_Rssi  AP3_Rssi  \\\n",
      "0             4077.0            13164.0     -63.0     -74.0     -52.0   \n",
      "1             4038.0            12876.0     -63.0     -75.0     -47.0   \n",
      "2             3849.0            13608.0     -55.0     -75.0     -51.0   \n",
      "3             4228.0            13135.0     -58.0     -75.0     -51.0   \n",
      "4             4155.0            12871.0     -63.0     -74.0     -46.0   \n",
      "\n",
      "   AP4_Rssi  AP1_StdDev (mm)  AP4_StdDev (mm)  \n",
      "0     -68.0           1153.0           1116.0  \n",
      "1     -64.0           1374.0           1219.0  \n",
      "2     -65.0           1423.0           1023.0  \n",
      "3     -69.0           1426.0           1619.0  \n",
      "4     -67.0            967.0           1081.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>444.0</td>\n",
       "      <td>7366.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>444.0</td>\n",
       "      <td>7444.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>327.0</td>\n",
       "      <td>7353.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>483.0</td>\n",
       "      <td>6987.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>483.0</td>\n",
       "      <td>7353.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16769</th>\n",
       "      <td>6313.0</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16647</th>\n",
       "      <td>5903.0</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16719</th>\n",
       "      <td>6343.0</td>\n",
       "      <td>7822.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16567</th>\n",
       "      <td>6313.0</td>\n",
       "      <td>7588.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16838</th>\n",
       "      <td>6050.0</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AP1_Distance (mm)  AP4_Distance (mm)  AP1_Rssi  AP2_Rssi  AP3_Rssi  \\\n",
       "1038               444.0             7366.0     -60.0     -71.0     -64.0   \n",
       "1020               444.0             7444.0     -59.0     -71.0     -62.0   \n",
       "1125               327.0             7353.0     -59.0     -71.0     -63.0   \n",
       "1102               483.0             6987.0     -59.0     -71.0     -62.0   \n",
       "826                483.0             7353.0     -60.0     -71.0     -56.0   \n",
       "...                  ...                ...       ...       ...       ...   \n",
       "16769             6313.0             7666.0     -71.0     -74.0     -60.0   \n",
       "16647             5903.0             7666.0     -70.0     -76.0     -58.0   \n",
       "16719             6343.0             7822.0     -71.0     -75.0     -59.0   \n",
       "16567             6313.0             7588.0     -72.0     -74.0     -61.0   \n",
       "16838             6050.0             7744.0     -73.0     -73.0     -59.0   \n",
       "\n",
       "       AP4_Rssi  AP1_StdDev (mm)  AP4_StdDev (mm)  label  \n",
       "1038      -52.0            791.0            381.0      0  \n",
       "1020      -49.0            905.0            295.0      0  \n",
       "1125      -50.0            757.0            792.0      0  \n",
       "1102      -50.0            743.0           1011.0      0  \n",
       "826       -54.0            729.0            410.0      0  \n",
       "...         ...              ...              ...    ...  \n",
       "16769     -61.0            946.0            756.0     48  \n",
       "16647     -60.0           1071.0            731.0     48  \n",
       "16719     -60.0            892.0            707.0     48  \n",
       "16567     -61.0            929.0            751.0     48  \n",
       "16838     -60.0           1116.0            657.0     48  \n",
       "\n",
       "[980 rows x 9 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入 regressor\n",
    "base_model_reg = joblib.load(f'{root}/regressor_model_{ap}_best_{weekrepresent[0][0]}week_to_{weekrepresent[0][1]}week_{dataamount}dataPerRP.pkl')\n",
    "# 載入 regressor dnn\n",
    "base_model_dnn = load_model(f'{root}/regressor_dnn_{ap}_best_{weekrepresent[0][0]}week_to_{weekrepresent[0][1]}week_{dataamount}dataPerRP.h5')\n",
    "# 載入 scaler\n",
    "scaler = joblib.load(f'{root}/scaler_regressor_dnn_{ap}_best_0.pkl')\n",
    "\n",
    "# 讀取測試資料 2024_12_21   2024_12_27   2025_01_03   2025_01_10   2025_02_28\n",
    "test_file_path = f\"timestamp_allignment_Balanced_{alldatadate[0]}_rtt_logs.csv\"  # 測試資料的檔案名稱\n",
    "date_test = f\"{alldatadate[0]}\"\n",
    "modelname = f\"regressor_DNN {ap}s BEST_{dataamount}data_{alldatadate[0]}\"\n",
    "data = pd.read_csv(test_file_path, usecols=selected_columns)\n",
    "\n",
    "# DNN transfer learnging 凍結所有層\n",
    "for layer in base_model_dnn.layers[:-1]:  # 除了最後一層 (Output Layer)\n",
    "    layer.trainable = False\n",
    "\n",
    "# 確認哪些層可訓練\n",
    "base_model_dnn.summary()\n",
    "\n",
    "base_model_dnn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "data_imputed = data.groupby(label_column).apply(\n",
    "    lambda group: group.fillna(group.mean())\n",
    ").reset_index()\n",
    "\n",
    "data_imputed\n",
    "\n",
    "\n",
    "reverse_label_mapping = {v: int(k) - 1 for k, v in label_mapping.items()}  # 讓數字標籤 -1\n",
    "\n",
    "y = data_imputed[target_column]\n",
    "\n",
    "y_numeric = y.map(reverse_label_mapping)\n",
    "y_numeric\n",
    "\n",
    "# 把label部分拿掉\n",
    "X = data_imputed.drop(columns=['level_1','Label'])\n",
    "print(X.head())\n",
    "\n",
    "# 轉為 DataFrame 方便操作\n",
    "data = pd.DataFrame(X)\n",
    "data['label'] = y_numeric  # 加入 label 欄位\n",
    "\n",
    "train_data_full = data.groupby('label', group_keys=False).sample(n=N_train, replace=False, random_state=42)\n",
    "train_data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>1948.000000</td>\n",
       "      <td>8799.0</td>\n",
       "      <td>-61.00000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>1077.000000</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>3335.000000</td>\n",
       "      <td>8657.0</td>\n",
       "      <td>-58.00000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>2299.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>4687.371025</td>\n",
       "      <td>8174.0</td>\n",
       "      <td>-60.95053</td>\n",
       "      <td>-70.165493</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>828.964664</td>\n",
       "      <td>764.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>219.000000</td>\n",
       "      <td>8330.0</td>\n",
       "      <td>-60.00000</td>\n",
       "      <td>-69.000000</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>2632.000000</td>\n",
       "      <td>2412.0</td>\n",
       "      <td>-61.00000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>477.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>444.000000</td>\n",
       "      <td>7275.0</td>\n",
       "      <td>-59.00000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15964</th>\n",
       "      <td>-219.000000</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>-61.00000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>1772.000000</td>\n",
       "      <td>8877.0</td>\n",
       "      <td>-61.00000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>1146.000000</td>\n",
       "      <td>994.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>3452.000000</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>-53.00000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>418.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16955</th>\n",
       "      <td>561.000000</td>\n",
       "      <td>3877.0</td>\n",
       "      <td>-54.00000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>481.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AP1_Distance (mm)  AP4_Distance (mm)  AP1_Rssi   AP2_Rssi  AP3_Rssi  \\\n",
       "2880         1948.000000             8799.0 -61.00000 -81.000000     -53.0   \n",
       "1239         3335.000000             8657.0 -58.00000 -70.000000     -49.0   \n",
       "11584        4687.371025             8174.0 -60.95053 -70.165493     -50.0   \n",
       "3591          219.000000             8330.0 -60.00000 -69.000000     -54.0   \n",
       "4638         2632.000000             2412.0 -61.00000 -71.000000     -54.0   \n",
       "...                  ...                ...       ...        ...       ...   \n",
       "1143          444.000000             7275.0 -59.00000 -71.000000     -67.0   \n",
       "15964        -219.000000             6133.0 -61.00000 -71.000000     -60.0   \n",
       "2829         1772.000000             8877.0 -61.00000 -81.000000     -53.0   \n",
       "5682         3452.000000             1914.0 -53.00000 -66.000000     -64.0   \n",
       "16955         561.000000             3877.0 -54.00000 -71.000000     -66.0   \n",
       "\n",
       "       AP4_Rssi  AP1_StdDev (mm)  AP4_StdDev (mm)  label  \n",
       "2880      -64.0      1077.000000           1076.0      5  \n",
       "1239      -60.0       394.000000           2299.0      9  \n",
       "11584     -57.0       828.964664            764.0     14  \n",
       "3591      -60.0       319.000000           1016.0      3  \n",
       "4638      -55.0       353.000000            477.0     33  \n",
       "...         ...              ...              ...    ...  \n",
       "1143      -51.0       724.000000           1564.0      0  \n",
       "15964     -58.0      1163.000000           2383.0     22  \n",
       "2829      -64.0      1146.000000            994.0      5  \n",
       "5682      -52.0       331.000000            418.0     35  \n",
       "16955     -48.0       340.000000            481.0     30  \n",
       "\n",
       "[784 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if N_val > 0:\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=N_val / N_train) # , random_state=42\n",
    "    train_index, val_index = next(sss.split(train_data_full.drop(columns=['label']), train_data_full['label']))\n",
    "    train_data = train_data_full.iloc[train_index]\n",
    "    val_data = train_data_full.iloc[val_index]\n",
    "    \n",
    "else:\n",
    "    val_data = pd.DataFrame(columns=data.columns)  # 若沒有 validation data，建立空 DataFrame\\\n",
    "    train_data = train_data_full\n",
    "\n",
    "# 剩下的資料（未被抽入 train_data_full 的部分）直接作為 test set\n",
    "remaining_data = data.drop(train_data_full.index)\n",
    "train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AP1 AP4 best (MDE_0.0093Accuracy_0.9919 )/regressor_model_AP1&AP4_best_0week_to_1week_20dataPerRP.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練 regressor 並儲存\n",
    "ap1_data = train_data[['AP1_Rssi', 'AP1_Distance (mm)']].dropna().rename(\n",
    "    columns={'AP1_Rssi': 'Rssi', 'AP1_Distance (mm)': 'Distance'}\n",
    ")\n",
    "ap4_data = train_data[['AP4_Rssi', 'AP4_Distance (mm)']].dropna().rename(\n",
    "    columns={'AP4_Rssi': 'Rssi', 'AP4_Distance (mm)': 'Distance'}\n",
    ")\n",
    "\n",
    "train_data_reg = pd.concat([ap1_data, ap4_data], ignore_index=True)\n",
    "\n",
    "\n",
    "X_train_reg = train_data_reg[['Rssi']]\n",
    "y_train_reg = train_data_reg['Distance']\n",
    "\n",
    "# 重新訓練模型（fine tuning）\n",
    "model_reg_finetuned = base_model_reg\n",
    "model_reg_finetuned.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# 儲存更新後的模型\n",
    "joblib.dump(model_reg_finetuned,f'{root}/regressor_model_{ap}_best_{weekrepresent[1][0]}week_to_{weekrepresent[1][1]}week_{dataamount}dataPerRP.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_1044\\2456486366.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['AP2_Distance_predicted'] = np.nan\n",
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_1044\\2456486366.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['AP3_Distance_predicted'] = np.nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Label',\n",
       " 'AP1_Distance (mm)',\n",
       " 'AP4_Distance (mm)',\n",
       " 'AP1_StdDev (mm)',\n",
       " 'AP4_StdDev (mm)',\n",
       " 'AP1_Rssi',\n",
       " 'AP2_Rssi',\n",
       " 'AP3_Rssi',\n",
       " 'AP4_Rssi',\n",
       " 'AP2_Distance_predicted',\n",
       " 'AP3_Distance_predicted']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### train data\n",
    "train_data['AP2_Distance_predicted'] = np.nan\n",
    "train_data['AP3_Distance_predicted'] = np.nan\n",
    "\n",
    "# 利用 AP2_Rssi 預測 AP2_Distance_predicted\n",
    "mask_ap2 = train_data['AP2_Rssi'].notna()\n",
    "train_data.loc[mask_ap2, 'AP2_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    train_data.loc[mask_ap2, ['AP2_Rssi']].rename(columns={'AP2_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 利用 AP3_Rssi 預測 AP3_Distance_predicted\n",
    "mask_ap3 = train_data['AP3_Rssi'].notna()\n",
    "train_data.loc[mask_ap3, 'AP3_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    train_data.loc[mask_ap3, ['AP3_Rssi']].rename(columns={'AP3_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "### val data\n",
    "val_data['AP2_Distance_predicted'] = np.nan\n",
    "val_data['AP3_Distance_predicted'] = np.nan\n",
    "\n",
    "# 利用 AP2_Rssi 預測 AP2_Distance_predicted\n",
    "mask_ap2 = val_data['AP2_Rssi'].notna()\n",
    "val_data.loc[mask_ap2, 'AP2_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    val_data.loc[mask_ap2, ['AP2_Rssi']].rename(columns={'AP2_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 利用 AP3_Rssi 預測 AP3_Distance_predicted\n",
    "mask_ap3 = val_data['AP3_Rssi'].notna()\n",
    "val_data.loc[mask_ap3, 'AP3_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    val_data.loc[mask_ap3, ['AP3_Rssi']].rename(columns={'AP3_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "### remaining data\n",
    "remaining_data['AP2_Distance_predicted'] = np.nan\n",
    "remaining_data['AP3_Distance_predicted'] = np.nan\n",
    "\n",
    "# 利用 AP2_Rssi 預測 AP2_Distance_predicted\n",
    "mask_ap2 = remaining_data['AP2_Rssi'].notna()\n",
    "remaining_data.loc[mask_ap2, 'AP2_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    remaining_data.loc[mask_ap2, ['AP2_Rssi']].rename(columns={'AP2_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 利用 AP3_Rssi 預測 AP3_Distance_predicted\n",
    "mask_ap3 = remaining_data['AP3_Rssi'].notna()\n",
    "remaining_data.loc[mask_ap3, 'AP3_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    remaining_data.loc[mask_ap3, ['AP3_Rssi']].rename(columns={'AP3_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 更新 DNN 模型用的特徵欄位，將 regressor 預測值加入\n",
    "selected_columns_dnn = selected_columns + ['AP2_Distance_predicted', 'AP3_Distance_predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1948.        , 8799.        ,  -61.        , ...,  -64.        ,\n",
       "        1077.        , 1076.        ],\n",
       "       [3335.        , 8657.        ,  -58.        , ...,  -60.        ,\n",
       "         394.        , 2299.        ],\n",
       "       [4687.37102473, 8174.        ,  -60.95053004, ...,  -57.        ,\n",
       "         828.96466431,  764.        ],\n",
       "       ...,\n",
       "       [1772.        , 8877.        ,  -61.        , ...,  -64.        ,\n",
       "        1146.        ,  994.        ],\n",
       "       [3452.        , 1914.        ,  -53.        , ...,  -52.        ,\n",
       "         331.        ,  418.        ],\n",
       "       [ 561.        , 3877.        ,  -54.        , ...,  -48.        ,\n",
       "         340.        ,  481.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# **轉換為 NumPy 陣列**\n",
    "X_train, y_train = train_data.drop(columns=['label']).values, train_data['label'].values\n",
    "X_val, y_val = val_data.drop(columns=['label']).values, val_data['label'].values\n",
    "X_test, y_test = remaining_data.drop(columns=['label']).values, remaining_data['label'].values\n",
    "\n",
    "\n",
    "# **計算每個 Set 內各 Label 的資料數量**\n",
    "train_label_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "val_label_counts = pd.Series(y_val).value_counts().sort_index()\n",
    "test_label_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "# **確保所有 Labels 都有出現在三個 Set 裡**\n",
    "all_labels = sorted(set(train_label_counts.index) | set(val_label_counts.index) | set(test_label_counts.index))\n",
    "label_distribution = pd.DataFrame(index=all_labels)\n",
    "\n",
    "label_distribution[\"Training Set\"] = train_label_counts\n",
    "label_distribution[\"Validation Set\"] = val_label_counts\n",
    "label_distribution[\"Test Set\"] = test_label_counts\n",
    "\n",
    "# **用 0 填補缺失值（表示該 Label 在該 Set 中沒有數據）**\n",
    "label_distribution = label_distribution.fillna(0).astype(int)\n",
    "\n",
    "# from IPython.display import display\n",
    "# display(label_distribution)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(number_of_week):\n",
    "\n",
    "# 載入 regressor\n",
    "    base_model_reg = joblib.load(f'{root}/regressor_model_{ap}_best_{weekrepresent[i][0]}week_to_{weekrepresent[i][1]}week_{dataamount}dataPerRP.pkl')\n",
    "# 載入 regressor dnn\n",
    "    base_model_dnn = load_model(f'{root}/regressor_dnn_{ap}_best_{weekrepresent[i][0]}week_to_{weekrepresent[i][1]}week_{dataamount}dataPerRP.h5')\n",
    "# 載入 scaler\n",
    "    scaler = joblib.load(f'{root}/scaler_regressor_dnn_{ap}_best_0.pkl')\n",
    "\n",
    "# 讀取測試資料 2024_12_21   2024_12_27   2025_01_03   2025_01_10   2025_02_28\n",
    "    test_file_path = f\"timestamp_allignment_Balanced_{alldatadate[i]}_rtt_logs.csv\"  # 測試資料的檔案名稱\n",
    "    date_test = f\"{alldatadate[i]}\"\n",
    "    modelname = f\"regressor_DNN {ap}s BEST_{dataamount}data_{alldatadate[i]}\"\n",
    "    data = pd.read_csv(test_file_path, usecols=selected_columns)\n",
    "\n",
    "# DNN transfer learnging 凍結所有層\n",
    "    for layer in base_model_dnn.layers[:-1]:  # 除了最後一層 (Output Layer)\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 確認哪些層可訓練\n",
    "    base_model_dnn.summary()\n",
    "\n",
    "    base_model_dnn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    processed_data = data.copy()\n",
    "\n",
    "    # 資料填補：以每個 Label 群組內的平均值填補缺失值\n",
    "    data_imputed = processed_data.groupby(label_column).apply(\n",
    "        lambda group: group.fillna(group.mean())\n",
    "    ).reset_index()\n",
    "    data_imputed\n",
    "    \n",
    "\n",
    "    reverse_label_mapping = {v: int(k) - 1 for k, v in label_mapping.items()}  # 讓數字標籤 -1\n",
    "\n",
    "    y = data_imputed[target_column]\n",
    "\n",
    "    y_numeric = y.map(reverse_label_mapping)\n",
    "    y_numeric\n",
    "\n",
    "    # 把label部分拿掉\n",
    "    X = data_imputed.drop(columns=['level_1','Label'])\n",
    "    print(X.head())\n",
    "\n",
    "    # 轉為 DataFrame 方便操作\n",
    "    data = pd.DataFrame(X)\n",
    "    data['label'] = y_numeric  # 加入 label 欄位\n",
    "\n",
    "    train_data_full = data.groupby('label', group_keys=False).sample(n=N_train, replace=False, random_state=42)\n",
    "    train_data_full\n",
    "\n",
    "    if N_val > 0:\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=N_val / N_train) # , random_state=42\n",
    "        train_index, val_index = next(sss.split(train_data_full.drop(columns=['label']), train_data_full['label']))\n",
    "        train_data = train_data_full.iloc[train_index]\n",
    "        val_data = train_data_full.iloc[val_index]\n",
    "        \n",
    "    else:\n",
    "        val_data = pd.DataFrame(columns=data.columns)  # 若沒有 validation data，建立空 DataFrame\\\n",
    "        train_data = train_data_full\n",
    "\n",
    "    remaining_data = data.drop(train_data_full.index)\n",
    "\n",
    "    \n",
    "    # **轉換為 NumPy 陣列**\n",
    "    X_train, y_train = train_data.drop(columns=['label']).values, train_data['label'].values\n",
    "    X_val, y_val = val_data.drop(columns=['label']).values, val_data['label'].values\n",
    "    X_test, y_test = remaining_data.drop(columns=['label']).values, remaining_data['label'].values\n",
    "\n",
    "\n",
    "   # **計算每個 Set 內各 Label 的資料數量**\n",
    "    train_label_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "    val_label_counts = pd.Series(y_val).value_counts().sort_index()\n",
    "    test_label_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "    # **確保所有 Labels 都有出現在三個 Set 裡**\n",
    "    all_labels = sorted(set(train_label_counts.index) | set(val_label_counts.index) | set(test_label_counts.index))\n",
    "    label_distribution = pd.DataFrame(index=all_labels)\n",
    "\n",
    "    label_distribution[\"Training Set\"] = train_label_counts\n",
    "    label_distribution[\"Validation Set\"] = val_label_counts\n",
    "    label_distribution[\"Test Set\"] = test_label_counts\n",
    "\n",
    "    # **用 0 填補缺失值（表示該 Label 在該 Set 中沒有數據）**\n",
    "    label_distribution = label_distribution.fillna(0).astype(int)\n",
    "\n",
    "    from IPython.display import display\n",
    "    display(label_distribution)\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "# 訓練 regressor 並儲存\n",
    "    ap1_data = X_train[['AP1_Rssi', 'AP1_Distance (mm)']].dropna().rename(\n",
    "        columns={'AP1_Rssi': 'Rssi', 'AP1_Distance (mm)': 'Distance'}\n",
    "    )\n",
    "    ap4_data = X_train[['AP4_Rssi', 'AP4_Distance (mm)']].dropna().rename(\n",
    "        columns={'AP4_Rssi': 'Rssi', 'AP4_Distance (mm)': 'Distance'}\n",
    "    )\n",
    "    \n",
    "    train_data_reg = pd.concat([ap1_data, ap4_data], ignore_index=True)\n",
    "\n",
    "    \n",
    "    X_train_reg = train_data_reg[['Rssi']]\n",
    "    y_train_reg = train_data_reg['Distance']\n",
    "\n",
    "    # 重新訓練模型（fine tuning）\n",
    "    model_reg_finetuned = base_model_reg\n",
    "    model_reg_finetuned.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "    # 儲存更新後的模型\n",
    "    model_reg_finetuned = joblib.dump(f'{root}/regressor_model_{ap}_best_{weekrepresent[i+1][0]}week_to_{weekrepresent[i+1][1]}week_{dataamount}dataPerRP.pkl')\n",
    "\n",
    "\n",
    "\n",
    "# 使用之前訓練時的標準化器 (scaler) 來標準化測試數據\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    import time\n",
    "    # 記錄開始時間\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "    if N_val > 0:\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    else:\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    # 確保變數命名一致\n",
    "    X_train_small = X_train  # 確保這裡用的變數和前面一致\n",
    "    y_train_small = y_train\n",
    "\n",
    "    # 設定 batch_size\n",
    "    batch_size = min(32, max(8, len(X_train_small) // 2))  # 避免 batch size 過大\n",
    "    # batch_size = 32\n",
    "    print(batch_size)\n",
    "\n",
    "    if N_val > 0:\n",
    "        base_model.fit(X_train_small, y_train_small,validation_data=(X_val, y_val), epochs=10000, batch_size=batch_size, callbacks=[early_stop])\n",
    "    else:\n",
    "        base_model.fit(X_train_small, y_train_small, epochs=10000, batch_size=batch_size, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "    # 記錄結束時間\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    # Needsave\n",
    "    # 計算訓練時間（秒）\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"訓練時間：{training_time:.2f} 秒\")\n",
    "    ALL_trainingtime.append(training_time)\n",
    "\n",
    "    # Needsave\n",
    "    loss, accuracy = base_model.evaluate(X_test, y_test)\n",
    "    print(f\"Evaluation on 90% unused data - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    ALL_loss.append(loss)\n",
    "    ALL_accuracy.append(accuracy)\n",
    "\n",
    "    # 預測測試資料\n",
    "    y_test_pred_numeric = base_model.predict(X_test_scaled)\n",
    "    y_pred_classes = np.argmax(y_test_pred_numeric, axis=1)\n",
    "\n",
    "    # 轉換為原本的 Label\n",
    "    y_test_pred_labels = [label_mapping[str(num + 1)] for num in y_pred_classes]  # 補回 +1\n",
    "    y_test_pred_labels\n",
    "\n",
    "    # 讀取測試資料的實際 Label\n",
    "    y_test_actual = test_data_imputed[target_column]\n",
    "    test_data_imputed\n",
    "\n",
    "    # 取得預測與實際座標\n",
    "    y_test_pred_coordinates = np.array([label_to_coordinates[label] for label in y_test_pred_labels])\n",
    "    y_test_actual_coordinates = np.array([label_to_coordinates[label] for label in y_test_actual])\n",
    "\n",
    "    # 計算 MDE (Mean Distance Error)\n",
    "    distances = np.linalg.norm(y_test_pred_coordinates - y_test_actual_coordinates, axis=1)\n",
    "    mean_mde = np.mean(distances)\n",
    "\n",
    "    # 記錄每個 RP 的 MDE\n",
    "    mde_report_test = {}\n",
    "    for true_label, distance in zip(y_test_actual, distances):\n",
    "        if true_label not in mde_report_test:\n",
    "            mde_report_test[true_label] = []\n",
    "        mde_report_test[true_label].append(distance)\n",
    "\n",
    "    # 計算測試資料的 MDE 平均值\n",
    "    mde_report_test_avg = {label: {\"mde\": np.mean(dists), \"count\": len(dists)} for label, dists in mde_report_test.items()}\n",
    "\n",
    "    # 儲存 MDE 結果到 JSON 檔案\n",
    "    test_file_path = f\"{root}/{modelname}.json\"\n",
    "    with open(test_file_path, \"w\") as f:\n",
    "        json.dump(mde_report_test_avg, f, indent=4)\n",
    "\n",
    "    # Needsave\n",
    "    print(f\"Test Data MDE report saved to: {test_file_path}\")\n",
    "    print(f\"\\nTest Data Mean MDE: {mean_mde:.4f} meters\")\n",
    "    ALL_mean_mde.append(mean_mde)\n",
    "\n",
    "\n",
    "    base_model.save(f'{root}/DNN_best_model{ap}_{weekrepresent[i+1][0]}week_to_{weekrepresent[i+1][1]}week_{dataamount}dataPerRP.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
