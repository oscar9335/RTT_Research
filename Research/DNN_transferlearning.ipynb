{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_coordinates = {\n",
    "    \"1-1\": (0, 0), \"1-2\": (0.6, 0), \"1-3\": (1.2, 0), \"1-4\": (1.8, 0), \"1-5\": (2.4, 0), \"1-6\": (3.0, 0),\"1-7\": (3.6, 0), \"1-8\": (4.2, 0), \"1-9\": (4.8, 0), \"1-10\": (5.4, 0), \"1-11\": (6.0, 0),\n",
    "    \"2-1\": (0, 0.6), \"2-11\": (6.0, 0.6),\n",
    "    \"3-1\": (0, 1.2), \"3-11\": (6.0, 1.2),\n",
    "    \"4-1\": (0, 1.8), \"4-11\": (6.0, 1.8),\n",
    "    \"5-1\": (0, 2.4), \"5-11\": (6.0, 2.4),\n",
    "    \"6-1\": (0, 3.0), \"6-2\": (0.6, 3.0), \"6-3\": (1.2, 3.0), \"6-4\": (1.8, 3.0), \"6-5\": (2.4, 3.0),\"6-6\": (3.0, 3.0), \"6-7\": (3.6, 3.0), \"6-8\": (4.2, 3.0), \"6-9\": (4.8, 3.0), \"6-10\": (5.4, 3.0), \"6-11\": (6.0, 3.0),\n",
    "    \"7-1\": (0, 3.6), \"7-11\": (6.0, 3.6),\n",
    "    \"8-1\": (0, 4.2), \"8-11\": (6.0, 4.2),\n",
    "    \"9-1\": (0, 4.8), \"9-11\": (6.0, 4.8),\n",
    "    \"10-1\": (0, 5.4), \"10-11\": (6.0, 5.4),\n",
    "    \"11-1\": (0, 6.0), \"11-2\": (0.6, 6.0), \"11-3\": (1.2, 6.0), \"11-4\": (1.8, 6.0), \"11-5\": (2.4, 6.0),\"11-6\": (3.0, 6.0), \"11-7\": (3.6, 6.0), \"11-8\": (4.2, 6.0), \"11-9\": (4.8, 6.0), \"11-10\": (5.4, 6.0), \"11-11\": (6.0, 6.0)\n",
    "}\n",
    "label_mapping = {\n",
    "    '11': '1-1','10': '1-2','9': '1-3','8': '1-4','7': '1-5','6': '1-6','5': '1-7','4': '1-8','3': '1-9','2': '1-10','1': '1-11',\n",
    "    '12': '2-1','30': '2-11',\n",
    "    '13': '3-1','29': '3-11',\n",
    "    '14': '4-1','28': '4-11',\n",
    "    '15': '5-1','27': '5-11',\n",
    "    '16': '6-1','17': '6-2','18': '6-3','19': '6-4','20': '6-5','21': '6-6','22': '6-7','23': '6-8','24': '6-9','25': '6-10','26': '6-11',\n",
    "    '49': '7-1','31': '7-11',\n",
    "    '48': '8-1','32': '8-11',\n",
    "    '47': '9-1','33': '9-11',\n",
    "    '46': '10-1','34': '10-11',\n",
    "    '45': '11-1','44': '11-2','43': '11-3','42': '11-4','41': '11-5','40': '11-6','39': '11-7','38': '11-8','37': '11-9','36': '11-10','35': '11-11'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib  # 用於保存模型\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "c:\\Users\\吳定洋\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.3.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 載入模型與標準化器\n",
    "# base_model = load_model('Model_SAVE/4 mc AP RSSI FTM StdDev 2024-12-14 data train/DNN_best_model4mcAP.h5')\n",
    "base_model = load_model('DNN_best_model4mcAP_2week_to_3week_5dataPerRP.h5')\n",
    "\n",
    "scaler = joblib.load('Model_SAVE/4 mc AP RSSI FTM StdDev 2024-12-14 data train/scaler_4mcAP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,185</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)             │         \u001b[38;5;34m3,185\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,595</span> (80.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,595\u001b[0m (80.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,185</span> (12.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,185\u001b[0m (12.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> (68.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,408\u001b[0m (68.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 凍結所有層\n",
    "for layer in base_model.layers[:-1]:  # 除了最後一層 (Output Layer)\n",
    "    layer.trainable = False\n",
    "\n",
    "# 確認哪些層可訓練\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入新資料 & 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Label',\n",
    "                    'AP1_Distance (mm)','AP2_Distance (mm)','AP3_Distance (mm)','AP4_Distance (mm)',\n",
    "'AP1_StdDev (mm)','AP2_StdDev (mm)','AP3_StdDev (mm)','AP4_StdDev (mm)',\n",
    "                                'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi']  \n",
    "\n",
    "X_testing_selected_columns = [\n",
    "        'AP1_Distance (mm)','AP2_Distance (mm)','AP3_Distance (mm)','AP4_Distance (mm)',\n",
    "        'AP1_StdDev (mm)','AP2_StdDev (mm)','AP3_StdDev (mm)','AP4_StdDev (mm)',\n",
    "                                'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi']  \n",
    "\n",
    "label_column = 'Label'\n",
    "target_column = 'Label'\n",
    "#  'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi'\n",
    "# 'AP1_Distance (mm)','AP2_Distance (mm)','AP3_Distance (mm)','AP4_Distance (mm)',\n",
    "# 'AP1_StdDev (mm)','AP2_StdDev (mm)','AP3_StdDev (mm)','AP4_StdDev (mm)',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP2_Distance (mm)</th>\n",
       "      <th>AP3_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP2_StdDev (mm)</th>\n",
       "      <th>AP3_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>6987.0</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>-421.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>1588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1</td>\n",
       "      <td>4155.0</td>\n",
       "      <td>8862.0</td>\n",
       "      <td>10518.0</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>1373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>8715.0</td>\n",
       "      <td>10557.0</td>\n",
       "      <td>-333.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-1</td>\n",
       "      <td>3921.0</td>\n",
       "      <td>7163.0</td>\n",
       "      <td>10557.0</td>\n",
       "      <td>-333.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-1</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>8335.0</td>\n",
       "      <td>10479.0</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>9-11</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>8296.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>4969.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>9-11</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>8413.0</td>\n",
       "      <td>2412.0</td>\n",
       "      <td>4422.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>9-11</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>7983.0</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>4969.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20480</th>\n",
       "      <td>9-11</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>8530.0</td>\n",
       "      <td>2432.0</td>\n",
       "      <td>5116.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20481</th>\n",
       "      <td>9-11</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>8335.0</td>\n",
       "      <td>2471.0</td>\n",
       "      <td>4383.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20482 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  AP1_Distance (mm)  AP2_Distance (mm)  AP3_Distance (mm)  \\\n",
       "0       1-1             3999.0             6987.0             9980.0   \n",
       "1       1-1             4155.0             8862.0            10518.0   \n",
       "2       1-1             3960.0             8715.0            10557.0   \n",
       "3       1-1             3921.0             7163.0            10557.0   \n",
       "4       1-1             4116.0             8335.0            10479.0   \n",
       "...     ...                ...                ...                ...   \n",
       "20477  9-11             2124.0             8296.0             2510.0   \n",
       "20478  9-11             2124.0             8413.0             2412.0   \n",
       "20479  9-11             2046.0             7983.0             2627.0   \n",
       "20480  9-11             2202.0             8530.0             2432.0   \n",
       "20481  9-11             2007.0             8335.0             2471.0   \n",
       "\n",
       "       AP4_Distance (mm)  AP1_Rssi  AP2_Rssi  AP3_Rssi  AP4_Rssi  \\\n",
       "0                 -421.0     -61.0     -71.0     -62.0     -43.0   \n",
       "1                 -342.0     -61.0     -71.0     -64.0     -47.0   \n",
       "2                 -333.0     -61.0     -71.0     -64.0     -47.0   \n",
       "3                 -333.0     -61.0     -71.0     -63.0     -47.0   \n",
       "4                 -342.0     -60.0     -70.0     -64.0     -43.0   \n",
       "...                  ...       ...       ...       ...       ...   \n",
       "20477             4969.0     -56.0     -66.0     -51.0     -68.0   \n",
       "20478             4422.0     -56.0     -66.0     -52.0     -68.0   \n",
       "20479             4969.0     -56.0     -66.0     -51.0     -69.0   \n",
       "20480             5116.0     -56.0     -66.0     -52.0     -69.0   \n",
       "20481             4383.0     -55.0     -65.0     -52.0     -69.0   \n",
       "\n",
       "       AP1_StdDev (mm)  AP2_StdDev (mm)  AP3_StdDev (mm)  AP4_StdDev (mm)  \n",
       "0               1148.0           2068.0           1495.0           1588.0  \n",
       "1               1071.0           1731.0            958.0           1373.0  \n",
       "2               1129.0           1465.0           1222.0           1466.0  \n",
       "3               1131.0           2130.0           1101.0           1467.0  \n",
       "4               1135.0           1796.0           1125.0           1288.0  \n",
       "...                ...              ...              ...              ...  \n",
       "20477            164.0            375.0            477.0            774.0  \n",
       "20478             59.0            281.0            560.0            419.0  \n",
       "20479            233.0            485.0            410.0           1048.0  \n",
       "20480             88.0            286.0            610.0            745.0  \n",
       "20481            226.0           1021.0            517.0            381.0  \n",
       "\n",
       "[20482 rows x 13 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取測試資料\n",
    "test_file_path = \"timestamp_allignment_Balanced_2025_01_10_rtt_logs.csv\"  # 測試資料的檔案名稱\n",
    "date_test = \"2025_01_10\"\n",
    "modelname = \"DNN 4 mcAPs BEST\"\n",
    "test_data = pd.read_csv(test_file_path, usecols=selected_columns)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_13772\\195304898.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_processed_data = pd.concat([test_processed_data, group], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values: 1299\n",
      "Number of rows with NaN values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>level_1</th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP2_Distance (mm)</th>\n",
       "      <th>AP3_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP2_StdDev (mm)</th>\n",
       "      <th>AP3_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>7075.00000</td>\n",
       "      <td>12054.000000</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>2406.000000</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>7192.00000</td>\n",
       "      <td>10518.000000</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>2197.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1</td>\n",
       "      <td>2</td>\n",
       "      <td>4116.000000</td>\n",
       "      <td>9155.00000</td>\n",
       "      <td>10440.000000</td>\n",
       "      <td>-303.0</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>1509.000000</td>\n",
       "      <td>1253.000000</td>\n",
       "      <td>1468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>6811.00000</td>\n",
       "      <td>10478.000000</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-65.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1161.000000</td>\n",
       "      <td>2386.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-1</td>\n",
       "      <td>4</td>\n",
       "      <td>4038.000000</td>\n",
       "      <td>6841.00000</td>\n",
       "      <td>10479.000000</td>\n",
       "      <td>-303.0</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>2075.000000</td>\n",
       "      <td>1131.000000</td>\n",
       "      <td>1509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19497</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19497</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>8218.00000</td>\n",
       "      <td>2588.000000</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>488.000000</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19498</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19498</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>8139.00000</td>\n",
       "      <td>2666.000000</td>\n",
       "      <td>4539.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19499</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19499</td>\n",
       "      <td>2085.000000</td>\n",
       "      <td>8335.00000</td>\n",
       "      <td>2588.000000</td>\n",
       "      <td>5057.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>1292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19500</td>\n",
       "      <td>2081.512821</td>\n",
       "      <td>8234.04359</td>\n",
       "      <td>2576.604113</td>\n",
       "      <td>4735.0</td>\n",
       "      <td>-55.335897</td>\n",
       "      <td>-65.969231</td>\n",
       "      <td>-50.969152</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>190.787179</td>\n",
       "      <td>488.812821</td>\n",
       "      <td>476.794344</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19501</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19501</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>8257.00000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>1105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19502 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  level_1  AP1_Distance (mm)  AP2_Distance (mm)  AP3_Distance (mm)  \\\n",
       "0       1-1        0        4385.000000         7075.00000       12054.000000   \n",
       "1       1-1        1        3999.000000         7192.00000       10518.000000   \n",
       "2       1-1        2        4116.000000         9155.00000       10440.000000   \n",
       "3       1-1        3        3999.000000         6811.00000       10478.000000   \n",
       "4       1-1        4        4038.000000         6841.00000       10479.000000   \n",
       "...     ...      ...                ...                ...                ...   \n",
       "19497  9-11    19497        2202.000000         8218.00000        2588.000000   \n",
       "19498  9-11    19498        2202.000000         8139.00000        2666.000000   \n",
       "19499  9-11    19499        2085.000000         8335.00000        2588.000000   \n",
       "19500  9-11    19500        2081.512821         8234.04359        2576.604113   \n",
       "19501  9-11    19501        1968.000000         8257.00000        2549.000000   \n",
       "\n",
       "       AP4_Distance (mm)   AP1_Rssi   AP2_Rssi   AP3_Rssi  AP4_Rssi  \\\n",
       "0                 -342.0 -53.000000 -71.000000 -60.000000     -47.0   \n",
       "1                 -342.0 -61.000000 -71.000000 -64.000000     -47.0   \n",
       "2                 -303.0 -60.000000 -71.000000 -64.000000     -45.0   \n",
       "3                 -342.0 -61.000000 -71.000000 -65.000000     -47.0   \n",
       "4                 -303.0 -61.000000 -71.000000 -64.000000     -47.0   \n",
       "...                  ...        ...        ...        ...       ...   \n",
       "19497             4617.0 -56.000000 -66.000000 -51.000000     -69.0   \n",
       "19498             4539.0 -56.000000 -66.000000 -51.000000     -69.0   \n",
       "19499             5057.0 -56.000000 -66.000000 -51.000000     -68.0   \n",
       "19500             4735.0 -55.335897 -65.969231 -50.969152     -68.0   \n",
       "19501             5145.0 -56.000000 -66.000000 -51.000000     -69.0   \n",
       "\n",
       "       AP1_StdDev (mm)  AP2_StdDev (mm)  AP3_StdDev (mm)  AP4_StdDev (mm)  \n",
       "0          2406.000000      1989.000000      1566.000000           1455.0  \n",
       "1          1083.000000      2197.000000      1001.000000           1488.0  \n",
       "2          1073.000000      1509.000000      1253.000000           1468.0  \n",
       "3          1161.000000      2386.000000      1177.000000           1531.0  \n",
       "4          1029.000000      2075.000000      1131.000000           1509.0  \n",
       "...                ...              ...              ...              ...  \n",
       "19497        88.000000       384.000000       488.000000            292.0  \n",
       "19498        88.000000       421.000000       419.000000            330.0  \n",
       "19499       142.000000       356.000000       442.000000           1292.0  \n",
       "19500       190.787179       488.812821       476.794344            217.0  \n",
       "19501       340.000000       401.000000       475.000000           1105.0  \n",
       "\n",
       "[19502 rows x 14 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料前處理 (一): 刪除前後n筆資料\n",
    "n = 10\n",
    "# 確保依據Label排序\n",
    "test_data = test_data.sort_values(by=label_column).reset_index(drop=True)\n",
    "\n",
    "# 建立一個空的 DataFrame 用於存放處理後的資料\n",
    "test_processed_data = pd.DataFrame(columns=test_data.columns)\n",
    "\n",
    "# 針對每個Label群組進行處理\n",
    "for label, group in test_data.groupby(label_column):\n",
    "    # 刪除前n筆和後n筆資料\n",
    "    if len(group) > 2 * n:  # 確保群組資料足夠\n",
    "        group = group.iloc[n:-n]\n",
    "    else:\n",
    "        group = pd.DataFrame()  # 若資料不足，刪除整個群組\n",
    "    # 將處理後的群組資料加入\n",
    "    test_processed_data = pd.concat([test_processed_data, group], ignore_index=True)\n",
    "\n",
    "# test_processed_data\n",
    "# Calculate the number of rows with NaN values\n",
    "nan_rows = test_processed_data.isnull().any(axis=1).sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of rows with NaN values: {nan_rows}\")\n",
    "\n",
    "# 找出包含 NaN 的列\n",
    "rows_with_nan = test_processed_data[test_processed_data.isnull().any(axis=1)]\n",
    "\n",
    "# # 印出這些列\n",
    "# print(\"Rows with NaN values:\")\n",
    "# print(rows_with_nan)\n",
    "test_data_imputed = test_processed_data.groupby(label_column).apply(\n",
    "    lambda group: group.fillna(group.mean())\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the number of rows with NaN values\n",
    "nan_rows = test_data_imputed.isnull().any(axis=1).sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of rows with NaN values: {nan_rows}\")\n",
    "\n",
    "# 找出包含 NaN 的列\n",
    "rows_with_nan = test_data_imputed[test_data_imputed.isnull().any(axis=1)]\n",
    "\n",
    "test_data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_label_mapping = {v: int(k) - 1 for k, v in label_mapping.items()}  # 讓數字標籤 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reverse_label_mapping in DNN: {'1-1': 10, '1-2': 9, '1-3': 8, '1-4': 7, '1-5': 6, '1-6': 5, '1-7': 4, '1-8': 3, '1-9': 2, '1-10': 1, '1-11': 0, '2-1': 11, '2-11': 29, '3-1': 12, '3-11': 28, '4-1': 13, '4-11': 27, '5-1': 14, '5-11': 26, '6-1': 15, '6-2': 16, '6-3': 17, '6-4': 18, '6-5': 19, '6-6': 20, '6-7': 21, '6-8': 22, '6-9': 23, '6-10': 24, '6-11': 25, '7-1': 48, '7-11': 30, '8-1': 47, '8-11': 31, '9-1': 46, '9-11': 32, '10-1': 45, '10-11': 33, '11-1': 44, '11-2': 43, '11-3': 42, '11-4': 41, '11-5': 40, '11-6': 39, '11-7': 38, '11-8': 37, '11-9': 36, '11-10': 35, '11-11': 34}\n",
      "y_numeric unique values in DNN: [10  1  0  9  8  7  6  5  4  3  2 45 33 44 35 34 43 42 41 40 39 38 37 36\n",
      " 11 29 12 28 13 27 14 26 15 24 25 16 17 18 19 20 21 22 23 48 30 47 31 46\n",
      " 32]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        10\n",
       "1        10\n",
       "2        10\n",
       "3        10\n",
       "4        10\n",
       "         ..\n",
       "19497    32\n",
       "19498    32\n",
       "19499    32\n",
       "19500    32\n",
       "19501    32\n",
       "Name: Label, Length: 19502, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立 Label 映射\n",
    "y_test = test_data_imputed[target_column]\n",
    "y_test_numeric = y_test.map(reverse_label_mapping)\n",
    "\n",
    "print(\"Final reverse_label_mapping in DNN:\", reverse_label_mapping)\n",
    "print(\"y_numeric unique values in DNN:\", y_test_numeric.unique())\n",
    "\n",
    "y_test_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 把label部分拿掉\n",
    "X_test = test_data_imputed.drop(columns=['level_1','Label'])\n",
    "\n",
    "# 確保測試資料的特徵與訓練資料的特徵一致\n",
    "X_test = X_test[X_testing_selected_columns]  # 選取相同的特徵\n",
    "\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用之前訓練時的標準化器 (scaler) 來標準化測試數據\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新訓練model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "# 會發現如果用 train_test_split的方法會有資料分布不平均問題，解決辦法如下\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 設定每個類別的固定樣本數\n",
    "N_train = 5 # 訓練集每個類別至少要有 N_train 筆資料\n",
    "test_val_ratio = 0.5  # 剩餘資料中，50% 作為驗證集，50% 作為測試集\n",
    "\n",
    "# 轉為 DataFrame 方便操作\n",
    "data = pd.DataFrame(X_test_scaled)\n",
    "data['label'] = y_test_numeric  # 加入 label 欄位\n",
    "\n",
    "print((data['label'] == 10).sum())  # 直接計算 True 的數量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679937</td>\n",
       "      <td>0.630414</td>\n",
       "      <td>1.976193</td>\n",
       "      <td>-1.250919</td>\n",
       "      <td>2.397912</td>\n",
       "      <td>1.882758</td>\n",
       "      <td>1.714068</td>\n",
       "      <td>1.023419</td>\n",
       "      <td>1.584552</td>\n",
       "      <td>-0.693505</td>\n",
       "      <td>-0.345825</td>\n",
       "      <td>1.655083</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517006</td>\n",
       "      <td>0.670419</td>\n",
       "      <td>1.393051</td>\n",
       "      <td>-1.250919</td>\n",
       "      <td>0.275802</td>\n",
       "      <td>2.200621</td>\n",
       "      <td>0.594312</td>\n",
       "      <td>1.083537</td>\n",
       "      <td>-0.120783</td>\n",
       "      <td>-0.693505</td>\n",
       "      <td>-1.105064</td>\n",
       "      <td>1.655083</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566392</td>\n",
       "      <td>1.341612</td>\n",
       "      <td>1.363439</td>\n",
       "      <td>-1.234804</td>\n",
       "      <td>0.259762</td>\n",
       "      <td>1.149230</td>\n",
       "      <td>1.093743</td>\n",
       "      <td>1.047102</td>\n",
       "      <td>0.092384</td>\n",
       "      <td>-0.693505</td>\n",
       "      <td>-1.105064</td>\n",
       "      <td>1.965049</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.517006</td>\n",
       "      <td>0.540147</td>\n",
       "      <td>1.377865</td>\n",
       "      <td>-1.250919</td>\n",
       "      <td>0.400915</td>\n",
       "      <td>2.489447</td>\n",
       "      <td>0.943121</td>\n",
       "      <td>1.161874</td>\n",
       "      <td>-0.120783</td>\n",
       "      <td>-0.693505</td>\n",
       "      <td>-1.294873</td>\n",
       "      <td>1.655083</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533468</td>\n",
       "      <td>0.550404</td>\n",
       "      <td>1.378245</td>\n",
       "      <td>-1.234804</td>\n",
       "      <td>0.189185</td>\n",
       "      <td>2.014182</td>\n",
       "      <td>0.851955</td>\n",
       "      <td>1.121795</td>\n",
       "      <td>-0.120783</td>\n",
       "      <td>-0.693505</td>\n",
       "      <td>-1.105064</td>\n",
       "      <td>1.655083</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19497</th>\n",
       "      <td>-0.241512</td>\n",
       "      <td>1.021231</td>\n",
       "      <td>-1.617570</td>\n",
       "      <td>0.798065</td>\n",
       "      <td>-1.320192</td>\n",
       "      <td>-0.569976</td>\n",
       "      <td>-0.422387</td>\n",
       "      <td>-1.095304</td>\n",
       "      <td>0.945051</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>1.362461</td>\n",
       "      <td>-1.754546</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19498</th>\n",
       "      <td>-0.241512</td>\n",
       "      <td>0.994219</td>\n",
       "      <td>-1.587958</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>-1.320192</td>\n",
       "      <td>-0.513434</td>\n",
       "      <td>-0.559136</td>\n",
       "      <td>-1.026077</td>\n",
       "      <td>0.945051</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>1.362461</td>\n",
       "      <td>-1.754546</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19499</th>\n",
       "      <td>-0.290898</td>\n",
       "      <td>1.061236</td>\n",
       "      <td>-1.617570</td>\n",
       "      <td>0.979866</td>\n",
       "      <td>-1.233575</td>\n",
       "      <td>-0.612766</td>\n",
       "      <td>-0.513553</td>\n",
       "      <td>0.726470</td>\n",
       "      <td>0.945051</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>1.362461</td>\n",
       "      <td>-1.599563</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>-0.292370</td>\n",
       "      <td>1.026717</td>\n",
       "      <td>-1.621897</td>\n",
       "      <td>0.846821</td>\n",
       "      <td>-1.155320</td>\n",
       "      <td>-0.409803</td>\n",
       "      <td>-0.444595</td>\n",
       "      <td>-1.231937</td>\n",
       "      <td>1.086616</td>\n",
       "      <td>0.226663</td>\n",
       "      <td>1.368316</td>\n",
       "      <td>-1.599563</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19501</th>\n",
       "      <td>-0.340284</td>\n",
       "      <td>1.034566</td>\n",
       "      <td>-1.632377</td>\n",
       "      <td>1.016226</td>\n",
       "      <td>-0.915980</td>\n",
       "      <td>-0.543997</td>\n",
       "      <td>-0.448151</td>\n",
       "      <td>0.385798</td>\n",
       "      <td>0.945051</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>1.362461</td>\n",
       "      <td>-1.754546</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19502 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.679937  0.630414  1.976193 -1.250919  2.397912  1.882758  1.714068   \n",
       "1      0.517006  0.670419  1.393051 -1.250919  0.275802  2.200621  0.594312   \n",
       "2      0.566392  1.341612  1.363439 -1.234804  0.259762  1.149230  1.093743   \n",
       "3      0.517006  0.540147  1.377865 -1.250919  0.400915  2.489447  0.943121   \n",
       "4      0.533468  0.550404  1.378245 -1.234804  0.189185  2.014182  0.851955   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19497 -0.241512  1.021231 -1.617570  0.798065 -1.320192 -0.569976 -0.422387   \n",
       "19498 -0.241512  0.994219 -1.587958  0.765836 -1.320192 -0.513434 -0.559136   \n",
       "19499 -0.290898  1.061236 -1.617570  0.979866 -1.233575 -0.612766 -0.513553   \n",
       "19500 -0.292370  1.026717 -1.621897  0.846821 -1.155320 -0.409803 -0.444595   \n",
       "19501 -0.340284  1.034566 -1.632377  1.016226 -0.915980 -0.543997 -0.448151   \n",
       "\n",
       "              7         8         9        10        11  label  \n",
       "0      1.023419  1.584552 -0.693505 -0.345825  1.655083     10  \n",
       "1      1.083537 -0.120783 -0.693505 -1.105064  1.655083     10  \n",
       "2      1.047102  0.092384 -0.693505 -1.105064  1.965049     10  \n",
       "3      1.161874 -0.120783 -0.693505 -1.294873  1.655083     10  \n",
       "4      1.121795 -0.120783 -0.693505 -1.105064  1.655083     10  \n",
       "...         ...       ...       ...       ...       ...    ...  \n",
       "19497 -1.095304  0.945051  0.221035  1.362461 -1.754546     32  \n",
       "19498 -1.026077  0.945051  0.221035  1.362461 -1.754546     32  \n",
       "19499  0.726470  0.945051  0.221035  1.362461 -1.599563     32  \n",
       "19500 -1.231937  1.086616  0.226663  1.368316 -1.599563     32  \n",
       "19501  0.385798  0.945051  0.221035  1.362461 -1.754546     32  \n",
       "\n",
       "[19502 rows x 13 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# 儲存訓練集\n",
    "train_data = data.groupby('label', group_keys=False).sample(n=N_train, replace=False, random_state=42)\n",
    "# print(train_data.index)  # 查看 train_data 的索引\n",
    "\n",
    "print((train_data['label'] == 10).sum())  # 計算 label 為 10 的數量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    }
   ],
   "source": [
    "remaining_data = data.drop(train_data.index)\n",
    "print(remaining_data['label'].value_counts().get(10, 0))  # 應該是 348\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    }
   ],
   "source": [
    "# 取得剩餘資料的 features 和 labels\n",
    "X_remaining = remaining_data.drop(columns=['label'])\n",
    "y_remaining = remaining_data['label']\n",
    "\n",
    "print(y_remaining.value_counts().get(10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 245 samples, 49 unique labels\n",
      "Validation set: 9628 samples, 49 unique labels\n",
      "Test set: 9629 samples, 49 unique labels\n"
     ]
    }
   ],
   "source": [
    "# 使用 StratifiedShuffleSplit 來確保驗證集與測試集的類別比例一致\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=test_val_ratio, random_state=42)\n",
    "for val_index, test_index in sss.split(X_remaining, y_remaining):\n",
    "    X_val, X_test = X_remaining.iloc[val_index], X_remaining.iloc[test_index]\n",
    "    y_val, y_test = y_remaining.iloc[val_index], y_remaining.iloc[test_index]\n",
    "\n",
    "# 轉換回 NumPy 陣列\n",
    "X_train_small, y_train_small = train_data.drop(columns=['label']).values, train_data['label'].values\n",
    "X_val, y_val = X_val.values, y_val.values\n",
    "X_test, y_test = X_test.values, y_test.values\n",
    "\n",
    "# 確認切分後的數據數量\n",
    "print(f\"Training set: {len(X_train_small)} samples, {len(np.unique(y_train_small))} unique labels\")\n",
    "print(f\"Validation set: {len(X_val)} samples, {len(np.unique(y_val))} unique labels\")\n",
    "print(f\"Test set: {len(X_test)} samples, {len(np.unique(y_test))} unique labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取出 10% 資料作為訓練資料，剩下的 90% 作為測試資料\n",
    "# X_train_small, X_unused, y_train_small, y_unused = train_test_split(\n",
    "#     X_test_scaled, y_test_numeric, test_size=0.99, random_state=42, stratify=y_test_numeric\n",
    "# )\n",
    "# # 再切出一半作為validation set and test set\n",
    "# X_val, X_test, y_val, y_test = train_test_split(\n",
    "#     X_unused, y_unused, test_size=0.5, random_state=42, stratify=y_unused\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 245 samples\n",
      "Validation set: 9628 samples\n",
      "Test set: 9629 samples\n"
     ]
    }
   ],
   "source": [
    "# 檢查各組資料比例\n",
    "print(f\"Training set: {len(X_train_small)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "      <th>Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training Set  Validation Set  Test Set\n",
       "0              5             196       197\n",
       "1              5             196       197\n",
       "2              5             196       197\n",
       "3              5             197       196\n",
       "4              5             197       196\n",
       "5              5             196       197\n",
       "6              5             197       196\n",
       "7              5             196       197\n",
       "8              5             197       196\n",
       "9              5             197       196\n",
       "10             5             196       197\n",
       "11             5             196       197\n",
       "12             5             197       196\n",
       "13             5             197       196\n",
       "14             5             196       197\n",
       "15             5             197       196\n",
       "16             5             197       196\n",
       "17             5             197       196\n",
       "18             5             196       197\n",
       "19             5             197       196\n",
       "20             5             196       197\n",
       "21             5             196       197\n",
       "22             5             196       197\n",
       "23             5             196       197\n",
       "24             5             197       196\n",
       "25             5             197       196\n",
       "26             5             197       196\n",
       "27             5             197       196\n",
       "28             5             196       197\n",
       "29             5             196       197\n",
       "30             5             196       197\n",
       "31             5             197       196\n",
       "32             5             196       197\n",
       "33             5             197       196\n",
       "34             5             197       196\n",
       "35             5             196       197\n",
       "36             5             196       197\n",
       "37             5             196       197\n",
       "38             5             196       197\n",
       "39             5             196       197\n",
       "40             5             197       196\n",
       "41             5             197       196\n",
       "42             5             196       197\n",
       "43             5             196       197\n",
       "44             5             197       196\n",
       "45             5             197       196\n",
       "46             5             197       196\n",
       "47             5             197       196\n",
       "48             5             196       197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 計算每個 Set 內各 Label 的資料數量\n",
    "train_label_counts = pd.Series(y_train_small).value_counts().sort_index()\n",
    "val_label_counts = pd.Series(y_val).value_counts().sort_index()\n",
    "test_label_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "# # 印出統計結果\n",
    "# print(\"Training Set - Label Counts:\")\n",
    "# print(train_label_counts)\n",
    "\n",
    "# print(\"\\nValidation Set - Label Counts:\")\n",
    "# print(val_label_counts)\n",
    "\n",
    "# print(\"\\nTest Set - Label Counts:\")\n",
    "# print(test_label_counts)\n",
    "\n",
    "# 確保所有 Labels 都有出現在三個 Set 裡\n",
    "all_labels = sorted(set(train_label_counts.index) | set(val_label_counts.index) | set(test_label_counts.index))\n",
    "label_distribution = pd.DataFrame(index=all_labels)\n",
    "\n",
    "label_distribution[\"Training Set\"] = train_label_counts\n",
    "label_distribution[\"Validation Set\"] = val_label_counts\n",
    "label_distribution[\"Test Set\"] = test_label_counts\n",
    "\n",
    "# 用 0 填補缺失值（表示該 Label 在該 Set 中沒有數據）\n",
    "label_distribution = label_distribution.fillna(0).astype(int)\n",
    "\n",
    "from IPython.display import display\n",
    "display(label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 記錄開始時間\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5001 - loss: 5.7259 - val_accuracy: 0.4959 - val_loss: 5.2176\n",
      "Epoch 2/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4876 - loss: 5.1204 - val_accuracy: 0.5080 - val_loss: 4.8191\n",
      "Epoch 3/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5223 - loss: 4.4905 - val_accuracy: 0.5242 - val_loss: 4.4685\n",
      "Epoch 4/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5632 - loss: 4.1269 - val_accuracy: 0.5393 - val_loss: 4.1770\n",
      "Epoch 5/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5809 - loss: 3.9192 - val_accuracy: 0.5540 - val_loss: 3.9187\n",
      "Epoch 6/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6068 - loss: 3.4585 - val_accuracy: 0.5671 - val_loss: 3.7014\n",
      "Epoch 7/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6520 - loss: 3.1933 - val_accuracy: 0.5746 - val_loss: 3.5133\n",
      "Epoch 8/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6833 - loss: 2.9055 - val_accuracy: 0.5827 - val_loss: 3.3353\n",
      "Epoch 9/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6708 - loss: 2.8747 - val_accuracy: 0.5903 - val_loss: 3.1723\n",
      "Epoch 10/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6838 - loss: 2.6700 - val_accuracy: 0.5965 - val_loss: 3.0171\n",
      "Epoch 11/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6963 - loss: 2.6187 - val_accuracy: 0.6053 - val_loss: 2.8649\n",
      "Epoch 12/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6672 - loss: 2.6542 - val_accuracy: 0.6138 - val_loss: 2.7164\n",
      "Epoch 13/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6801 - loss: 2.3145 - val_accuracy: 0.6227 - val_loss: 2.5870\n",
      "Epoch 14/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7004 - loss: 1.9533 - val_accuracy: 0.6290 - val_loss: 2.4692\n",
      "Epoch 15/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7313 - loss: 1.8695 - val_accuracy: 0.6393 - val_loss: 2.3576\n",
      "Epoch 16/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7226 - loss: 1.8541 - val_accuracy: 0.6509 - val_loss: 2.2546\n",
      "Epoch 17/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7625 - loss: 1.7053 - val_accuracy: 0.6628 - val_loss: 2.1531\n",
      "Epoch 18/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7688 - loss: 1.5687 - val_accuracy: 0.6724 - val_loss: 2.0742\n",
      "Epoch 19/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7799 - loss: 1.4255 - val_accuracy: 0.6835 - val_loss: 1.9978\n",
      "Epoch 20/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7957 - loss: 1.3480 - val_accuracy: 0.6939 - val_loss: 1.9225\n",
      "Epoch 21/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8191 - loss: 1.2152 - val_accuracy: 0.7054 - val_loss: 1.8578\n",
      "Epoch 22/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8339 - loss: 1.1257 - val_accuracy: 0.7134 - val_loss: 1.7956\n",
      "Epoch 23/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8346 - loss: 1.1746 - val_accuracy: 0.7211 - val_loss: 1.7430\n",
      "Epoch 24/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8527 - loss: 1.0451 - val_accuracy: 0.7283 - val_loss: 1.6949\n",
      "Epoch 25/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8302 - loss: 0.9575 - val_accuracy: 0.7365 - val_loss: 1.6574\n",
      "Epoch 26/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8210 - loss: 1.1155 - val_accuracy: 0.7413 - val_loss: 1.6057\n",
      "Epoch 27/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8623 - loss: 0.7799 - val_accuracy: 0.7476 - val_loss: 1.5587\n",
      "Epoch 28/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8628 - loss: 0.7390 - val_accuracy: 0.7537 - val_loss: 1.5095\n",
      "Epoch 29/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8386 - loss: 0.9286 - val_accuracy: 0.7598 - val_loss: 1.4599\n",
      "Epoch 30/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8897 - loss: 0.6977 - val_accuracy: 0.7651 - val_loss: 1.4211\n",
      "Epoch 31/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8682 - loss: 0.7288 - val_accuracy: 0.7708 - val_loss: 1.3841\n",
      "Epoch 32/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9144 - loss: 0.5546 - val_accuracy: 0.7749 - val_loss: 1.3511\n",
      "Epoch 33/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9095 - loss: 0.4723 - val_accuracy: 0.7787 - val_loss: 1.3267\n",
      "Epoch 34/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9116 - loss: 0.6010 - val_accuracy: 0.7826 - val_loss: 1.2948\n",
      "Epoch 35/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9315 - loss: 0.5307 - val_accuracy: 0.7871 - val_loss: 1.2668\n",
      "Epoch 36/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9104 - loss: 0.4116 - val_accuracy: 0.7903 - val_loss: 1.2397\n",
      "Epoch 37/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9009 - loss: 0.5700 - val_accuracy: 0.7946 - val_loss: 1.2090\n",
      "Epoch 38/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9053 - loss: 0.5852 - val_accuracy: 0.7973 - val_loss: 1.1850\n",
      "Epoch 39/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9102 - loss: 0.3953 - val_accuracy: 0.8009 - val_loss: 1.1666\n",
      "Epoch 40/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9236 - loss: 0.3914 - val_accuracy: 0.8030 - val_loss: 1.1451\n",
      "Epoch 41/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9284 - loss: 0.3775 - val_accuracy: 0.8063 - val_loss: 1.1287\n",
      "Epoch 42/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9136 - loss: 0.4160 - val_accuracy: 0.8108 - val_loss: 1.1039\n",
      "Epoch 43/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8949 - loss: 0.5462 - val_accuracy: 0.8140 - val_loss: 1.0854\n",
      "Epoch 44/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9339 - loss: 0.3133 - val_accuracy: 0.8161 - val_loss: 1.0694\n",
      "Epoch 45/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9195 - loss: 0.4585 - val_accuracy: 0.8179 - val_loss: 1.0548\n",
      "Epoch 46/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9315 - loss: 0.3337 - val_accuracy: 0.8215 - val_loss: 1.0396\n",
      "Epoch 47/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9172 - loss: 0.3875 - val_accuracy: 0.8234 - val_loss: 1.0264\n",
      "Epoch 48/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9263 - loss: 0.3929 - val_accuracy: 0.8259 - val_loss: 1.0155\n",
      "Epoch 49/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9461 - loss: 0.3226 - val_accuracy: 0.8276 - val_loss: 1.0038\n",
      "Epoch 50/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9202 - loss: 0.3677 - val_accuracy: 0.8312 - val_loss: 0.9902\n",
      "Epoch 51/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9367 - loss: 0.3443 - val_accuracy: 0.8323 - val_loss: 0.9814\n",
      "Epoch 52/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9445 - loss: 0.2943 - val_accuracy: 0.8349 - val_loss: 0.9711\n",
      "Epoch 53/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9527 - loss: 0.2540 - val_accuracy: 0.8371 - val_loss: 0.9610\n",
      "Epoch 54/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9560 - loss: 0.2282 - val_accuracy: 0.8380 - val_loss: 0.9546\n",
      "Epoch 55/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9413 - loss: 0.2560 - val_accuracy: 0.8390 - val_loss: 0.9475\n",
      "Epoch 56/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9630 - loss: 0.1709 - val_accuracy: 0.8403 - val_loss: 0.9405\n",
      "Epoch 57/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9533 - loss: 0.1925 - val_accuracy: 0.8417 - val_loss: 0.9332\n",
      "Epoch 58/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9566 - loss: 0.2059 - val_accuracy: 0.8433 - val_loss: 0.9256\n",
      "Epoch 59/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9682 - loss: 0.1589 - val_accuracy: 0.8447 - val_loss: 0.9190\n",
      "Epoch 60/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9594 - loss: 0.1746 - val_accuracy: 0.8465 - val_loss: 0.9135\n",
      "Epoch 61/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9653 - loss: 0.1580 - val_accuracy: 0.8480 - val_loss: 0.9089\n",
      "Epoch 62/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9745 - loss: 0.1220 - val_accuracy: 0.8489 - val_loss: 0.9037\n",
      "Epoch 63/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9564 - loss: 0.1622 - val_accuracy: 0.8504 - val_loss: 0.8973\n",
      "Epoch 64/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9735 - loss: 0.1090 - val_accuracy: 0.8514 - val_loss: 0.8920\n",
      "Epoch 65/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9583 - loss: 0.1559 - val_accuracy: 0.8524 - val_loss: 0.8880\n",
      "Epoch 66/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9749 - loss: 0.0989 - val_accuracy: 0.8544 - val_loss: 0.8826\n",
      "Epoch 67/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9759 - loss: 0.1079 - val_accuracy: 0.8553 - val_loss: 0.8780\n",
      "Epoch 68/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9602 - loss: 0.1695 - val_accuracy: 0.8564 - val_loss: 0.8742\n",
      "Epoch 69/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9674 - loss: 0.1106 - val_accuracy: 0.8582 - val_loss: 0.8682\n",
      "Epoch 70/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9644 - loss: 0.1198 - val_accuracy: 0.8595 - val_loss: 0.8642\n",
      "Epoch 71/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9753 - loss: 0.0733 - val_accuracy: 0.8603 - val_loss: 0.8592\n",
      "Epoch 72/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9757 - loss: 0.0666 - val_accuracy: 0.8612 - val_loss: 0.8551\n",
      "Epoch 73/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9779 - loss: 0.0756 - val_accuracy: 0.8622 - val_loss: 0.8508\n",
      "Epoch 74/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9817 - loss: 0.0788 - val_accuracy: 0.8627 - val_loss: 0.8474\n",
      "Epoch 75/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9824 - loss: 0.0868 - val_accuracy: 0.8636 - val_loss: 0.8419\n",
      "Epoch 76/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9761 - loss: 0.0950 - val_accuracy: 0.8648 - val_loss: 0.8375\n",
      "Epoch 77/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9846 - loss: 0.0591 - val_accuracy: 0.8660 - val_loss: 0.8341\n",
      "Epoch 78/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9715 - loss: 0.0858 - val_accuracy: 0.8675 - val_loss: 0.8302\n",
      "Epoch 79/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9825 - loss: 0.0774 - val_accuracy: 0.8685 - val_loss: 0.8256\n",
      "Epoch 80/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9837 - loss: 0.0561 - val_accuracy: 0.8692 - val_loss: 0.8221\n",
      "Epoch 81/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9834 - loss: 0.0796 - val_accuracy: 0.8698 - val_loss: 0.8183\n",
      "Epoch 82/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9872 - loss: 0.0443 - val_accuracy: 0.8703 - val_loss: 0.8149\n",
      "Epoch 83/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9755 - loss: 0.0679 - val_accuracy: 0.8715 - val_loss: 0.8109\n",
      "Epoch 84/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9909 - loss: 0.0555 - val_accuracy: 0.8722 - val_loss: 0.8066\n",
      "Epoch 85/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9891 - loss: 0.0461 - val_accuracy: 0.8728 - val_loss: 0.8035\n",
      "Epoch 86/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9971 - loss: 0.0358 - val_accuracy: 0.8740 - val_loss: 0.8010\n",
      "Epoch 87/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9927 - loss: 0.0328 - val_accuracy: 0.8751 - val_loss: 0.7978\n",
      "Epoch 88/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9965 - loss: 0.0463 - val_accuracy: 0.8757 - val_loss: 0.7952\n",
      "Epoch 89/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9973 - loss: 0.0330 - val_accuracy: 0.8763 - val_loss: 0.7927\n",
      "Epoch 90/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9986 - loss: 0.0319 - val_accuracy: 0.8772 - val_loss: 0.7905\n",
      "Epoch 91/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9953 - loss: 0.0391 - val_accuracy: 0.8778 - val_loss: 0.7876\n",
      "Epoch 92/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9980 - loss: 0.0294 - val_accuracy: 0.8775 - val_loss: 0.7856\n",
      "Epoch 93/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 0.8784 - val_loss: 0.7830\n",
      "Epoch 94/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.8795 - val_loss: 0.7807\n",
      "Epoch 95/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0269 - val_accuracy: 0.8798 - val_loss: 0.7782\n",
      "Epoch 96/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.8800 - val_loss: 0.7762\n",
      "Epoch 97/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.8803 - val_loss: 0.7742\n",
      "Epoch 98/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.8808 - val_loss: 0.7726\n",
      "Epoch 99/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 0.8807 - val_loss: 0.7710\n",
      "Epoch 100/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.8812 - val_loss: 0.7683\n",
      "Epoch 101/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.8817 - val_loss: 0.7673\n",
      "Epoch 102/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.8827 - val_loss: 0.7655\n",
      "Epoch 103/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.8827 - val_loss: 0.7635\n",
      "Epoch 104/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.8832 - val_loss: 0.7616\n",
      "Epoch 105/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.8833 - val_loss: 0.7605\n",
      "Epoch 106/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.8837 - val_loss: 0.7589\n",
      "Epoch 107/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.8843 - val_loss: 0.7572\n",
      "Epoch 108/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.8848 - val_loss: 0.7555\n",
      "Epoch 109/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.8848 - val_loss: 0.7541\n",
      "Epoch 110/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.8849 - val_loss: 0.7524\n",
      "Epoch 111/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.8850 - val_loss: 0.7507\n",
      "Epoch 112/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.8853 - val_loss: 0.7491\n",
      "Epoch 113/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.8857 - val_loss: 0.7476\n",
      "Epoch 114/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.8865 - val_loss: 0.7462\n",
      "Epoch 115/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.8869 - val_loss: 0.7445\n",
      "Epoch 116/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.8867 - val_loss: 0.7435\n",
      "Epoch 117/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.8874 - val_loss: 0.7421\n",
      "Epoch 118/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.8874 - val_loss: 0.7409\n",
      "Epoch 119/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8880 - val_loss: 0.7399\n",
      "Epoch 120/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.8885 - val_loss: 0.7387\n",
      "Epoch 121/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.8885 - val_loss: 0.7373\n",
      "Epoch 122/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.8888 - val_loss: 0.7361\n",
      "Epoch 123/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8891 - val_loss: 0.7350\n",
      "Epoch 124/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.8894 - val_loss: 0.7334\n",
      "Epoch 125/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.8896 - val_loss: 0.7320\n",
      "Epoch 126/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.8897 - val_loss: 0.7312\n",
      "Epoch 127/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.8897 - val_loss: 0.7303\n",
      "Epoch 128/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.8899 - val_loss: 0.7290\n",
      "Epoch 129/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8902 - val_loss: 0.7283\n",
      "Epoch 130/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.8902 - val_loss: 0.7269\n",
      "Epoch 131/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8906 - val_loss: 0.7262\n",
      "Epoch 132/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.8908 - val_loss: 0.7248\n",
      "Epoch 133/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.8910 - val_loss: 0.7236\n",
      "Epoch 134/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8914 - val_loss: 0.7228\n",
      "Epoch 135/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.8916 - val_loss: 0.7217\n",
      "Epoch 136/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8917 - val_loss: 0.7207\n",
      "Epoch 137/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8919 - val_loss: 0.7198\n",
      "Epoch 138/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.8922 - val_loss: 0.7188\n",
      "Epoch 139/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.8926 - val_loss: 0.7180\n",
      "Epoch 140/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8928 - val_loss: 0.7172\n",
      "Epoch 141/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.8934 - val_loss: 0.7160\n",
      "Epoch 142/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8939 - val_loss: 0.7153\n",
      "Epoch 143/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8941 - val_loss: 0.7142\n",
      "Epoch 144/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8943 - val_loss: 0.7133\n",
      "Epoch 145/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.8949 - val_loss: 0.7126\n",
      "Epoch 146/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.8948 - val_loss: 0.7116\n",
      "Epoch 147/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.8949 - val_loss: 0.7105\n",
      "Epoch 148/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8950 - val_loss: 0.7094\n",
      "Epoch 149/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.8951 - val_loss: 0.7088\n",
      "Epoch 150/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8954 - val_loss: 0.7078\n",
      "Epoch 151/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8954 - val_loss: 0.7072\n",
      "Epoch 152/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8956 - val_loss: 0.7065\n",
      "Epoch 153/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8956 - val_loss: 0.7059\n",
      "Epoch 154/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8958 - val_loss: 0.7050\n",
      "Epoch 155/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.8960 - val_loss: 0.7039\n",
      "Epoch 156/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8963 - val_loss: 0.7036\n",
      "Epoch 157/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8962 - val_loss: 0.7027\n",
      "Epoch 158/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8966 - val_loss: 0.7021\n",
      "Epoch 159/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.8968 - val_loss: 0.7014\n",
      "Epoch 160/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8969 - val_loss: 0.7006\n",
      "Epoch 161/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8969 - val_loss: 0.7001\n",
      "Epoch 162/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8973 - val_loss: 0.6995\n",
      "Epoch 163/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8975 - val_loss: 0.6988\n",
      "Epoch 164/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8982 - val_loss: 0.6982\n",
      "Epoch 165/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8982 - val_loss: 0.6973\n",
      "Epoch 166/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8990 - val_loss: 0.6960\n",
      "Epoch 167/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8985 - val_loss: 0.6951\n",
      "Epoch 168/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8988 - val_loss: 0.6943\n",
      "Epoch 169/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8991 - val_loss: 0.6936\n",
      "Epoch 170/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.8991 - val_loss: 0.6929\n",
      "Epoch 171/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.8994 - val_loss: 0.6923\n",
      "Epoch 172/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8998 - val_loss: 0.6915\n",
      "Epoch 173/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8998 - val_loss: 0.6907\n",
      "Epoch 174/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8999 - val_loss: 0.6899\n",
      "Epoch 175/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8998 - val_loss: 0.6892\n",
      "Epoch 176/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8999 - val_loss: 0.6885\n",
      "Epoch 177/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8999 - val_loss: 0.6880\n",
      "Epoch 178/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9002 - val_loss: 0.6875\n",
      "Epoch 179/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9002 - val_loss: 0.6871\n",
      "Epoch 180/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9002 - val_loss: 0.6861\n",
      "Epoch 181/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9004 - val_loss: 0.6855\n",
      "Epoch 182/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9006 - val_loss: 0.6848\n",
      "Epoch 183/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9008 - val_loss: 0.6845\n",
      "Epoch 184/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9012 - val_loss: 0.6837\n",
      "Epoch 185/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9015 - val_loss: 0.6829\n",
      "Epoch 186/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9020 - val_loss: 0.6821\n",
      "Epoch 187/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9024 - val_loss: 0.6819\n",
      "Epoch 188/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9025 - val_loss: 0.6813\n",
      "Epoch 189/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9024 - val_loss: 0.6810\n",
      "Epoch 190/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9024 - val_loss: 0.6801\n",
      "Epoch 191/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9024 - val_loss: 0.6798\n",
      "Epoch 192/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9024 - val_loss: 0.6793\n",
      "Epoch 193/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9028 - val_loss: 0.6787\n",
      "Epoch 194/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9028 - val_loss: 0.6781\n",
      "Epoch 195/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9031 - val_loss: 0.6776\n",
      "Epoch 196/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9031 - val_loss: 0.6770\n",
      "Epoch 197/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9033 - val_loss: 0.6762\n",
      "Epoch 198/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9033 - val_loss: 0.6756\n",
      "Epoch 199/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9037 - val_loss: 0.6751\n",
      "Epoch 200/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9037 - val_loss: 0.6747\n",
      "Epoch 201/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9042 - val_loss: 0.6741\n",
      "Epoch 202/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9042 - val_loss: 0.6735\n",
      "Epoch 203/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9041 - val_loss: 0.6732\n",
      "Epoch 204/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9043 - val_loss: 0.6731\n",
      "Epoch 205/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9045 - val_loss: 0.6727\n",
      "Epoch 206/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9049 - val_loss: 0.6721\n",
      "Epoch 207/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9048 - val_loss: 0.6713\n",
      "Epoch 208/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9050 - val_loss: 0.6708\n",
      "Epoch 209/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9049 - val_loss: 0.6704\n",
      "Epoch 210/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9049 - val_loss: 0.6697\n",
      "Epoch 211/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9050 - val_loss: 0.6693\n",
      "Epoch 212/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9052 - val_loss: 0.6689\n",
      "Epoch 213/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9055 - val_loss: 0.6684\n",
      "Epoch 214/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9057 - val_loss: 0.6679\n",
      "Epoch 215/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9057 - val_loss: 0.6676\n",
      "Epoch 216/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9057 - val_loss: 0.6668\n",
      "Epoch 217/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9060 - val_loss: 0.6665\n",
      "Epoch 218/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9060 - val_loss: 0.6659\n",
      "Epoch 219/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9061 - val_loss: 0.6653\n",
      "Epoch 220/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9062 - val_loss: 0.6648\n",
      "Epoch 221/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9062 - val_loss: 0.6644\n",
      "Epoch 222/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9060 - val_loss: 0.6640\n",
      "Epoch 223/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9063 - val_loss: 0.6631\n",
      "Epoch 224/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9064 - val_loss: 0.6627\n",
      "Epoch 225/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9066 - val_loss: 0.6624\n",
      "Epoch 226/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9067 - val_loss: 0.6621\n",
      "Epoch 227/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9069 - val_loss: 0.6619\n",
      "Epoch 228/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9071 - val_loss: 0.6615\n",
      "Epoch 229/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9072 - val_loss: 0.6610\n",
      "Epoch 230/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9071 - val_loss: 0.6604\n",
      "Epoch 231/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9072 - val_loss: 0.6599\n",
      "Epoch 232/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9071 - val_loss: 0.6594\n",
      "Epoch 233/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9072 - val_loss: 0.6590\n",
      "Epoch 234/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9071 - val_loss: 0.6585\n",
      "Epoch 235/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9072 - val_loss: 0.6581\n",
      "Epoch 236/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9074 - val_loss: 0.6576\n",
      "Epoch 237/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9076 - val_loss: 0.6574\n",
      "Epoch 238/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9079 - val_loss: 0.6572\n",
      "Epoch 239/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9079 - val_loss: 0.6568\n",
      "Epoch 240/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9077 - val_loss: 0.6560\n",
      "Epoch 241/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9078 - val_loss: 0.6554\n",
      "Epoch 242/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9079 - val_loss: 0.6552\n",
      "Epoch 243/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9084 - val_loss: 0.6549\n",
      "Epoch 244/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9086 - val_loss: 0.6545\n",
      "Epoch 245/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9087 - val_loss: 0.6540\n",
      "Epoch 246/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9088 - val_loss: 0.6535\n",
      "Epoch 247/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9089 - val_loss: 0.6532\n",
      "Epoch 248/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9089 - val_loss: 0.6530\n",
      "Epoch 249/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9090 - val_loss: 0.6523\n",
      "Epoch 250/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9092 - val_loss: 0.6520\n",
      "Epoch 251/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9094 - val_loss: 0.6517\n",
      "Epoch 252/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9094 - val_loss: 0.6515\n",
      "Epoch 253/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9097 - val_loss: 0.6512\n",
      "Epoch 254/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9097 - val_loss: 0.6507\n",
      "Epoch 255/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9098 - val_loss: 0.6504\n",
      "Epoch 256/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9100 - val_loss: 0.6498\n",
      "Epoch 257/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9098 - val_loss: 0.6495\n",
      "Epoch 258/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9101 - val_loss: 0.6488\n",
      "Epoch 259/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9100 - val_loss: 0.6484\n",
      "Epoch 260/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9101 - val_loss: 0.6480\n",
      "Epoch 261/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9101 - val_loss: 0.6476\n",
      "Epoch 262/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9101 - val_loss: 0.6474\n",
      "Epoch 263/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9101 - val_loss: 0.6472\n",
      "Epoch 264/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9100 - val_loss: 0.6467\n",
      "Epoch 265/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9102 - val_loss: 0.6462\n",
      "Epoch 266/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9102 - val_loss: 0.6458\n",
      "Epoch 267/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9104 - val_loss: 0.6456\n",
      "Epoch 268/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9105 - val_loss: 0.6453\n",
      "Epoch 269/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9105 - val_loss: 0.6451\n",
      "Epoch 270/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9105 - val_loss: 0.6448\n",
      "Epoch 271/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9108 - val_loss: 0.6445\n",
      "Epoch 272/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9107 - val_loss: 0.6440\n",
      "Epoch 273/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9109 - val_loss: 0.6438\n",
      "Epoch 274/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9112 - val_loss: 0.6435\n",
      "Epoch 275/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9113 - val_loss: 0.6432\n",
      "Epoch 276/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9115 - val_loss: 0.6427\n",
      "Epoch 277/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9114 - val_loss: 0.6421\n",
      "Epoch 278/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9115 - val_loss: 0.6416\n",
      "Epoch 279/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9116 - val_loss: 0.6414\n",
      "Epoch 280/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9115 - val_loss: 0.6410\n",
      "Epoch 281/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9115 - val_loss: 0.6407\n",
      "Epoch 282/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9119 - val_loss: 0.6402\n",
      "Epoch 283/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9120 - val_loss: 0.6397\n",
      "Epoch 284/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9119 - val_loss: 0.6396\n",
      "Epoch 285/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9119 - val_loss: 0.6391\n",
      "Epoch 286/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9120 - val_loss: 0.6386\n",
      "Epoch 287/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9120 - val_loss: 0.6386\n",
      "Epoch 288/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9122 - val_loss: 0.6382\n",
      "Epoch 289/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9123 - val_loss: 0.6379\n",
      "Epoch 290/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9127 - val_loss: 0.6374\n",
      "Epoch 291/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9127 - val_loss: 0.6373\n",
      "Epoch 292/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9129 - val_loss: 0.6369\n",
      "Epoch 293/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9129 - val_loss: 0.6366\n",
      "Epoch 294/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9129 - val_loss: 0.6362\n",
      "Epoch 295/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9129 - val_loss: 0.6360\n",
      "Epoch 296/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9128 - val_loss: 0.6360\n",
      "Epoch 297/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9128 - val_loss: 0.6358\n",
      "Epoch 298/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9128 - val_loss: 0.6355\n",
      "Epoch 299/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9128 - val_loss: 0.6352\n",
      "Epoch 300/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9130 - val_loss: 0.6349\n",
      "Epoch 301/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9129 - val_loss: 0.6347\n",
      "Epoch 302/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9130 - val_loss: 0.6344\n",
      "Epoch 303/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9129 - val_loss: 0.6339\n",
      "Epoch 304/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9128 - val_loss: 0.6335\n",
      "Epoch 305/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9130 - val_loss: 0.6333\n",
      "Epoch 306/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9131 - val_loss: 0.6330\n",
      "Epoch 307/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9130 - val_loss: 0.6329\n",
      "Epoch 308/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9131 - val_loss: 0.6325\n",
      "Epoch 309/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9131 - val_loss: 0.6322\n",
      "Epoch 310/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9132 - val_loss: 0.6319\n",
      "Epoch 311/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9132 - val_loss: 0.6315\n",
      "Epoch 312/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9133 - val_loss: 0.6314\n",
      "Epoch 313/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9133 - val_loss: 0.6310\n",
      "Epoch 314/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9133 - val_loss: 0.6304\n",
      "Epoch 315/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9133 - val_loss: 0.6300\n",
      "Epoch 316/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9133 - val_loss: 0.6299\n",
      "Epoch 317/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9134 - val_loss: 0.6297\n",
      "Epoch 318/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9134 - val_loss: 0.6292\n",
      "Epoch 319/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9133 - val_loss: 0.6291\n",
      "Epoch 320/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9133 - val_loss: 0.6289\n",
      "Epoch 321/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9133 - val_loss: 0.6286\n",
      "Epoch 322/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9134 - val_loss: 0.6284\n",
      "Epoch 323/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9136 - val_loss: 0.6280\n",
      "Epoch 324/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9137 - val_loss: 0.6276\n",
      "Epoch 325/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9139 - val_loss: 0.6274\n",
      "Epoch 326/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9140 - val_loss: 0.6271\n",
      "Epoch 327/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9141 - val_loss: 0.6271\n",
      "Epoch 328/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9141 - val_loss: 0.6266\n",
      "Epoch 329/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9141 - val_loss: 0.6265\n",
      "Epoch 330/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9141 - val_loss: 0.6262\n",
      "Epoch 331/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9143 - val_loss: 0.6259\n",
      "Epoch 332/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9141 - val_loss: 0.6256\n",
      "Epoch 333/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9144 - val_loss: 0.6252\n",
      "Epoch 334/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9144 - val_loss: 0.6251\n",
      "Epoch 335/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9145 - val_loss: 0.6250\n",
      "Epoch 336/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9145 - val_loss: 0.6249\n",
      "Epoch 337/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9145 - val_loss: 0.6245\n",
      "Epoch 338/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9147 - val_loss: 0.6242\n",
      "Epoch 339/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9148 - val_loss: 0.6239\n",
      "Epoch 340/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9151 - val_loss: 0.6237\n",
      "Epoch 341/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9150 - val_loss: 0.6234\n",
      "Epoch 342/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9151 - val_loss: 0.6231\n",
      "Epoch 343/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9150 - val_loss: 0.6230\n",
      "Epoch 344/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9152 - val_loss: 0.6227\n",
      "Epoch 345/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9152 - val_loss: 0.6224\n",
      "Epoch 346/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9152 - val_loss: 0.6224\n",
      "Epoch 347/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9152 - val_loss: 0.6223\n",
      "Epoch 348/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9155 - val_loss: 0.6218\n",
      "Epoch 349/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9155 - val_loss: 0.6215\n",
      "Epoch 350/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9155 - val_loss: 0.6213\n",
      "Epoch 351/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9154 - val_loss: 0.6209\n",
      "Epoch 352/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9156 - val_loss: 0.6206\n",
      "Epoch 353/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9156 - val_loss: 0.6202\n",
      "Epoch 354/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9160 - val_loss: 0.6204\n",
      "Epoch 355/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9159 - val_loss: 0.6201\n",
      "Epoch 356/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9159 - val_loss: 0.6197\n",
      "Epoch 357/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9160 - val_loss: 0.6194\n",
      "Epoch 358/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9162 - val_loss: 0.6192\n",
      "Epoch 359/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9164 - val_loss: 0.6189\n",
      "Epoch 360/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9163 - val_loss: 0.6188\n",
      "Epoch 361/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9165 - val_loss: 0.6186\n",
      "Epoch 362/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9164 - val_loss: 0.6185\n",
      "Epoch 363/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9164 - val_loss: 0.6181\n",
      "Epoch 364/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9164 - val_loss: 0.6178\n",
      "Epoch 365/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9165 - val_loss: 0.6175\n",
      "Epoch 366/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9166 - val_loss: 0.6172\n",
      "Epoch 367/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9165 - val_loss: 0.6168\n",
      "Epoch 368/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9166 - val_loss: 0.6167\n",
      "Epoch 369/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9166 - val_loss: 0.6167\n",
      "Epoch 370/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9167 - val_loss: 0.6164\n",
      "Epoch 371/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9167 - val_loss: 0.6161\n",
      "Epoch 372/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9167 - val_loss: 0.6158\n",
      "Epoch 373/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9169 - val_loss: 0.6158\n",
      "Epoch 374/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9169 - val_loss: 0.6154\n",
      "Epoch 375/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9171 - val_loss: 0.6152\n",
      "Epoch 376/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9173 - val_loss: 0.6150\n",
      "Epoch 377/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9172 - val_loss: 0.6148\n",
      "Epoch 378/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9171 - val_loss: 0.6146\n",
      "Epoch 379/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9171 - val_loss: 0.6146\n",
      "Epoch 380/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9172 - val_loss: 0.6141\n",
      "Epoch 381/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9174 - val_loss: 0.6136\n",
      "Epoch 382/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9174 - val_loss: 0.6134\n",
      "Epoch 383/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9174 - val_loss: 0.6133\n",
      "Epoch 384/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9174 - val_loss: 0.6130\n",
      "Epoch 385/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9176 - val_loss: 0.6128\n",
      "Epoch 386/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9176 - val_loss: 0.6124\n",
      "Epoch 387/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9177 - val_loss: 0.6125\n",
      "Epoch 388/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9179 - val_loss: 0.6124\n",
      "Epoch 389/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9178 - val_loss: 0.6122\n",
      "Epoch 390/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9178 - val_loss: 0.6118\n",
      "Epoch 391/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9179 - val_loss: 0.6116\n",
      "Epoch 392/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9179 - val_loss: 0.6115\n",
      "Epoch 393/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9181 - val_loss: 0.6113\n",
      "Epoch 394/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9181 - val_loss: 0.6109\n",
      "Epoch 395/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9182 - val_loss: 0.6105\n",
      "Epoch 396/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9182 - val_loss: 0.6105\n",
      "Epoch 397/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9181 - val_loss: 0.6101\n",
      "Epoch 398/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9183 - val_loss: 0.6100\n",
      "Epoch 399/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9185 - val_loss: 0.6098\n",
      "Epoch 400/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9186 - val_loss: 0.6095\n",
      "Epoch 401/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9187 - val_loss: 0.6096\n",
      "Epoch 402/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9187 - val_loss: 0.6094\n",
      "Epoch 403/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9186 - val_loss: 0.6091\n",
      "Epoch 404/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9187 - val_loss: 0.6090\n",
      "Epoch 405/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9185 - val_loss: 0.6087\n",
      "Epoch 406/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9187 - val_loss: 0.6084\n",
      "Epoch 407/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9185 - val_loss: 0.6083\n",
      "Epoch 408/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9188 - val_loss: 0.6081\n",
      "Epoch 409/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9186 - val_loss: 0.6079\n",
      "Epoch 410/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9188 - val_loss: 0.6075\n",
      "Epoch 411/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9189 - val_loss: 0.6074\n",
      "Epoch 412/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9189 - val_loss: 0.6071\n",
      "Epoch 413/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9190 - val_loss: 0.6068\n",
      "Epoch 414/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9190 - val_loss: 0.6066\n",
      "Epoch 415/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9190 - val_loss: 0.6064\n",
      "Epoch 416/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9190 - val_loss: 0.6060\n",
      "Epoch 417/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9191 - val_loss: 0.6057\n",
      "Epoch 418/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9191 - val_loss: 0.6056\n",
      "Epoch 419/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9191 - val_loss: 0.6055\n",
      "Epoch 420/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9191 - val_loss: 0.6054\n",
      "Epoch 421/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9192 - val_loss: 0.6051\n",
      "Epoch 422/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9193 - val_loss: 0.6048\n",
      "Epoch 423/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9193 - val_loss: 0.6046\n",
      "Epoch 424/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9193 - val_loss: 0.6045\n",
      "Epoch 425/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9193 - val_loss: 0.6042\n",
      "Epoch 426/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9194 - val_loss: 0.6042\n",
      "Epoch 427/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9194 - val_loss: 0.6041\n",
      "Epoch 428/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9193 - val_loss: 0.6037\n",
      "Epoch 429/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9194 - val_loss: 0.6036\n",
      "Epoch 430/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.6965e-04 - val_accuracy: 0.9193 - val_loss: 0.6035\n",
      "Epoch 431/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9194 - val_loss: 0.6032\n",
      "Epoch 432/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9197 - val_loss: 0.6030\n",
      "Epoch 433/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9197 - val_loss: 0.6030\n",
      "Epoch 434/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9197 - val_loss: 0.6027\n",
      "Epoch 435/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9197 - val_loss: 0.6025\n",
      "Epoch 436/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9196 - val_loss: 0.6023\n",
      "Epoch 437/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9197 - val_loss: 0.6022\n",
      "Epoch 438/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9196 - val_loss: 0.6020\n",
      "Epoch 439/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9198 - val_loss: 0.6018\n",
      "Epoch 440/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9198 - val_loss: 0.6016\n",
      "Epoch 441/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9200 - val_loss: 0.6016\n",
      "Epoch 442/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9199 - val_loss: 0.6014\n",
      "Epoch 443/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9199 - val_loss: 0.6014\n",
      "Epoch 444/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.9449e-04 - val_accuracy: 0.9199 - val_loss: 0.6013\n",
      "Epoch 445/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9199 - val_loss: 0.6011\n",
      "Epoch 446/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.1849e-04 - val_accuracy: 0.9203 - val_loss: 0.6009\n",
      "Epoch 447/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9203 - val_loss: 0.6004\n",
      "Epoch 448/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9206 - val_loss: 0.6000\n",
      "Epoch 449/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9206 - val_loss: 0.5999\n",
      "Epoch 450/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9208 - val_loss: 0.5998\n",
      "Epoch 451/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.1553e-04 - val_accuracy: 0.9206 - val_loss: 0.5995\n",
      "Epoch 452/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9204 - val_loss: 0.5993\n",
      "Epoch 453/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9206 - val_loss: 0.5990\n",
      "Epoch 454/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.2354e-04 - val_accuracy: 0.9209 - val_loss: 0.5988\n",
      "Epoch 455/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.7415e-04 - val_accuracy: 0.9209 - val_loss: 0.5987\n",
      "Epoch 456/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0878e-04 - val_accuracy: 0.9209 - val_loss: 0.5985\n",
      "Epoch 457/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.8098e-04 - val_accuracy: 0.9209 - val_loss: 0.5983\n",
      "Epoch 458/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.8649e-04 - val_accuracy: 0.9210 - val_loss: 0.5979\n",
      "Epoch 459/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.4030e-04 - val_accuracy: 0.9208 - val_loss: 0.5979\n",
      "Epoch 460/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.7383e-04 - val_accuracy: 0.9210 - val_loss: 0.5978\n",
      "Epoch 461/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.6448e-04 - val_accuracy: 0.9209 - val_loss: 0.5976\n",
      "Epoch 462/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9211 - val_loss: 0.5974\n",
      "Epoch 463/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7818e-04 - val_accuracy: 0.9209 - val_loss: 0.5973\n",
      "Epoch 464/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9210 - val_loss: 0.5972\n",
      "Epoch 465/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.2817e-04 - val_accuracy: 0.9210 - val_loss: 0.5969\n",
      "Epoch 466/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9211 - val_loss: 0.5968\n",
      "Epoch 467/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.7222e-04 - val_accuracy: 0.9211 - val_loss: 0.5967\n",
      "Epoch 468/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7039e-04 - val_accuracy: 0.9212 - val_loss: 0.5965\n",
      "Epoch 469/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9211 - val_loss: 0.5962\n",
      "Epoch 470/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9213 - val_loss: 0.5960\n",
      "Epoch 471/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.4024e-04 - val_accuracy: 0.9213 - val_loss: 0.5960\n",
      "Epoch 472/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.3294e-04 - val_accuracy: 0.9213 - val_loss: 0.5959\n",
      "Epoch 473/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.9245e-04 - val_accuracy: 0.9212 - val_loss: 0.5956\n",
      "Epoch 474/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9212 - val_loss: 0.5954\n",
      "Epoch 475/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.9011e-04 - val_accuracy: 0.9213 - val_loss: 0.5952\n",
      "Epoch 476/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.3513e-04 - val_accuracy: 0.9214 - val_loss: 0.5952\n",
      "Epoch 477/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9215 - val_loss: 0.5950\n",
      "Epoch 478/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.8459e-04 - val_accuracy: 0.9215 - val_loss: 0.5948\n",
      "Epoch 479/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.5901e-04 - val_accuracy: 0.9215 - val_loss: 0.5946\n",
      "Epoch 480/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.2303e-04 - val_accuracy: 0.9216 - val_loss: 0.5943\n",
      "Epoch 481/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.5735e-04 - val_accuracy: 0.9216 - val_loss: 0.5942\n",
      "Epoch 482/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.2501e-04 - val_accuracy: 0.9218 - val_loss: 0.5942\n",
      "Epoch 483/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.3074e-04 - val_accuracy: 0.9216 - val_loss: 0.5939\n",
      "Epoch 484/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.2350e-04 - val_accuracy: 0.9218 - val_loss: 0.5937\n",
      "Epoch 485/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9218 - val_loss: 0.5936\n",
      "Epoch 486/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.1839e-04 - val_accuracy: 0.9218 - val_loss: 0.5936\n",
      "Epoch 487/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.3499e-04 - val_accuracy: 0.9218 - val_loss: 0.5933\n",
      "Epoch 488/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.2414e-04 - val_accuracy: 0.9218 - val_loss: 0.5931\n",
      "Epoch 489/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.1895e-04 - val_accuracy: 0.9218 - val_loss: 0.5928\n",
      "Epoch 490/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.5201e-04 - val_accuracy: 0.9219 - val_loss: 0.5928\n",
      "Epoch 491/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.2614e-04 - val_accuracy: 0.9220 - val_loss: 0.5927\n",
      "Epoch 492/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.8462e-04 - val_accuracy: 0.9220 - val_loss: 0.5925\n",
      "Epoch 493/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.6136e-04 - val_accuracy: 0.9221 - val_loss: 0.5925\n",
      "Epoch 494/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.7444e-04 - val_accuracy: 0.9221 - val_loss: 0.5922\n",
      "Epoch 495/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9832e-04 - val_accuracy: 0.9221 - val_loss: 0.5922\n",
      "Epoch 496/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.0900e-04 - val_accuracy: 0.9220 - val_loss: 0.5919\n",
      "Epoch 497/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7061e-04 - val_accuracy: 0.9220 - val_loss: 0.5917\n",
      "Epoch 498/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.6856e-04 - val_accuracy: 0.9221 - val_loss: 0.5914\n",
      "Epoch 499/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.8408e-04 - val_accuracy: 0.9221 - val_loss: 0.5913\n",
      "Epoch 500/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.9355e-04 - val_accuracy: 0.9221 - val_loss: 0.5911\n",
      "Epoch 501/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.9711e-04 - val_accuracy: 0.9221 - val_loss: 0.5908\n",
      "Epoch 502/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.9735e-04 - val_accuracy: 0.9221 - val_loss: 0.5906\n",
      "Epoch 503/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.4321e-04 - val_accuracy: 0.9223 - val_loss: 0.5906\n",
      "Epoch 504/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.0634e-04 - val_accuracy: 0.9224 - val_loss: 0.5903\n",
      "Epoch 505/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.4852e-04 - val_accuracy: 0.9223 - val_loss: 0.5901\n",
      "Epoch 506/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.5776e-04 - val_accuracy: 0.9225 - val_loss: 0.5900\n",
      "Epoch 507/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.4703e-04 - val_accuracy: 0.9226 - val_loss: 0.5899\n",
      "Epoch 508/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.9783e-04 - val_accuracy: 0.9226 - val_loss: 0.5897\n",
      "Epoch 509/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.0431e-04 - val_accuracy: 0.9226 - val_loss: 0.5897\n",
      "Epoch 510/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.0784e-04 - val_accuracy: 0.9227 - val_loss: 0.5894\n",
      "Epoch 511/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.4244e-04 - val_accuracy: 0.9227 - val_loss: 0.5894\n",
      "Epoch 512/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.7070e-04 - val_accuracy: 0.9227 - val_loss: 0.5894\n",
      "Epoch 513/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.9039e-04 - val_accuracy: 0.9229 - val_loss: 0.5892\n",
      "Epoch 514/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.4564e-04 - val_accuracy: 0.9228 - val_loss: 0.5889\n",
      "Epoch 515/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5693e-04 - val_accuracy: 0.9230 - val_loss: 0.5890\n",
      "Epoch 516/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.8553e-04 - val_accuracy: 0.9229 - val_loss: 0.5886\n",
      "Epoch 517/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.7178e-04 - val_accuracy: 0.9230 - val_loss: 0.5886\n",
      "Epoch 518/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.1791e-04 - val_accuracy: 0.9230 - val_loss: 0.5883\n",
      "Epoch 519/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.4868e-04 - val_accuracy: 0.9230 - val_loss: 0.5881\n",
      "Epoch 520/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.0641e-04 - val_accuracy: 0.9230 - val_loss: 0.5879\n",
      "Epoch 521/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.3155e-04 - val_accuracy: 0.9230 - val_loss: 0.5878\n",
      "Epoch 522/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.7238e-04 - val_accuracy: 0.9230 - val_loss: 0.5876\n",
      "Epoch 523/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.2569e-04 - val_accuracy: 0.9230 - val_loss: 0.5874\n",
      "Epoch 524/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.0119e-04 - val_accuracy: 0.9231 - val_loss: 0.5873\n",
      "Epoch 525/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4606e-04 - val_accuracy: 0.9231 - val_loss: 0.5871\n",
      "Epoch 526/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.0944e-04 - val_accuracy: 0.9231 - val_loss: 0.5869\n",
      "Epoch 527/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.1638e-04 - val_accuracy: 0.9231 - val_loss: 0.5867\n",
      "Epoch 528/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.1614e-04 - val_accuracy: 0.9231 - val_loss: 0.5863\n",
      "Epoch 529/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9637e-04 - val_accuracy: 0.9232 - val_loss: 0.5862\n",
      "Epoch 530/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.6024e-04 - val_accuracy: 0.9233 - val_loss: 0.5862\n",
      "Epoch 531/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.9208e-04 - val_accuracy: 0.9233 - val_loss: 0.5861\n",
      "Epoch 532/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2767e-04 - val_accuracy: 0.9233 - val_loss: 0.5860\n",
      "Epoch 533/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.8787e-04 - val_accuracy: 0.9233 - val_loss: 0.5858\n",
      "Epoch 534/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.2205e-04 - val_accuracy: 0.9235 - val_loss: 0.5857\n",
      "Epoch 535/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0935e-04 - val_accuracy: 0.9235 - val_loss: 0.5856\n",
      "Epoch 536/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2541e-04 - val_accuracy: 0.9237 - val_loss: 0.5854\n",
      "Epoch 537/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5195e-04 - val_accuracy: 0.9237 - val_loss: 0.5851\n",
      "Epoch 538/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5796e-04 - val_accuracy: 0.9236 - val_loss: 0.5849\n",
      "Epoch 539/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.2572e-04 - val_accuracy: 0.9238 - val_loss: 0.5848\n",
      "Epoch 540/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.3663e-04 - val_accuracy: 0.9237 - val_loss: 0.5848\n",
      "Epoch 541/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5382e-04 - val_accuracy: 0.9238 - val_loss: 0.5846\n",
      "Epoch 542/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.8883e-04 - val_accuracy: 0.9239 - val_loss: 0.5845\n",
      "Epoch 543/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.1582e-04 - val_accuracy: 0.9239 - val_loss: 0.5843\n",
      "Epoch 544/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.3406e-04 - val_accuracy: 0.9240 - val_loss: 0.5841\n",
      "Epoch 545/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.6512e-04 - val_accuracy: 0.9240 - val_loss: 0.5838\n",
      "Epoch 546/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2549e-04 - val_accuracy: 0.9240 - val_loss: 0.5839\n",
      "Epoch 547/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1695e-04 - val_accuracy: 0.9240 - val_loss: 0.5837\n",
      "Epoch 548/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.0270e-04 - val_accuracy: 0.9241 - val_loss: 0.5836\n",
      "Epoch 549/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.3507e-04 - val_accuracy: 0.9241 - val_loss: 0.5835\n",
      "Epoch 550/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.7704e-04 - val_accuracy: 0.9241 - val_loss: 0.5832\n",
      "Epoch 551/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5439e-04 - val_accuracy: 0.9241 - val_loss: 0.5832\n",
      "Epoch 552/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.6314e-04 - val_accuracy: 0.9242 - val_loss: 0.5831\n",
      "Epoch 553/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.7979e-04 - val_accuracy: 0.9241 - val_loss: 0.5829\n",
      "Epoch 554/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9026e-04 - val_accuracy: 0.9240 - val_loss: 0.5828\n",
      "Epoch 555/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2944e-04 - val_accuracy: 0.9239 - val_loss: 0.5827\n",
      "Epoch 556/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.2729e-04 - val_accuracy: 0.9241 - val_loss: 0.5826\n",
      "Epoch 557/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1655e-04 - val_accuracy: 0.9243 - val_loss: 0.5823\n",
      "Epoch 558/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.5079e-04 - val_accuracy: 0.9242 - val_loss: 0.5823\n",
      "Epoch 559/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1466e-04 - val_accuracy: 0.9241 - val_loss: 0.5822\n",
      "Epoch 560/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.9818e-04 - val_accuracy: 0.9242 - val_loss: 0.5820\n",
      "Epoch 561/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4790e-04 - val_accuracy: 0.9242 - val_loss: 0.5818\n",
      "Epoch 562/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.3587e-04 - val_accuracy: 0.9242 - val_loss: 0.5816\n",
      "Epoch 563/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9298e-04 - val_accuracy: 0.9242 - val_loss: 0.5814\n",
      "Epoch 564/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7095e-04 - val_accuracy: 0.9242 - val_loss: 0.5814\n",
      "Epoch 565/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.2294e-04 - val_accuracy: 0.9242 - val_loss: 0.5814\n",
      "Epoch 566/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.6497e-04 - val_accuracy: 0.9242 - val_loss: 0.5812\n",
      "Epoch 567/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.5203e-04 - val_accuracy: 0.9242 - val_loss: 0.5811\n",
      "Epoch 568/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3003e-04 - val_accuracy: 0.9242 - val_loss: 0.5809\n",
      "Epoch 569/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9569e-04 - val_accuracy: 0.9242 - val_loss: 0.5808\n",
      "Epoch 570/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7112e-04 - val_accuracy: 0.9242 - val_loss: 0.5806\n",
      "Epoch 571/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.0617e-04 - val_accuracy: 0.9242 - val_loss: 0.5804\n",
      "Epoch 572/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.6328e-04 - val_accuracy: 0.9243 - val_loss: 0.5802\n",
      "Epoch 573/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.6453e-04 - val_accuracy: 0.9242 - val_loss: 0.5799\n",
      "Epoch 574/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.6701e-04 - val_accuracy: 0.9244 - val_loss: 0.5797\n",
      "Epoch 575/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8099e-04 - val_accuracy: 0.9246 - val_loss: 0.5797\n",
      "Epoch 576/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7487e-04 - val_accuracy: 0.9246 - val_loss: 0.5797\n",
      "Epoch 577/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.0051e-04 - val_accuracy: 0.9246 - val_loss: 0.5795\n",
      "Epoch 578/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.7591e-04 - val_accuracy: 0.9246 - val_loss: 0.5793\n",
      "Epoch 579/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2087e-04 - val_accuracy: 0.9246 - val_loss: 0.5791\n",
      "Epoch 580/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.5972e-04 - val_accuracy: 0.9246 - val_loss: 0.5791\n",
      "Epoch 581/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.5218e-04 - val_accuracy: 0.9249 - val_loss: 0.5790\n",
      "Epoch 582/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.8114e-04 - val_accuracy: 0.9250 - val_loss: 0.5789\n",
      "Epoch 583/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.8841e-04 - val_accuracy: 0.9251 - val_loss: 0.5787\n",
      "Epoch 584/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7528e-04 - val_accuracy: 0.9251 - val_loss: 0.5786\n",
      "Epoch 585/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1143e-04 - val_accuracy: 0.9252 - val_loss: 0.5784\n",
      "Epoch 586/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7649e-04 - val_accuracy: 0.9252 - val_loss: 0.5783\n",
      "Epoch 587/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8281e-04 - val_accuracy: 0.9252 - val_loss: 0.5782\n",
      "Epoch 588/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.5955e-04 - val_accuracy: 0.9252 - val_loss: 0.5780\n",
      "Epoch 589/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.1238e-04 - val_accuracy: 0.9254 - val_loss: 0.5778\n",
      "Epoch 590/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3618e-04 - val_accuracy: 0.9254 - val_loss: 0.5778\n",
      "Epoch 591/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1892e-04 - val_accuracy: 0.9255 - val_loss: 0.5776\n",
      "Epoch 592/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7153e-04 - val_accuracy: 0.9257 - val_loss: 0.5775\n",
      "Epoch 593/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.1544e-04 - val_accuracy: 0.9257 - val_loss: 0.5773\n",
      "Epoch 594/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5063e-04 - val_accuracy: 0.9257 - val_loss: 0.5771\n",
      "Epoch 595/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0272e-04 - val_accuracy: 0.9258 - val_loss: 0.5771\n",
      "Epoch 596/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3340e-04 - val_accuracy: 0.9258 - val_loss: 0.5769\n",
      "Epoch 597/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7680e-04 - val_accuracy: 0.9258 - val_loss: 0.5767\n",
      "Epoch 598/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7047e-04 - val_accuracy: 0.9258 - val_loss: 0.5767\n",
      "Epoch 599/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7280e-04 - val_accuracy: 0.9258 - val_loss: 0.5765\n",
      "Epoch 600/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.5767e-04 - val_accuracy: 0.9257 - val_loss: 0.5763\n",
      "Epoch 601/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8353e-04 - val_accuracy: 0.9257 - val_loss: 0.5764\n",
      "Epoch 602/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.1346e-04 - val_accuracy: 0.9257 - val_loss: 0.5761\n",
      "Epoch 603/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.5176e-04 - val_accuracy: 0.9258 - val_loss: 0.5760\n",
      "Epoch 604/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.5533e-04 - val_accuracy: 0.9257 - val_loss: 0.5757\n",
      "Epoch 605/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.6272e-04 - val_accuracy: 0.9259 - val_loss: 0.5757\n",
      "Epoch 606/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.6443e-04 - val_accuracy: 0.9260 - val_loss: 0.5755\n",
      "Epoch 607/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5365e-04 - val_accuracy: 0.9262 - val_loss: 0.5753\n",
      "Epoch 608/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.7186e-04 - val_accuracy: 0.9262 - val_loss: 0.5752\n",
      "Epoch 609/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6762e-04 - val_accuracy: 0.9262 - val_loss: 0.5749\n",
      "Epoch 610/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.6189e-04 - val_accuracy: 0.9262 - val_loss: 0.5747\n",
      "Epoch 611/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0169e-04 - val_accuracy: 0.9262 - val_loss: 0.5746\n",
      "Epoch 612/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4963e-04 - val_accuracy: 0.9262 - val_loss: 0.5744\n",
      "Epoch 613/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9528e-04 - val_accuracy: 0.9260 - val_loss: 0.5745\n",
      "Epoch 614/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.9015e-04 - val_accuracy: 0.9260 - val_loss: 0.5743\n",
      "Epoch 615/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9687e-04 - val_accuracy: 0.9260 - val_loss: 0.5741\n",
      "Epoch 616/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7016e-04 - val_accuracy: 0.9260 - val_loss: 0.5739\n",
      "Epoch 617/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.1293e-04 - val_accuracy: 0.9260 - val_loss: 0.5737\n",
      "Epoch 618/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.6196e-04 - val_accuracy: 0.9260 - val_loss: 0.5737\n",
      "Epoch 619/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6583e-04 - val_accuracy: 0.9260 - val_loss: 0.5736\n",
      "Epoch 620/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.6781e-04 - val_accuracy: 0.9260 - val_loss: 0.5733\n",
      "Epoch 621/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8143e-04 - val_accuracy: 0.9260 - val_loss: 0.5732\n",
      "Epoch 622/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.1689e-04 - val_accuracy: 0.9260 - val_loss: 0.5731\n",
      "Epoch 623/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2365e-04 - val_accuracy: 0.9262 - val_loss: 0.5731\n",
      "Epoch 624/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.6587e-04 - val_accuracy: 0.9262 - val_loss: 0.5728\n",
      "Epoch 625/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9311e-04 - val_accuracy: 0.9262 - val_loss: 0.5728\n",
      "Epoch 626/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.3604e-04 - val_accuracy: 0.9262 - val_loss: 0.5726\n",
      "Epoch 627/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.3218e-04 - val_accuracy: 0.9262 - val_loss: 0.5725\n",
      "Epoch 628/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8953e-04 - val_accuracy: 0.9262 - val_loss: 0.5725\n",
      "Epoch 629/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5062e-04 - val_accuracy: 0.9262 - val_loss: 0.5723\n",
      "Epoch 630/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.1939e-04 - val_accuracy: 0.9262 - val_loss: 0.5723\n",
      "Epoch 631/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5783e-04 - val_accuracy: 0.9262 - val_loss: 0.5721\n",
      "Epoch 632/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.5442e-04 - val_accuracy: 0.9262 - val_loss: 0.5719\n",
      "Epoch 633/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.6826e-04 - val_accuracy: 0.9262 - val_loss: 0.5718\n",
      "Epoch 634/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4095e-04 - val_accuracy: 0.9262 - val_loss: 0.5718\n",
      "Epoch 635/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4761e-04 - val_accuracy: 0.9263 - val_loss: 0.5716\n",
      "Epoch 636/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4641e-04 - val_accuracy: 0.9262 - val_loss: 0.5716\n",
      "Epoch 637/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2598e-04 - val_accuracy: 0.9262 - val_loss: 0.5714\n",
      "Epoch 638/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4447e-04 - val_accuracy: 0.9260 - val_loss: 0.5714\n",
      "Epoch 639/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7694e-04 - val_accuracy: 0.9262 - val_loss: 0.5713\n",
      "Epoch 640/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7187e-04 - val_accuracy: 0.9262 - val_loss: 0.5711\n",
      "Epoch 641/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.3868e-04 - val_accuracy: 0.9262 - val_loss: 0.5710\n",
      "Epoch 642/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8844e-04 - val_accuracy: 0.9262 - val_loss: 0.5709\n",
      "Epoch 643/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7073e-04 - val_accuracy: 0.9262 - val_loss: 0.5708\n",
      "Epoch 644/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7554e-04 - val_accuracy: 0.9263 - val_loss: 0.5707\n",
      "Epoch 645/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1326e-04 - val_accuracy: 0.9264 - val_loss: 0.5706\n",
      "Epoch 646/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8317e-04 - val_accuracy: 0.9264 - val_loss: 0.5705\n",
      "Epoch 647/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5521e-04 - val_accuracy: 0.9264 - val_loss: 0.5703\n",
      "Epoch 648/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0060e-04 - val_accuracy: 0.9264 - val_loss: 0.5701\n",
      "Epoch 649/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.4999e-04 - val_accuracy: 0.9264 - val_loss: 0.5699\n",
      "Epoch 650/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4446e-04 - val_accuracy: 0.9265 - val_loss: 0.5699\n",
      "Epoch 651/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8388e-04 - val_accuracy: 0.9264 - val_loss: 0.5699\n",
      "Epoch 652/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.5151e-04 - val_accuracy: 0.9265 - val_loss: 0.5698\n",
      "Epoch 653/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7273e-04 - val_accuracy: 0.9265 - val_loss: 0.5697\n",
      "Epoch 654/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6563e-04 - val_accuracy: 0.9265 - val_loss: 0.5695\n",
      "Epoch 655/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9942e-04 - val_accuracy: 0.9265 - val_loss: 0.5693\n",
      "Epoch 656/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4062e-04 - val_accuracy: 0.9265 - val_loss: 0.5690\n",
      "Epoch 657/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7587e-04 - val_accuracy: 0.9265 - val_loss: 0.5691\n",
      "Epoch 658/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1211e-04 - val_accuracy: 0.9265 - val_loss: 0.5690\n",
      "Epoch 659/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9280e-04 - val_accuracy: 0.9265 - val_loss: 0.5689\n",
      "Epoch 660/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.8552e-04 - val_accuracy: 0.9265 - val_loss: 0.5687\n",
      "Epoch 661/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1624e-04 - val_accuracy: 0.9265 - val_loss: 0.5686\n",
      "Epoch 662/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9930e-04 - val_accuracy: 0.9266 - val_loss: 0.5686\n",
      "Epoch 663/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.6204e-04 - val_accuracy: 0.9265 - val_loss: 0.5684\n",
      "Epoch 664/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4309e-04 - val_accuracy: 0.9265 - val_loss: 0.5683\n",
      "Epoch 665/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7629e-04 - val_accuracy: 0.9265 - val_loss: 0.5682\n",
      "Epoch 666/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9497e-04 - val_accuracy: 0.9265 - val_loss: 0.5680\n",
      "Epoch 667/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8158e-04 - val_accuracy: 0.9265 - val_loss: 0.5678\n",
      "Epoch 668/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2593e-04 - val_accuracy: 0.9265 - val_loss: 0.5676\n",
      "Epoch 669/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9543e-04 - val_accuracy: 0.9265 - val_loss: 0.5673\n",
      "Epoch 670/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6131e-04 - val_accuracy: 0.9265 - val_loss: 0.5670\n",
      "Epoch 671/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6607e-04 - val_accuracy: 0.9265 - val_loss: 0.5671\n",
      "Epoch 672/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6845e-04 - val_accuracy: 0.9265 - val_loss: 0.5670\n",
      "Epoch 673/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.1679e-04 - val_accuracy: 0.9265 - val_loss: 0.5669\n",
      "Epoch 674/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7378e-04 - val_accuracy: 0.9265 - val_loss: 0.5667\n",
      "Epoch 675/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7552e-04 - val_accuracy: 0.9265 - val_loss: 0.5667\n",
      "Epoch 676/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9609e-04 - val_accuracy: 0.9265 - val_loss: 0.5666\n",
      "Epoch 677/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1846e-04 - val_accuracy: 0.9265 - val_loss: 0.5665\n",
      "Epoch 678/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6722e-04 - val_accuracy: 0.9265 - val_loss: 0.5663\n",
      "Epoch 679/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.0249e-04 - val_accuracy: 0.9266 - val_loss: 0.5662\n",
      "Epoch 680/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.5350e-04 - val_accuracy: 0.9266 - val_loss: 0.5662\n",
      "Epoch 681/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9734e-04 - val_accuracy: 0.9267 - val_loss: 0.5661\n",
      "Epoch 682/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9754e-04 - val_accuracy: 0.9267 - val_loss: 0.5659\n",
      "Epoch 683/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7413e-04 - val_accuracy: 0.9267 - val_loss: 0.5657\n",
      "Epoch 684/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6004e-04 - val_accuracy: 0.9268 - val_loss: 0.5655\n",
      "Epoch 685/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8137e-04 - val_accuracy: 0.9266 - val_loss: 0.5654\n",
      "Epoch 686/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4105e-04 - val_accuracy: 0.9266 - val_loss: 0.5653\n",
      "Epoch 687/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4702e-04 - val_accuracy: 0.9267 - val_loss: 0.5652\n",
      "Epoch 688/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.4104e-04 - val_accuracy: 0.9268 - val_loss: 0.5651\n",
      "Epoch 689/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5079e-04 - val_accuracy: 0.9268 - val_loss: 0.5649\n",
      "Epoch 690/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6483e-04 - val_accuracy: 0.9268 - val_loss: 0.5649\n",
      "Epoch 691/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.3752e-04 - val_accuracy: 0.9270 - val_loss: 0.5649\n",
      "Epoch 692/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0193e-04 - val_accuracy: 0.9271 - val_loss: 0.5647\n",
      "Epoch 693/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4111e-04 - val_accuracy: 0.9271 - val_loss: 0.5645\n",
      "Epoch 694/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4524e-04 - val_accuracy: 0.9271 - val_loss: 0.5645\n",
      "Epoch 695/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.0470e-04 - val_accuracy: 0.9272 - val_loss: 0.5644\n",
      "Epoch 696/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7283e-04 - val_accuracy: 0.9272 - val_loss: 0.5643\n",
      "Epoch 697/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7518e-04 - val_accuracy: 0.9272 - val_loss: 0.5644\n",
      "Epoch 698/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.0356e-04 - val_accuracy: 0.9272 - val_loss: 0.5639\n",
      "Epoch 699/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0914e-04 - val_accuracy: 0.9272 - val_loss: 0.5638\n",
      "Epoch 700/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5202e-04 - val_accuracy: 0.9272 - val_loss: 0.5637\n",
      "Epoch 701/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2020e-04 - val_accuracy: 0.9274 - val_loss: 0.5634\n",
      "Epoch 702/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.0449e-04 - val_accuracy: 0.9274 - val_loss: 0.5634\n",
      "Epoch 703/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.5809e-04 - val_accuracy: 0.9274 - val_loss: 0.5632\n",
      "Epoch 704/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.3277e-04 - val_accuracy: 0.9274 - val_loss: 0.5631\n",
      "Epoch 705/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.6265e-04 - val_accuracy: 0.9274 - val_loss: 0.5632\n",
      "Epoch 706/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.9521e-04 - val_accuracy: 0.9274 - val_loss: 0.5630\n",
      "Epoch 707/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.3636e-04 - val_accuracy: 0.9274 - val_loss: 0.5628\n",
      "Epoch 708/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9485e-04 - val_accuracy: 0.9274 - val_loss: 0.5627\n",
      "Epoch 709/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.1825e-04 - val_accuracy: 0.9274 - val_loss: 0.5627\n",
      "Epoch 710/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.2822e-04 - val_accuracy: 0.9274 - val_loss: 0.5628\n",
      "Epoch 711/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.0941e-04 - val_accuracy: 0.9274 - val_loss: 0.5625\n",
      "Epoch 712/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1104e-04 - val_accuracy: 0.9275 - val_loss: 0.5623\n",
      "Epoch 713/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6605e-04 - val_accuracy: 0.9274 - val_loss: 0.5621\n",
      "Epoch 714/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5905e-04 - val_accuracy: 0.9274 - val_loss: 0.5620\n",
      "Epoch 715/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2078e-04 - val_accuracy: 0.9274 - val_loss: 0.5617\n",
      "Epoch 716/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.8005e-04 - val_accuracy: 0.9274 - val_loss: 0.5616\n",
      "Epoch 717/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.5362e-04 - val_accuracy: 0.9275 - val_loss: 0.5615\n",
      "Epoch 718/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6831e-04 - val_accuracy: 0.9275 - val_loss: 0.5612\n",
      "Epoch 719/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9813e-04 - val_accuracy: 0.9276 - val_loss: 0.5611\n",
      "Epoch 720/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0058e-04 - val_accuracy: 0.9276 - val_loss: 0.5611\n",
      "Epoch 721/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.9436e-04 - val_accuracy: 0.9276 - val_loss: 0.5610\n",
      "Epoch 722/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8389e-04 - val_accuracy: 0.9277 - val_loss: 0.5608\n",
      "Epoch 723/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.9164e-04 - val_accuracy: 0.9277 - val_loss: 0.5608\n",
      "Epoch 724/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.4466e-04 - val_accuracy: 0.9277 - val_loss: 0.5607\n",
      "Epoch 725/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2108e-04 - val_accuracy: 0.9278 - val_loss: 0.5607\n",
      "Epoch 726/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6750e-04 - val_accuracy: 0.9279 - val_loss: 0.5606\n",
      "Epoch 727/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7474e-04 - val_accuracy: 0.9279 - val_loss: 0.5603\n",
      "Epoch 728/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.1275e-04 - val_accuracy: 0.9278 - val_loss: 0.5604\n",
      "Epoch 729/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8275e-04 - val_accuracy: 0.9278 - val_loss: 0.5603\n",
      "Epoch 730/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.9019e-04 - val_accuracy: 0.9278 - val_loss: 0.5603\n",
      "Epoch 731/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0489e-04 - val_accuracy: 0.9278 - val_loss: 0.5602\n",
      "Epoch 732/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.5979e-04 - val_accuracy: 0.9279 - val_loss: 0.5599\n",
      "Epoch 733/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.3462e-04 - val_accuracy: 0.9279 - val_loss: 0.5598\n",
      "Epoch 734/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7956e-04 - val_accuracy: 0.9279 - val_loss: 0.5597\n",
      "Epoch 735/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2368e-04 - val_accuracy: 0.9278 - val_loss: 0.5598\n",
      "Epoch 736/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9262e-04 - val_accuracy: 0.9279 - val_loss: 0.5597\n",
      "Epoch 737/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2241e-04 - val_accuracy: 0.9279 - val_loss: 0.5595\n",
      "Epoch 738/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.3788e-04 - val_accuracy: 0.9280 - val_loss: 0.5593\n",
      "Epoch 739/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2083e-04 - val_accuracy: 0.9280 - val_loss: 0.5592\n",
      "Epoch 740/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8395e-04 - val_accuracy: 0.9280 - val_loss: 0.5590\n",
      "Epoch 741/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7398e-04 - val_accuracy: 0.9279 - val_loss: 0.5589\n",
      "Epoch 742/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4840e-04 - val_accuracy: 0.9280 - val_loss: 0.5589\n",
      "Epoch 743/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8340e-04 - val_accuracy: 0.9280 - val_loss: 0.5588\n",
      "Epoch 744/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6555e-04 - val_accuracy: 0.9279 - val_loss: 0.5588\n",
      "Epoch 745/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.4069e-04 - val_accuracy: 0.9280 - val_loss: 0.5585\n",
      "Epoch 746/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.5720e-04 - val_accuracy: 0.9279 - val_loss: 0.5585\n",
      "Epoch 747/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9591e-04 - val_accuracy: 0.9279 - val_loss: 0.5583\n",
      "Epoch 748/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1980e-04 - val_accuracy: 0.9279 - val_loss: 0.5583\n",
      "Epoch 749/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4932e-04 - val_accuracy: 0.9279 - val_loss: 0.5582\n",
      "Epoch 750/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4334e-04 - val_accuracy: 0.9279 - val_loss: 0.5581\n",
      "Epoch 751/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7782e-04 - val_accuracy: 0.9279 - val_loss: 0.5580\n",
      "Epoch 752/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5940e-04 - val_accuracy: 0.9280 - val_loss: 0.5578\n",
      "Epoch 753/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5745e-04 - val_accuracy: 0.9280 - val_loss: 0.5577\n",
      "Epoch 754/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3637e-04 - val_accuracy: 0.9280 - val_loss: 0.5577\n",
      "Epoch 755/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3886e-04 - val_accuracy: 0.9281 - val_loss: 0.5576\n",
      "Epoch 756/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7478e-04 - val_accuracy: 0.9281 - val_loss: 0.5574\n",
      "Epoch 757/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9662e-04 - val_accuracy: 0.9281 - val_loss: 0.5573\n",
      "Epoch 758/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7020e-04 - val_accuracy: 0.9280 - val_loss: 0.5573\n",
      "Epoch 759/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7244e-04 - val_accuracy: 0.9280 - val_loss: 0.5572\n",
      "Epoch 760/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8235e-04 - val_accuracy: 0.9280 - val_loss: 0.5571\n",
      "Epoch 761/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5575e-04 - val_accuracy: 0.9280 - val_loss: 0.5571\n",
      "Epoch 762/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5281e-04 - val_accuracy: 0.9281 - val_loss: 0.5569\n",
      "Epoch 763/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1199e-04 - val_accuracy: 0.9281 - val_loss: 0.5568\n",
      "Epoch 764/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3476e-04 - val_accuracy: 0.9281 - val_loss: 0.5567\n",
      "Epoch 765/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4585e-04 - val_accuracy: 0.9281 - val_loss: 0.5566\n",
      "Epoch 766/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6370e-04 - val_accuracy: 0.9283 - val_loss: 0.5564\n",
      "Epoch 767/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7391e-04 - val_accuracy: 0.9284 - val_loss: 0.5563\n",
      "Epoch 768/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3436e-04 - val_accuracy: 0.9285 - val_loss: 0.5561\n",
      "Epoch 769/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6247e-04 - val_accuracy: 0.9285 - val_loss: 0.5561\n",
      "Epoch 770/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6191e-04 - val_accuracy: 0.9285 - val_loss: 0.5558\n",
      "Epoch 771/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7361e-04 - val_accuracy: 0.9285 - val_loss: 0.5556\n",
      "Epoch 772/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6331e-04 - val_accuracy: 0.9286 - val_loss: 0.5555\n",
      "Epoch 773/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3147e-04 - val_accuracy: 0.9287 - val_loss: 0.5555\n",
      "Epoch 774/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8933e-04 - val_accuracy: 0.9287 - val_loss: 0.5554\n",
      "Epoch 775/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.4208e-04 - val_accuracy: 0.9286 - val_loss: 0.5551\n",
      "Epoch 776/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6535e-04 - val_accuracy: 0.9289 - val_loss: 0.5550\n",
      "Epoch 777/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.5778e-04 - val_accuracy: 0.9287 - val_loss: 0.5548\n",
      "Epoch 778/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6385e-04 - val_accuracy: 0.9289 - val_loss: 0.5546\n",
      "Epoch 779/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6358e-04 - val_accuracy: 0.9290 - val_loss: 0.5545\n",
      "Epoch 780/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.5348e-04 - val_accuracy: 0.9290 - val_loss: 0.5544\n",
      "Epoch 781/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1822e-04 - val_accuracy: 0.9290 - val_loss: 0.5543\n",
      "Epoch 782/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.4716e-04 - val_accuracy: 0.9291 - val_loss: 0.5543\n",
      "Epoch 783/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.4157e-04 - val_accuracy: 0.9291 - val_loss: 0.5542\n",
      "Epoch 784/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6355e-04 - val_accuracy: 0.9291 - val_loss: 0.5542\n",
      "Epoch 785/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8767e-04 - val_accuracy: 0.9291 - val_loss: 0.5542\n",
      "Epoch 786/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5403e-04 - val_accuracy: 0.9292 - val_loss: 0.5540\n",
      "Epoch 787/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.4032e-04 - val_accuracy: 0.9292 - val_loss: 0.5539\n",
      "Epoch 788/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8766e-04 - val_accuracy: 0.9293 - val_loss: 0.5538\n",
      "Epoch 789/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3907e-04 - val_accuracy: 0.9289 - val_loss: 0.5538\n",
      "Epoch 790/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9890e-04 - val_accuracy: 0.9292 - val_loss: 0.5538\n",
      "Epoch 791/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2120e-04 - val_accuracy: 0.9291 - val_loss: 0.5536\n",
      "Epoch 792/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1992e-04 - val_accuracy: 0.9292 - val_loss: 0.5537\n",
      "Epoch 793/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0868e-04 - val_accuracy: 0.9291 - val_loss: 0.5535\n",
      "Epoch 794/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2618e-04 - val_accuracy: 0.9293 - val_loss: 0.5534\n",
      "Epoch 795/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1705e-04 - val_accuracy: 0.9293 - val_loss: 0.5534\n",
      "Epoch 796/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0817e-04 - val_accuracy: 0.9293 - val_loss: 0.5533\n",
      "Epoch 797/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3702e-04 - val_accuracy: 0.9293 - val_loss: 0.5530\n",
      "Epoch 798/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1764e-04 - val_accuracy: 0.9293 - val_loss: 0.5530\n",
      "Epoch 799/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9825e-04 - val_accuracy: 0.9293 - val_loss: 0.5529\n",
      "Epoch 800/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3830e-04 - val_accuracy: 0.9294 - val_loss: 0.5526\n",
      "Epoch 801/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0772e-04 - val_accuracy: 0.9296 - val_loss: 0.5525\n",
      "Epoch 802/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9412e-04 - val_accuracy: 0.9296 - val_loss: 0.5524\n",
      "Epoch 803/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.1587e-04 - val_accuracy: 0.9296 - val_loss: 0.5523\n",
      "Epoch 804/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2285e-04 - val_accuracy: 0.9298 - val_loss: 0.5523\n",
      "Epoch 805/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.5943e-04 - val_accuracy: 0.9297 - val_loss: 0.5523\n",
      "Epoch 806/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3535e-04 - val_accuracy: 0.9300 - val_loss: 0.5522\n",
      "Epoch 807/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7469e-04 - val_accuracy: 0.9300 - val_loss: 0.5520\n",
      "Epoch 808/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3326e-04 - val_accuracy: 0.9301 - val_loss: 0.5519\n",
      "Epoch 809/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9352e-04 - val_accuracy: 0.9301 - val_loss: 0.5519\n",
      "Epoch 810/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.0984e-04 - val_accuracy: 0.9302 - val_loss: 0.5517\n",
      "Epoch 811/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1851e-04 - val_accuracy: 0.9302 - val_loss: 0.5516\n",
      "Epoch 812/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1382e-04 - val_accuracy: 0.9302 - val_loss: 0.5516\n",
      "Epoch 813/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2439e-04 - val_accuracy: 0.9302 - val_loss: 0.5514\n",
      "Epoch 814/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2680e-04 - val_accuracy: 0.9301 - val_loss: 0.5514\n",
      "Epoch 815/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6291e-04 - val_accuracy: 0.9301 - val_loss: 0.5512\n",
      "Epoch 816/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8302e-04 - val_accuracy: 0.9301 - val_loss: 0.5512\n",
      "Epoch 817/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8394e-04 - val_accuracy: 0.9301 - val_loss: 0.5510\n",
      "Epoch 818/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2433e-04 - val_accuracy: 0.9302 - val_loss: 0.5511\n",
      "Epoch 819/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7884e-04 - val_accuracy: 0.9301 - val_loss: 0.5510\n",
      "Epoch 820/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3808e-04 - val_accuracy: 0.9302 - val_loss: 0.5508\n",
      "Epoch 821/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9676e-04 - val_accuracy: 0.9303 - val_loss: 0.5505\n",
      "Epoch 822/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8207e-04 - val_accuracy: 0.9304 - val_loss: 0.5503\n",
      "Epoch 823/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9658e-04 - val_accuracy: 0.9303 - val_loss: 0.5503\n",
      "Epoch 824/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1111e-04 - val_accuracy: 0.9304 - val_loss: 0.5501\n",
      "Epoch 825/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0569e-04 - val_accuracy: 0.9304 - val_loss: 0.5501\n",
      "Epoch 826/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1703e-04 - val_accuracy: 0.9305 - val_loss: 0.5499\n",
      "Epoch 827/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.0172e-04 - val_accuracy: 0.9306 - val_loss: 0.5500\n",
      "Epoch 828/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8794e-04 - val_accuracy: 0.9307 - val_loss: 0.5500\n",
      "Epoch 829/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.2198e-04 - val_accuracy: 0.9306 - val_loss: 0.5501\n",
      "Epoch 830/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7235e-04 - val_accuracy: 0.9307 - val_loss: 0.5499\n",
      "Epoch 831/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8316e-04 - val_accuracy: 0.9307 - val_loss: 0.5498\n",
      "Epoch 832/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9381e-04 - val_accuracy: 0.9306 - val_loss: 0.5496\n",
      "Epoch 833/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0399e-04 - val_accuracy: 0.9306 - val_loss: 0.5493\n",
      "Epoch 834/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.9008e-04 - val_accuracy: 0.9307 - val_loss: 0.5493\n",
      "Epoch 835/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8011e-04 - val_accuracy: 0.9307 - val_loss: 0.5494\n",
      "Epoch 836/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7062e-04 - val_accuracy: 0.9307 - val_loss: 0.5492\n",
      "Epoch 837/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9102e-04 - val_accuracy: 0.9307 - val_loss: 0.5491\n",
      "Epoch 838/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8712e-04 - val_accuracy: 0.9308 - val_loss: 0.5489\n",
      "Epoch 839/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0241e-04 - val_accuracy: 0.9307 - val_loss: 0.5487\n",
      "Epoch 840/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8719e-04 - val_accuracy: 0.9307 - val_loss: 0.5488\n",
      "Epoch 841/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1515e-04 - val_accuracy: 0.9307 - val_loss: 0.5486\n",
      "Epoch 842/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1947e-04 - val_accuracy: 0.9308 - val_loss: 0.5486\n",
      "Epoch 843/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8047e-04 - val_accuracy: 0.9308 - val_loss: 0.5485\n",
      "Epoch 844/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0161e-04 - val_accuracy: 0.9309 - val_loss: 0.5485\n",
      "Epoch 845/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0864e-04 - val_accuracy: 0.9309 - val_loss: 0.5484\n",
      "Epoch 846/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8905e-04 - val_accuracy: 0.9309 - val_loss: 0.5482\n",
      "Epoch 847/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8722e-04 - val_accuracy: 0.9309 - val_loss: 0.5482\n",
      "Epoch 848/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8921e-04 - val_accuracy: 0.9310 - val_loss: 0.5480\n",
      "Epoch 849/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7616e-04 - val_accuracy: 0.9310 - val_loss: 0.5481\n",
      "Epoch 850/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8940e-04 - val_accuracy: 0.9310 - val_loss: 0.5479\n",
      "Epoch 851/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0566e-04 - val_accuracy: 0.9311 - val_loss: 0.5479\n",
      "Epoch 852/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5411e-04 - val_accuracy: 0.9311 - val_loss: 0.5479\n",
      "Epoch 853/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.9180e-04 - val_accuracy: 0.9313 - val_loss: 0.5478\n",
      "Epoch 854/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9000e-04 - val_accuracy: 0.9314 - val_loss: 0.5476\n",
      "Epoch 855/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8272e-04 - val_accuracy: 0.9313 - val_loss: 0.5473\n",
      "Epoch 856/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.9769e-04 - val_accuracy: 0.9313 - val_loss: 0.5474\n",
      "Epoch 857/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7311e-04 - val_accuracy: 0.9314 - val_loss: 0.5473\n",
      "Epoch 858/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9207e-04 - val_accuracy: 0.9314 - val_loss: 0.5474\n",
      "Epoch 859/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9626e-04 - val_accuracy: 0.9314 - val_loss: 0.5472\n",
      "Epoch 860/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6920e-04 - val_accuracy: 0.9314 - val_loss: 0.5472\n",
      "Epoch 861/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8651e-04 - val_accuracy: 0.9314 - val_loss: 0.5472\n",
      "Epoch 862/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6875e-04 - val_accuracy: 0.9316 - val_loss: 0.5471\n",
      "Epoch 863/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7655e-04 - val_accuracy: 0.9314 - val_loss: 0.5468\n",
      "Epoch 864/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7109e-04 - val_accuracy: 0.9314 - val_loss: 0.5466\n",
      "Epoch 865/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6933e-04 - val_accuracy: 0.9316 - val_loss: 0.5465\n",
      "Epoch 866/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6940e-04 - val_accuracy: 0.9314 - val_loss: 0.5464\n",
      "Epoch 867/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7477e-04 - val_accuracy: 0.9316 - val_loss: 0.5464\n",
      "Epoch 868/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5043e-04 - val_accuracy: 0.9316 - val_loss: 0.5462\n",
      "Epoch 869/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5731e-04 - val_accuracy: 0.9316 - val_loss: 0.5460\n",
      "Epoch 870/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4102e-04 - val_accuracy: 0.9317 - val_loss: 0.5460\n",
      "Epoch 871/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6716e-04 - val_accuracy: 0.9317 - val_loss: 0.5457\n",
      "Epoch 872/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5301e-04 - val_accuracy: 0.9317 - val_loss: 0.5456\n",
      "Epoch 873/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7337e-04 - val_accuracy: 0.9318 - val_loss: 0.5455\n",
      "Epoch 874/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7039e-04 - val_accuracy: 0.9319 - val_loss: 0.5453\n",
      "Epoch 875/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5805e-04 - val_accuracy: 0.9318 - val_loss: 0.5452\n",
      "Epoch 876/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6300e-04 - val_accuracy: 0.9319 - val_loss: 0.5451\n",
      "Epoch 877/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7748e-04 - val_accuracy: 0.9319 - val_loss: 0.5450\n",
      "Epoch 878/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7298e-04 - val_accuracy: 0.9319 - val_loss: 0.5449\n",
      "Epoch 879/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5382e-04 - val_accuracy: 0.9319 - val_loss: 0.5447\n",
      "Epoch 880/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6680e-04 - val_accuracy: 0.9320 - val_loss: 0.5446\n",
      "Epoch 881/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5958e-04 - val_accuracy: 0.9320 - val_loss: 0.5447\n",
      "Epoch 882/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6002e-04 - val_accuracy: 0.9321 - val_loss: 0.5446\n",
      "Epoch 883/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5712e-04 - val_accuracy: 0.9320 - val_loss: 0.5444\n",
      "Epoch 884/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5146e-04 - val_accuracy: 0.9321 - val_loss: 0.5443\n",
      "Epoch 885/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5624e-04 - val_accuracy: 0.9321 - val_loss: 0.5443\n",
      "Epoch 886/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5549e-04 - val_accuracy: 0.9320 - val_loss: 0.5440\n",
      "Epoch 887/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3003e-04 - val_accuracy: 0.9321 - val_loss: 0.5439\n",
      "Epoch 888/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3703e-04 - val_accuracy: 0.9321 - val_loss: 0.5440\n",
      "Epoch 889/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5588e-04 - val_accuracy: 0.9322 - val_loss: 0.5439\n",
      "Epoch 890/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6581e-04 - val_accuracy: 0.9323 - val_loss: 0.5438\n",
      "Epoch 891/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5705e-04 - val_accuracy: 0.9323 - val_loss: 0.5437\n",
      "Epoch 892/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5750e-04 - val_accuracy: 0.9323 - val_loss: 0.5438\n",
      "Epoch 893/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5452e-04 - val_accuracy: 0.9323 - val_loss: 0.5437\n",
      "Epoch 894/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.3696e-04 - val_accuracy: 0.9323 - val_loss: 0.5436\n",
      "Epoch 895/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5172e-04 - val_accuracy: 0.9323 - val_loss: 0.5437\n",
      "Epoch 896/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5195e-04 - val_accuracy: 0.9323 - val_loss: 0.5436\n",
      "Epoch 897/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4907e-04 - val_accuracy: 0.9323 - val_loss: 0.5435\n",
      "Epoch 898/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2224e-04 - val_accuracy: 0.9323 - val_loss: 0.5433\n",
      "Epoch 899/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4474e-04 - val_accuracy: 0.9323 - val_loss: 0.5431\n",
      "Epoch 900/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8600e-04 - val_accuracy: 0.9323 - val_loss: 0.5431\n",
      "Epoch 901/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.5040e-04 - val_accuracy: 0.9323 - val_loss: 0.5431\n",
      "Epoch 902/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6725e-04 - val_accuracy: 0.9323 - val_loss: 0.5430\n",
      "Epoch 903/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5584e-04 - val_accuracy: 0.9323 - val_loss: 0.5429\n",
      "Epoch 904/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5043e-04 - val_accuracy: 0.9323 - val_loss: 0.5429\n",
      "Epoch 905/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4756e-04 - val_accuracy: 0.9323 - val_loss: 0.5428\n",
      "Epoch 906/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4576e-04 - val_accuracy: 0.9323 - val_loss: 0.5426\n",
      "Epoch 907/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6612e-04 - val_accuracy: 0.9323 - val_loss: 0.5425\n",
      "Epoch 908/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5327e-04 - val_accuracy: 0.9323 - val_loss: 0.5426\n",
      "Epoch 909/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4237e-04 - val_accuracy: 0.9323 - val_loss: 0.5424\n",
      "Epoch 910/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5339e-04 - val_accuracy: 0.9323 - val_loss: 0.5423\n",
      "Epoch 911/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5410e-04 - val_accuracy: 0.9323 - val_loss: 0.5421\n",
      "Epoch 912/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4958e-04 - val_accuracy: 0.9324 - val_loss: 0.5421\n",
      "Epoch 913/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3531e-04 - val_accuracy: 0.9323 - val_loss: 0.5421\n",
      "Epoch 914/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6211e-04 - val_accuracy: 0.9323 - val_loss: 0.5420\n",
      "Epoch 915/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2794e-04 - val_accuracy: 0.9323 - val_loss: 0.5419\n",
      "Epoch 916/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4203e-04 - val_accuracy: 0.9324 - val_loss: 0.5418\n",
      "Epoch 917/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4518e-04 - val_accuracy: 0.9324 - val_loss: 0.5418\n",
      "Epoch 918/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3306e-04 - val_accuracy: 0.9324 - val_loss: 0.5418\n",
      "Epoch 919/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5089e-04 - val_accuracy: 0.9324 - val_loss: 0.5416\n",
      "Epoch 920/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.3077e-04 - val_accuracy: 0.9325 - val_loss: 0.5414\n",
      "Epoch 921/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3685e-04 - val_accuracy: 0.9325 - val_loss: 0.5413\n",
      "Epoch 922/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4883e-04 - val_accuracy: 0.9324 - val_loss: 0.5412\n",
      "Epoch 923/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4316e-04 - val_accuracy: 0.9324 - val_loss: 0.5412\n",
      "Epoch 924/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2923e-04 - val_accuracy: 0.9324 - val_loss: 0.5410\n",
      "Epoch 925/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5379e-04 - val_accuracy: 0.9324 - val_loss: 0.5410\n",
      "Epoch 926/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3011e-04 - val_accuracy: 0.9325 - val_loss: 0.5408\n",
      "Epoch 927/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3227e-04 - val_accuracy: 0.9325 - val_loss: 0.5406\n",
      "Epoch 928/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2491e-04 - val_accuracy: 0.9326 - val_loss: 0.5405\n",
      "Epoch 929/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4146e-04 - val_accuracy: 0.9326 - val_loss: 0.5404\n",
      "Epoch 930/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2913e-04 - val_accuracy: 0.9326 - val_loss: 0.5402\n",
      "Epoch 931/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3174e-04 - val_accuracy: 0.9328 - val_loss: 0.5401\n",
      "Epoch 932/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4087e-04 - val_accuracy: 0.9327 - val_loss: 0.5399\n",
      "Epoch 933/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3555e-04 - val_accuracy: 0.9328 - val_loss: 0.5399\n",
      "Epoch 934/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4028e-04 - val_accuracy: 0.9327 - val_loss: 0.5399\n",
      "Epoch 935/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1155e-04 - val_accuracy: 0.9328 - val_loss: 0.5397\n",
      "Epoch 936/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3045e-04 - val_accuracy: 0.9328 - val_loss: 0.5396\n",
      "Epoch 937/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0891e-04 - val_accuracy: 0.9327 - val_loss: 0.5396\n",
      "Epoch 938/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.4367e-04 - val_accuracy: 0.9328 - val_loss: 0.5393\n",
      "Epoch 939/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2920e-04 - val_accuracy: 0.9328 - val_loss: 0.5392\n",
      "Epoch 940/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5046e-04 - val_accuracy: 0.9328 - val_loss: 0.5390\n",
      "Epoch 941/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1214e-04 - val_accuracy: 0.9329 - val_loss: 0.5391\n",
      "Epoch 942/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3922e-04 - val_accuracy: 0.9328 - val_loss: 0.5391\n",
      "Epoch 943/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1624e-04 - val_accuracy: 0.9328 - val_loss: 0.5391\n",
      "Epoch 944/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0431e-04 - val_accuracy: 0.9329 - val_loss: 0.5390\n",
      "Epoch 945/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4622e-04 - val_accuracy: 0.9329 - val_loss: 0.5388\n",
      "Epoch 946/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1699e-04 - val_accuracy: 0.9329 - val_loss: 0.5387\n",
      "Epoch 947/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3307e-04 - val_accuracy: 0.9329 - val_loss: 0.5386\n",
      "Epoch 948/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2183e-04 - val_accuracy: 0.9329 - val_loss: 0.5386\n",
      "Epoch 949/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.4562e-04 - val_accuracy: 0.9330 - val_loss: 0.5386\n",
      "Epoch 950/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3147e-04 - val_accuracy: 0.9331 - val_loss: 0.5385\n",
      "Epoch 951/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3698e-04 - val_accuracy: 0.9331 - val_loss: 0.5385\n",
      "Epoch 952/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1923e-04 - val_accuracy: 0.9331 - val_loss: 0.5383\n",
      "Epoch 953/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2141e-04 - val_accuracy: 0.9331 - val_loss: 0.5384\n",
      "Epoch 954/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4648e-04 - val_accuracy: 0.9331 - val_loss: 0.5383\n",
      "Epoch 955/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1050e-04 - val_accuracy: 0.9330 - val_loss: 0.5380\n",
      "Epoch 956/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0965e-04 - val_accuracy: 0.9331 - val_loss: 0.5380\n",
      "Epoch 957/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0796e-04 - val_accuracy: 0.9331 - val_loss: 0.5377\n",
      "Epoch 958/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0950e-04 - val_accuracy: 0.9332 - val_loss: 0.5376\n",
      "Epoch 959/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1078e-04 - val_accuracy: 0.9331 - val_loss: 0.5376\n",
      "Epoch 960/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2232e-04 - val_accuracy: 0.9331 - val_loss: 0.5375\n",
      "Epoch 961/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1300e-04 - val_accuracy: 0.9331 - val_loss: 0.5375\n",
      "Epoch 962/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1976e-04 - val_accuracy: 0.9331 - val_loss: 0.5375\n",
      "Epoch 963/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3522e-04 - val_accuracy: 0.9331 - val_loss: 0.5374\n",
      "Epoch 964/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2528e-04 - val_accuracy: 0.9331 - val_loss: 0.5371\n",
      "Epoch 965/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0053e-04 - val_accuracy: 0.9331 - val_loss: 0.5372\n",
      "Epoch 966/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2368e-04 - val_accuracy: 0.9331 - val_loss: 0.5370\n",
      "Epoch 967/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1232e-04 - val_accuracy: 0.9331 - val_loss: 0.5369\n",
      "Epoch 968/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2215e-04 - val_accuracy: 0.9331 - val_loss: 0.5367\n",
      "Epoch 969/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1651e-04 - val_accuracy: 0.9332 - val_loss: 0.5366\n",
      "Epoch 970/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.5862e-05 - val_accuracy: 0.9332 - val_loss: 0.5366\n",
      "Epoch 971/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1911e-04 - val_accuracy: 0.9332 - val_loss: 0.5366\n",
      "Epoch 972/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0700e-04 - val_accuracy: 0.9333 - val_loss: 0.5366\n",
      "Epoch 973/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.2614e-04 - val_accuracy: 0.9334 - val_loss: 0.5363\n",
      "Epoch 974/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1088e-04 - val_accuracy: 0.9334 - val_loss: 0.5363\n",
      "Epoch 975/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1038e-04 - val_accuracy: 0.9334 - val_loss: 0.5362\n",
      "Epoch 976/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.1111e-04 - val_accuracy: 0.9337 - val_loss: 0.5360\n",
      "Epoch 977/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2437e-04 - val_accuracy: 0.9337 - val_loss: 0.5362\n",
      "Epoch 978/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1752e-04 - val_accuracy: 0.9338 - val_loss: 0.5359\n",
      "Epoch 979/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1938e-04 - val_accuracy: 0.9338 - val_loss: 0.5358\n",
      "Epoch 980/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2203e-04 - val_accuracy: 0.9339 - val_loss: 0.5356\n",
      "Epoch 981/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.9560e-05 - val_accuracy: 0.9338 - val_loss: 0.5355\n",
      "Epoch 982/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0816e-04 - val_accuracy: 0.9338 - val_loss: 0.5355\n",
      "Epoch 983/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3193e-04 - val_accuracy: 0.9339 - val_loss: 0.5355\n",
      "Epoch 984/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1968e-04 - val_accuracy: 0.9340 - val_loss: 0.5356\n",
      "Epoch 985/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1595e-04 - val_accuracy: 0.9340 - val_loss: 0.5355\n",
      "Epoch 986/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0797e-04 - val_accuracy: 0.9339 - val_loss: 0.5355\n",
      "Epoch 987/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0081e-04 - val_accuracy: 0.9340 - val_loss: 0.5353\n",
      "Epoch 988/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0675e-04 - val_accuracy: 0.9340 - val_loss: 0.5353\n",
      "Epoch 989/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2057e-04 - val_accuracy: 0.9339 - val_loss: 0.5353\n",
      "Epoch 990/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2380e-04 - val_accuracy: 0.9339 - val_loss: 0.5352\n",
      "Epoch 991/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.0482e-04 - val_accuracy: 0.9339 - val_loss: 0.5351\n",
      "Epoch 992/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0244e-04 - val_accuracy: 0.9342 - val_loss: 0.5348\n",
      "Epoch 993/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.9832e-05 - val_accuracy: 0.9342 - val_loss: 0.5347\n",
      "Epoch 994/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.0976e-04 - val_accuracy: 0.9342 - val_loss: 0.5347\n",
      "Epoch 995/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0570e-04 - val_accuracy: 0.9342 - val_loss: 0.5347\n",
      "Epoch 996/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1037e-04 - val_accuracy: 0.9343 - val_loss: 0.5344\n",
      "Epoch 997/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0628e-04 - val_accuracy: 0.9344 - val_loss: 0.5344\n",
      "Epoch 998/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2479e-04 - val_accuracy: 0.9344 - val_loss: 0.5343\n",
      "Epoch 999/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.9724e-05 - val_accuracy: 0.9343 - val_loss: 0.5340\n",
      "Epoch 1000/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.3522e-05 - val_accuracy: 0.9344 - val_loss: 0.5340\n",
      "Epoch 1001/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1021e-04 - val_accuracy: 0.9344 - val_loss: 0.5339\n",
      "Epoch 1002/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0670e-04 - val_accuracy: 0.9344 - val_loss: 0.5339\n",
      "Epoch 1003/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.3884e-05 - val_accuracy: 0.9344 - val_loss: 0.5338\n",
      "Epoch 1004/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.2160e-05 - val_accuracy: 0.9344 - val_loss: 0.5336\n",
      "Epoch 1005/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0088e-04 - val_accuracy: 0.9344 - val_loss: 0.5335\n",
      "Epoch 1006/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0260e-04 - val_accuracy: 0.9344 - val_loss: 0.5335\n",
      "Epoch 1007/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0302e-04 - val_accuracy: 0.9346 - val_loss: 0.5332\n",
      "Epoch 1008/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0123e-04 - val_accuracy: 0.9346 - val_loss: 0.5331\n",
      "Epoch 1009/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0213e-04 - val_accuracy: 0.9346 - val_loss: 0.5331\n",
      "Epoch 1010/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0120e-04 - val_accuracy: 0.9346 - val_loss: 0.5331\n",
      "Epoch 1011/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0225e-04 - val_accuracy: 0.9347 - val_loss: 0.5329\n",
      "Epoch 1012/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0424e-04 - val_accuracy: 0.9347 - val_loss: 0.5328\n",
      "Epoch 1013/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.8263e-05 - val_accuracy: 0.9348 - val_loss: 0.5327\n",
      "Epoch 1014/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0568e-05 - val_accuracy: 0.9348 - val_loss: 0.5327\n",
      "Epoch 1015/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.9047e-05 - val_accuracy: 0.9348 - val_loss: 0.5326\n",
      "Epoch 1016/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.1528e-05 - val_accuracy: 0.9348 - val_loss: 0.5326\n",
      "Epoch 1017/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.1047e-05 - val_accuracy: 0.9348 - val_loss: 0.5327\n",
      "Epoch 1018/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0039e-04 - val_accuracy: 0.9348 - val_loss: 0.5326\n",
      "Epoch 1019/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.6811e-05 - val_accuracy: 0.9349 - val_loss: 0.5323\n",
      "Epoch 1020/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.6151e-05 - val_accuracy: 0.9349 - val_loss: 0.5324\n",
      "Epoch 1021/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0249e-04 - val_accuracy: 0.9349 - val_loss: 0.5322\n",
      "Epoch 1022/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.8894e-05 - val_accuracy: 0.9349 - val_loss: 0.5322\n",
      "Epoch 1023/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.8911e-05 - val_accuracy: 0.9349 - val_loss: 0.5321\n",
      "Epoch 1024/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0953e-04 - val_accuracy: 0.9349 - val_loss: 0.5321\n",
      "Epoch 1025/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.3969e-05 - val_accuracy: 0.9349 - val_loss: 0.5319\n",
      "Epoch 1026/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.1837e-05 - val_accuracy: 0.9349 - val_loss: 0.5319\n",
      "Epoch 1027/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.9353e-05 - val_accuracy: 0.9349 - val_loss: 0.5317\n",
      "Epoch 1028/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.9499e-05 - val_accuracy: 0.9350 - val_loss: 0.5317\n",
      "Epoch 1029/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.6673e-05 - val_accuracy: 0.9350 - val_loss: 0.5315\n",
      "Epoch 1030/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.2089e-05 - val_accuracy: 0.9350 - val_loss: 0.5316\n",
      "Epoch 1031/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7504e-05 - val_accuracy: 0.9350 - val_loss: 0.5315\n",
      "Epoch 1032/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.3776e-05 - val_accuracy: 0.9350 - val_loss: 0.5314\n",
      "Epoch 1033/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.1471e-05 - val_accuracy: 0.9350 - val_loss: 0.5312\n",
      "Epoch 1034/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.8788e-05 - val_accuracy: 0.9350 - val_loss: 0.5313\n",
      "Epoch 1035/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.0738e-05 - val_accuracy: 0.9350 - val_loss: 0.5312\n",
      "Epoch 1036/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0022e-05 - val_accuracy: 0.9350 - val_loss: 0.5312\n",
      "Epoch 1037/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.2933e-05 - val_accuracy: 0.9350 - val_loss: 0.5312\n",
      "Epoch 1038/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.8744e-05 - val_accuracy: 0.9350 - val_loss: 0.5310\n",
      "Epoch 1039/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0245e-05 - val_accuracy: 0.9350 - val_loss: 0.5309\n",
      "Epoch 1040/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.4427e-05 - val_accuracy: 0.9350 - val_loss: 0.5309\n",
      "Epoch 1041/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.2571e-05 - val_accuracy: 0.9351 - val_loss: 0.5307\n",
      "Epoch 1042/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.7594e-05 - val_accuracy: 0.9350 - val_loss: 0.5307\n",
      "Epoch 1043/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.8246e-05 - val_accuracy: 0.9352 - val_loss: 0.5306\n",
      "Epoch 1044/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0114e-04 - val_accuracy: 0.9352 - val_loss: 0.5304\n",
      "Epoch 1045/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0191e-05 - val_accuracy: 0.9352 - val_loss: 0.5303\n",
      "Epoch 1046/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.9768e-05 - val_accuracy: 0.9352 - val_loss: 0.5302\n",
      "Epoch 1047/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.9573e-05 - val_accuracy: 0.9352 - val_loss: 0.5303\n",
      "Epoch 1048/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.7438e-05 - val_accuracy: 0.9352 - val_loss: 0.5301\n",
      "Epoch 1049/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.8603e-05 - val_accuracy: 0.9352 - val_loss: 0.5299\n",
      "Epoch 1050/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.2268e-05 - val_accuracy: 0.9352 - val_loss: 0.5299\n",
      "Epoch 1051/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.2179e-05 - val_accuracy: 0.9352 - val_loss: 0.5297\n",
      "Epoch 1052/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0309e-04 - val_accuracy: 0.9354 - val_loss: 0.5296\n",
      "Epoch 1053/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.3310e-05 - val_accuracy: 0.9354 - val_loss: 0.5296\n",
      "Epoch 1054/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.3614e-05 - val_accuracy: 0.9354 - val_loss: 0.5295\n",
      "Epoch 1055/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.9488e-05 - val_accuracy: 0.9354 - val_loss: 0.5294\n",
      "Epoch 1056/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.7810e-05 - val_accuracy: 0.9354 - val_loss: 0.5292\n",
      "Epoch 1057/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0694e-05 - val_accuracy: 0.9354 - val_loss: 0.5292\n",
      "Epoch 1058/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.1515e-05 - val_accuracy: 0.9354 - val_loss: 0.5289\n",
      "Epoch 1059/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.2713e-05 - val_accuracy: 0.9354 - val_loss: 0.5289\n",
      "Epoch 1060/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.3812e-05 - val_accuracy: 0.9355 - val_loss: 0.5289\n",
      "Epoch 1061/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.1803e-05 - val_accuracy: 0.9354 - val_loss: 0.5289\n",
      "Epoch 1062/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.0814e-05 - val_accuracy: 0.9354 - val_loss: 0.5290\n",
      "Epoch 1063/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0022e-05 - val_accuracy: 0.9354 - val_loss: 0.5289\n",
      "Epoch 1064/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.4235e-05 - val_accuracy: 0.9355 - val_loss: 0.5288\n",
      "Epoch 1065/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.9126e-05 - val_accuracy: 0.9355 - val_loss: 0.5288\n",
      "Epoch 1066/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.2930e-05 - val_accuracy: 0.9355 - val_loss: 0.5286\n",
      "Epoch 1067/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.8857e-05 - val_accuracy: 0.9355 - val_loss: 0.5285\n",
      "Epoch 1068/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.3427e-05 - val_accuracy: 0.9355 - val_loss: 0.5284\n",
      "Epoch 1069/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.6246e-05 - val_accuracy: 0.9355 - val_loss: 0.5284\n",
      "Epoch 1070/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.3042e-05 - val_accuracy: 0.9355 - val_loss: 0.5286\n",
      "Epoch 1071/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.0972e-05 - val_accuracy: 0.9355 - val_loss: 0.5284\n",
      "Epoch 1072/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.3492e-05 - val_accuracy: 0.9355 - val_loss: 0.5283\n",
      "Epoch 1073/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.4687e-05 - val_accuracy: 0.9355 - val_loss: 0.5282\n",
      "Epoch 1074/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0323e-05 - val_accuracy: 0.9355 - val_loss: 0.5282\n",
      "Epoch 1075/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.1197e-05 - val_accuracy: 0.9355 - val_loss: 0.5281\n",
      "Epoch 1076/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.3430e-05 - val_accuracy: 0.9355 - val_loss: 0.5280\n",
      "Epoch 1077/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.3003e-05 - val_accuracy: 0.9355 - val_loss: 0.5280\n",
      "Epoch 1078/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.1023e-05 - val_accuracy: 0.9356 - val_loss: 0.5278\n",
      "Epoch 1079/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.1901e-05 - val_accuracy: 0.9355 - val_loss: 0.5277\n",
      "Epoch 1080/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.0144e-05 - val_accuracy: 0.9356 - val_loss: 0.5274\n",
      "Epoch 1081/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.9044e-05 - val_accuracy: 0.9356 - val_loss: 0.5275\n",
      "Epoch 1082/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.9578e-05 - val_accuracy: 0.9356 - val_loss: 0.5274\n",
      "Epoch 1083/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.8701e-05 - val_accuracy: 0.9356 - val_loss: 0.5271\n",
      "Epoch 1084/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.6755e-05 - val_accuracy: 0.9356 - val_loss: 0.5270\n",
      "Epoch 1085/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5526e-05 - val_accuracy: 0.9356 - val_loss: 0.5270\n",
      "Epoch 1086/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.0789e-05 - val_accuracy: 0.9357 - val_loss: 0.5268\n",
      "Epoch 1087/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.4392e-05 - val_accuracy: 0.9357 - val_loss: 0.5268\n",
      "Epoch 1088/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.8775e-05 - val_accuracy: 0.9356 - val_loss: 0.5268\n",
      "Epoch 1089/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9835e-05 - val_accuracy: 0.9356 - val_loss: 0.5268\n",
      "Epoch 1090/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.6106e-05 - val_accuracy: 0.9357 - val_loss: 0.5266\n",
      "Epoch 1091/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4116e-05 - val_accuracy: 0.9357 - val_loss: 0.5263\n",
      "Epoch 1092/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.8756e-05 - val_accuracy: 0.9358 - val_loss: 0.5262\n",
      "Epoch 1093/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.4505e-05 - val_accuracy: 0.9358 - val_loss: 0.5260\n",
      "Epoch 1094/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.7545e-05 - val_accuracy: 0.9358 - val_loss: 0.5259\n",
      "Epoch 1095/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.3426e-05 - val_accuracy: 0.9358 - val_loss: 0.5261\n",
      "Epoch 1096/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.6879e-05 - val_accuracy: 0.9358 - val_loss: 0.5261\n",
      "Epoch 1097/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5596e-05 - val_accuracy: 0.9358 - val_loss: 0.5259\n",
      "Epoch 1098/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.3804e-05 - val_accuracy: 0.9358 - val_loss: 0.5259\n",
      "Epoch 1099/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.8095e-05 - val_accuracy: 0.9358 - val_loss: 0.5259\n",
      "Epoch 1100/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9185e-05 - val_accuracy: 0.9357 - val_loss: 0.5257\n",
      "Epoch 1101/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.8414e-05 - val_accuracy: 0.9357 - val_loss: 0.5255\n",
      "Epoch 1102/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1866e-05 - val_accuracy: 0.9357 - val_loss: 0.5254\n",
      "Epoch 1103/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.8732e-05 - val_accuracy: 0.9357 - val_loss: 0.5252\n",
      "Epoch 1104/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.4183e-05 - val_accuracy: 0.9357 - val_loss: 0.5252\n",
      "Epoch 1105/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3831e-05 - val_accuracy: 0.9357 - val_loss: 0.5250\n",
      "Epoch 1106/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.4646e-05 - val_accuracy: 0.9357 - val_loss: 0.5248\n",
      "Epoch 1107/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8322e-05 - val_accuracy: 0.9358 - val_loss: 0.5247\n",
      "Epoch 1108/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.0385e-05 - val_accuracy: 0.9358 - val_loss: 0.5248\n",
      "Epoch 1109/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.1649e-05 - val_accuracy: 0.9357 - val_loss: 0.5248\n",
      "Epoch 1110/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.7470e-05 - val_accuracy: 0.9357 - val_loss: 0.5246\n",
      "Epoch 1111/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.0908e-05 - val_accuracy: 0.9357 - val_loss: 0.5247\n",
      "Epoch 1112/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.5765e-05 - val_accuracy: 0.9357 - val_loss: 0.5246\n",
      "Epoch 1113/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8864e-05 - val_accuracy: 0.9357 - val_loss: 0.5245\n",
      "Epoch 1114/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8768e-05 - val_accuracy: 0.9357 - val_loss: 0.5242\n",
      "Epoch 1115/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.7315e-05 - val_accuracy: 0.9357 - val_loss: 0.5241\n",
      "Epoch 1116/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.1428e-05 - val_accuracy: 0.9358 - val_loss: 0.5240\n",
      "Epoch 1117/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.7554e-05 - val_accuracy: 0.9358 - val_loss: 0.5238\n",
      "Epoch 1118/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.8529e-05 - val_accuracy: 0.9358 - val_loss: 0.5237\n",
      "Epoch 1119/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.4133e-05 - val_accuracy: 0.9358 - val_loss: 0.5236\n",
      "Epoch 1120/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.8783e-05 - val_accuracy: 0.9358 - val_loss: 0.5236\n",
      "Epoch 1121/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.6465e-05 - val_accuracy: 0.9358 - val_loss: 0.5235\n",
      "Epoch 1122/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3868e-05 - val_accuracy: 0.9358 - val_loss: 0.5233\n",
      "Epoch 1123/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0956e-05 - val_accuracy: 0.9358 - val_loss: 0.5233\n",
      "Epoch 1124/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5413e-05 - val_accuracy: 0.9358 - val_loss: 0.5232\n",
      "Epoch 1125/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.3109e-05 - val_accuracy: 0.9359 - val_loss: 0.5231\n",
      "Epoch 1126/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.6622e-05 - val_accuracy: 0.9358 - val_loss: 0.5230\n",
      "Epoch 1127/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5043e-05 - val_accuracy: 0.9359 - val_loss: 0.5229\n",
      "Epoch 1128/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.0590e-05 - val_accuracy: 0.9357 - val_loss: 0.5229\n",
      "Epoch 1129/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.3239e-05 - val_accuracy: 0.9358 - val_loss: 0.5229\n",
      "Epoch 1130/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8050e-05 - val_accuracy: 0.9359 - val_loss: 0.5227\n",
      "Epoch 1131/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8296e-05 - val_accuracy: 0.9358 - val_loss: 0.5227\n",
      "Epoch 1132/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.8067e-05 - val_accuracy: 0.9358 - val_loss: 0.5226\n",
      "Epoch 1133/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3256e-05 - val_accuracy: 0.9356 - val_loss: 0.5225\n",
      "Epoch 1134/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7732e-05 - val_accuracy: 0.9357 - val_loss: 0.5224\n",
      "Epoch 1135/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.5309e-05 - val_accuracy: 0.9357 - val_loss: 0.5223\n",
      "Epoch 1136/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4056e-05 - val_accuracy: 0.9357 - val_loss: 0.5222\n",
      "Epoch 1137/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3386e-05 - val_accuracy: 0.9357 - val_loss: 0.5222\n",
      "Epoch 1138/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.6000e-05 - val_accuracy: 0.9357 - val_loss: 0.5220\n",
      "Epoch 1139/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.4130e-05 - val_accuracy: 0.9358 - val_loss: 0.5221\n",
      "Epoch 1140/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.0530e-05 - val_accuracy: 0.9359 - val_loss: 0.5219\n",
      "Epoch 1141/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9293e-05 - val_accuracy: 0.9359 - val_loss: 0.5219\n",
      "Epoch 1142/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3122e-05 - val_accuracy: 0.9359 - val_loss: 0.5218\n",
      "Epoch 1143/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.1834e-05 - val_accuracy: 0.9360 - val_loss: 0.5216\n",
      "Epoch 1144/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.8833e-05 - val_accuracy: 0.9360 - val_loss: 0.5215\n",
      "Epoch 1145/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.3197e-05 - val_accuracy: 0.9360 - val_loss: 0.5215\n",
      "Epoch 1146/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.9028e-05 - val_accuracy: 0.9359 - val_loss: 0.5216\n",
      "Epoch 1147/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.7774e-05 - val_accuracy: 0.9360 - val_loss: 0.5217\n",
      "Epoch 1148/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9692e-05 - val_accuracy: 0.9361 - val_loss: 0.5216\n",
      "Epoch 1149/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.4853e-05 - val_accuracy: 0.9360 - val_loss: 0.5216\n",
      "Epoch 1150/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.6014e-05 - val_accuracy: 0.9360 - val_loss: 0.5214\n",
      "Epoch 1151/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2825e-05 - val_accuracy: 0.9360 - val_loss: 0.5213\n",
      "Epoch 1152/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7271e-05 - val_accuracy: 0.9359 - val_loss: 0.5212\n",
      "Epoch 1153/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.7144e-05 - val_accuracy: 0.9359 - val_loss: 0.5211\n",
      "Epoch 1154/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.3005e-05 - val_accuracy: 0.9360 - val_loss: 0.5209\n",
      "Epoch 1155/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.6162e-05 - val_accuracy: 0.9361 - val_loss: 0.5208\n",
      "Epoch 1156/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.5371e-05 - val_accuracy: 0.9361 - val_loss: 0.5205\n",
      "Epoch 1157/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2620e-05 - val_accuracy: 0.9360 - val_loss: 0.5206\n",
      "Epoch 1158/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.5099e-05 - val_accuracy: 0.9361 - val_loss: 0.5204\n",
      "Epoch 1159/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.5000e-05 - val_accuracy: 0.9361 - val_loss: 0.5201\n",
      "Epoch 1160/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.9407e-05 - val_accuracy: 0.9361 - val_loss: 0.5199\n",
      "Epoch 1161/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.7975e-05 - val_accuracy: 0.9360 - val_loss: 0.5199\n",
      "Epoch 1162/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.3400e-05 - val_accuracy: 0.9360 - val_loss: 0.5199\n",
      "Epoch 1163/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.4396e-05 - val_accuracy: 0.9360 - val_loss: 0.5196\n",
      "Epoch 1164/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.3063e-05 - val_accuracy: 0.9361 - val_loss: 0.5198\n",
      "Epoch 1165/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3987e-05 - val_accuracy: 0.9362 - val_loss: 0.5198\n",
      "Epoch 1166/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0443e-05 - val_accuracy: 0.9362 - val_loss: 0.5197\n",
      "Epoch 1167/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.0663e-05 - val_accuracy: 0.9361 - val_loss: 0.5196\n",
      "Epoch 1168/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2694e-05 - val_accuracy: 0.9361 - val_loss: 0.5196\n",
      "Epoch 1169/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7334e-05 - val_accuracy: 0.9361 - val_loss: 0.5195\n",
      "Epoch 1170/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.4420e-05 - val_accuracy: 0.9361 - val_loss: 0.5193\n",
      "Epoch 1171/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.0358e-05 - val_accuracy: 0.9362 - val_loss: 0.5194\n",
      "Epoch 1172/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.0168e-05 - val_accuracy: 0.9362 - val_loss: 0.5192\n",
      "Epoch 1173/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7661e-05 - val_accuracy: 0.9362 - val_loss: 0.5190\n",
      "Epoch 1174/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2207e-05 - val_accuracy: 0.9362 - val_loss: 0.5189\n",
      "Epoch 1175/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8477e-05 - val_accuracy: 0.9362 - val_loss: 0.5187\n",
      "Epoch 1176/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.1948e-05 - val_accuracy: 0.9362 - val_loss: 0.5187\n",
      "Epoch 1177/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.8678e-05 - val_accuracy: 0.9362 - val_loss: 0.5186\n",
      "Epoch 1178/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9349e-05 - val_accuracy: 0.9361 - val_loss: 0.5186\n",
      "Epoch 1179/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7196e-05 - val_accuracy: 0.9362 - val_loss: 0.5184\n",
      "Epoch 1180/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.8202e-05 - val_accuracy: 0.9364 - val_loss: 0.5183\n",
      "Epoch 1181/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.4527e-05 - val_accuracy: 0.9364 - val_loss: 0.5182\n",
      "Epoch 1182/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.0154e-05 - val_accuracy: 0.9364 - val_loss: 0.5181\n",
      "Epoch 1183/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2245e-05 - val_accuracy: 0.9364 - val_loss: 0.5180\n",
      "Epoch 1184/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.0823e-05 - val_accuracy: 0.9364 - val_loss: 0.5180\n",
      "Epoch 1185/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.4055e-05 - val_accuracy: 0.9363 - val_loss: 0.5179\n",
      "Epoch 1186/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.1481e-05 - val_accuracy: 0.9363 - val_loss: 0.5178\n",
      "Epoch 1187/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.9169e-05 - val_accuracy: 0.9363 - val_loss: 0.5177\n",
      "Epoch 1188/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.2588e-05 - val_accuracy: 0.9363 - val_loss: 0.5176\n",
      "Epoch 1189/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6395e-05 - val_accuracy: 0.9363 - val_loss: 0.5175\n",
      "Epoch 1190/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.5550e-05 - val_accuracy: 0.9363 - val_loss: 0.5173\n",
      "Epoch 1191/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0956e-05 - val_accuracy: 0.9363 - val_loss: 0.5175\n",
      "Epoch 1192/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7311e-05 - val_accuracy: 0.9363 - val_loss: 0.5173\n",
      "Epoch 1193/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.8878e-05 - val_accuracy: 0.9363 - val_loss: 0.5174\n",
      "Epoch 1194/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.3707e-05 - val_accuracy: 0.9363 - val_loss: 0.5172\n",
      "Epoch 1195/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0710e-05 - val_accuracy: 0.9363 - val_loss: 0.5171\n",
      "Epoch 1196/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.8420e-05 - val_accuracy: 0.9364 - val_loss: 0.5171\n",
      "Epoch 1197/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.2111e-05 - val_accuracy: 0.9364 - val_loss: 0.5170\n",
      "Epoch 1198/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.5237e-05 - val_accuracy: 0.9364 - val_loss: 0.5168\n",
      "Epoch 1199/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5989e-05 - val_accuracy: 0.9364 - val_loss: 0.5166\n",
      "Epoch 1200/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.1346e-05 - val_accuracy: 0.9365 - val_loss: 0.5167\n",
      "Epoch 1201/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.6244e-05 - val_accuracy: 0.9363 - val_loss: 0.5166\n",
      "Epoch 1202/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.6233e-05 - val_accuracy: 0.9363 - val_loss: 0.5166\n",
      "Epoch 1203/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.1292e-05 - val_accuracy: 0.9364 - val_loss: 0.5163\n",
      "Epoch 1204/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.0002e-05 - val_accuracy: 0.9364 - val_loss: 0.5161\n",
      "Epoch 1205/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4719e-05 - val_accuracy: 0.9364 - val_loss: 0.5159\n",
      "Epoch 1206/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.9864e-05 - val_accuracy: 0.9365 - val_loss: 0.5158\n",
      "Epoch 1207/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.5411e-05 - val_accuracy: 0.9366 - val_loss: 0.5160\n",
      "Epoch 1208/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5406e-05 - val_accuracy: 0.9367 - val_loss: 0.5158\n",
      "Epoch 1209/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.0121e-05 - val_accuracy: 0.9366 - val_loss: 0.5157\n",
      "Epoch 1210/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7730e-05 - val_accuracy: 0.9369 - val_loss: 0.5155\n",
      "Epoch 1211/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.6179e-05 - val_accuracy: 0.9367 - val_loss: 0.5154\n",
      "Epoch 1212/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.3753e-05 - val_accuracy: 0.9367 - val_loss: 0.5154\n",
      "Epoch 1213/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6479e-05 - val_accuracy: 0.9370 - val_loss: 0.5154\n",
      "Epoch 1214/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8089e-05 - val_accuracy: 0.9369 - val_loss: 0.5152\n",
      "Epoch 1215/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.7600e-05 - val_accuracy: 0.9369 - val_loss: 0.5150\n",
      "Epoch 1216/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2519e-05 - val_accuracy: 0.9369 - val_loss: 0.5149\n",
      "Epoch 1217/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5937e-05 - val_accuracy: 0.9367 - val_loss: 0.5149\n",
      "Epoch 1218/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.1289e-05 - val_accuracy: 0.9367 - val_loss: 0.5150\n",
      "Epoch 1219/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2182e-05 - val_accuracy: 0.9369 - val_loss: 0.5148\n",
      "Epoch 1220/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0154e-05 - val_accuracy: 0.9369 - val_loss: 0.5149\n",
      "Epoch 1221/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0790e-05 - val_accuracy: 0.9369 - val_loss: 0.5148\n",
      "Epoch 1222/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5675e-05 - val_accuracy: 0.9369 - val_loss: 0.5146\n",
      "Epoch 1223/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.5679e-05 - val_accuracy: 0.9369 - val_loss: 0.5145\n",
      "Epoch 1224/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.8523e-05 - val_accuracy: 0.9370 - val_loss: 0.5144\n",
      "Epoch 1225/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.4268e-05 - val_accuracy: 0.9372 - val_loss: 0.5144\n",
      "Epoch 1226/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4217e-05 - val_accuracy: 0.9372 - val_loss: 0.5143\n",
      "Epoch 1227/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.3972e-05 - val_accuracy: 0.9372 - val_loss: 0.5143\n",
      "Epoch 1228/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.9285e-05 - val_accuracy: 0.9372 - val_loss: 0.5141\n",
      "Epoch 1229/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.4957e-05 - val_accuracy: 0.9372 - val_loss: 0.5140\n",
      "Epoch 1230/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0829e-05 - val_accuracy: 0.9373 - val_loss: 0.5140\n",
      "Epoch 1231/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8741e-05 - val_accuracy: 0.9372 - val_loss: 0.5139\n",
      "Epoch 1232/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9909e-05 - val_accuracy: 0.9372 - val_loss: 0.5138\n",
      "Epoch 1233/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5412e-05 - val_accuracy: 0.9372 - val_loss: 0.5138\n",
      "Epoch 1234/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4428e-05 - val_accuracy: 0.9372 - val_loss: 0.5138\n",
      "Epoch 1235/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.5487e-05 - val_accuracy: 0.9372 - val_loss: 0.5136\n",
      "Epoch 1236/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2551e-05 - val_accuracy: 0.9373 - val_loss: 0.5137\n",
      "Epoch 1237/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2431e-05 - val_accuracy: 0.9373 - val_loss: 0.5136\n",
      "Epoch 1238/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8353e-05 - val_accuracy: 0.9374 - val_loss: 0.5134\n",
      "Epoch 1239/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2018e-05 - val_accuracy: 0.9375 - val_loss: 0.5134\n",
      "Epoch 1240/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.0451e-05 - val_accuracy: 0.9374 - val_loss: 0.5133\n",
      "Epoch 1241/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7902e-05 - val_accuracy: 0.9375 - val_loss: 0.5133\n",
      "Epoch 1242/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6766e-05 - val_accuracy: 0.9376 - val_loss: 0.5132\n",
      "Epoch 1243/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9512e-05 - val_accuracy: 0.9375 - val_loss: 0.5130\n",
      "Epoch 1244/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.3777e-05 - val_accuracy: 0.9377 - val_loss: 0.5127\n",
      "Epoch 1245/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.1820e-05 - val_accuracy: 0.9375 - val_loss: 0.5127\n",
      "Epoch 1246/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.0463e-05 - val_accuracy: 0.9375 - val_loss: 0.5127\n",
      "Epoch 1247/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.0916e-05 - val_accuracy: 0.9376 - val_loss: 0.5125\n",
      "Epoch 1248/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1445e-05 - val_accuracy: 0.9376 - val_loss: 0.5124\n",
      "Epoch 1249/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9588e-05 - val_accuracy: 0.9376 - val_loss: 0.5123\n",
      "Epoch 1250/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.3555e-05 - val_accuracy: 0.9376 - val_loss: 0.5121\n",
      "Epoch 1251/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0607e-05 - val_accuracy: 0.9376 - val_loss: 0.5121\n",
      "Epoch 1252/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.3903e-05 - val_accuracy: 0.9376 - val_loss: 0.5119\n",
      "Epoch 1253/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.8569e-05 - val_accuracy: 0.9375 - val_loss: 0.5118\n",
      "Epoch 1254/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.0885e-05 - val_accuracy: 0.9375 - val_loss: 0.5117\n",
      "Epoch 1255/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.3421e-05 - val_accuracy: 0.9377 - val_loss: 0.5118\n",
      "Epoch 1256/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9353e-05 - val_accuracy: 0.9377 - val_loss: 0.5117\n",
      "Epoch 1257/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6464e-05 - val_accuracy: 0.9378 - val_loss: 0.5114\n",
      "Epoch 1258/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.4075e-05 - val_accuracy: 0.9378 - val_loss: 0.5114\n",
      "Epoch 1259/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8290e-05 - val_accuracy: 0.9378 - val_loss: 0.5112\n",
      "Epoch 1260/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.0624e-05 - val_accuracy: 0.9379 - val_loss: 0.5109\n",
      "Epoch 1261/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.8000e-05 - val_accuracy: 0.9380 - val_loss: 0.5108\n",
      "Epoch 1262/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.9044e-05 - val_accuracy: 0.9379 - val_loss: 0.5108\n",
      "Epoch 1263/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9909e-05 - val_accuracy: 0.9379 - val_loss: 0.5109\n",
      "Epoch 1264/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8277e-05 - val_accuracy: 0.9379 - val_loss: 0.5107\n",
      "Epoch 1265/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.3368e-05 - val_accuracy: 0.9380 - val_loss: 0.5106\n",
      "Epoch 1266/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.3153e-05 - val_accuracy: 0.9379 - val_loss: 0.5107\n",
      "Epoch 1267/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8429e-05 - val_accuracy: 0.9380 - val_loss: 0.5107\n",
      "Epoch 1268/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1131e-05 - val_accuracy: 0.9379 - val_loss: 0.5105\n",
      "Epoch 1269/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.2634e-05 - val_accuracy: 0.9379 - val_loss: 0.5104\n",
      "Epoch 1270/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.3676e-05 - val_accuracy: 0.9379 - val_loss: 0.5104\n",
      "Epoch 1271/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.7848e-05 - val_accuracy: 0.9379 - val_loss: 0.5104\n",
      "Epoch 1272/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9848e-05 - val_accuracy: 0.9379 - val_loss: 0.5103\n",
      "Epoch 1273/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5239e-05 - val_accuracy: 0.9379 - val_loss: 0.5102\n",
      "Epoch 1274/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.9441e-05 - val_accuracy: 0.9379 - val_loss: 0.5102\n",
      "Epoch 1275/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8904e-05 - val_accuracy: 0.9379 - val_loss: 0.5101\n",
      "Epoch 1276/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7678e-05 - val_accuracy: 0.9379 - val_loss: 0.5101\n",
      "Epoch 1277/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.3752e-05 - val_accuracy: 0.9379 - val_loss: 0.5101\n",
      "Epoch 1278/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.5583e-05 - val_accuracy: 0.9380 - val_loss: 0.5101\n",
      "Epoch 1279/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.0875e-05 - val_accuracy: 0.9381 - val_loss: 0.5097\n",
      "Epoch 1280/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.4505e-05 - val_accuracy: 0.9381 - val_loss: 0.5097\n",
      "Epoch 1281/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.3381e-05 - val_accuracy: 0.9382 - val_loss: 0.5095\n",
      "Epoch 1282/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2456e-05 - val_accuracy: 0.9382 - val_loss: 0.5093\n",
      "Epoch 1283/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.7204e-05 - val_accuracy: 0.9383 - val_loss: 0.5093\n",
      "Epoch 1284/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6149e-05 - val_accuracy: 0.9383 - val_loss: 0.5091\n",
      "Epoch 1285/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1343e-05 - val_accuracy: 0.9383 - val_loss: 0.5091\n",
      "Epoch 1286/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.3984e-05 - val_accuracy: 0.9382 - val_loss: 0.5090\n",
      "Epoch 1287/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.5970e-05 - val_accuracy: 0.9383 - val_loss: 0.5092\n",
      "Epoch 1288/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6329e-05 - val_accuracy: 0.9383 - val_loss: 0.5089\n",
      "Epoch 1289/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8194e-05 - val_accuracy: 0.9384 - val_loss: 0.5087\n",
      "Epoch 1290/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.3373e-05 - val_accuracy: 0.9384 - val_loss: 0.5087\n",
      "Epoch 1291/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5614e-05 - val_accuracy: 0.9384 - val_loss: 0.5087\n",
      "Epoch 1292/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.4086e-05 - val_accuracy: 0.9382 - val_loss: 0.5088\n",
      "Epoch 1293/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.7911e-05 - val_accuracy: 0.9384 - val_loss: 0.5084\n",
      "Epoch 1294/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.9214e-05 - val_accuracy: 0.9384 - val_loss: 0.5085\n",
      "Epoch 1295/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4242e-05 - val_accuracy: 0.9384 - val_loss: 0.5082\n",
      "Epoch 1296/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.6531e-05 - val_accuracy: 0.9384 - val_loss: 0.5082\n",
      "Epoch 1297/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.6888e-05 - val_accuracy: 0.9383 - val_loss: 0.5081\n",
      "Epoch 1298/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7092e-05 - val_accuracy: 0.9384 - val_loss: 0.5079\n",
      "Epoch 1299/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8054e-05 - val_accuracy: 0.9384 - val_loss: 0.5079\n",
      "Epoch 1300/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9120e-05 - val_accuracy: 0.9384 - val_loss: 0.5080\n",
      "Epoch 1301/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7154e-05 - val_accuracy: 0.9384 - val_loss: 0.5080\n",
      "Epoch 1302/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0932e-05 - val_accuracy: 0.9384 - val_loss: 0.5077\n",
      "Epoch 1303/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.0086e-05 - val_accuracy: 0.9386 - val_loss: 0.5075\n",
      "Epoch 1304/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.0562e-05 - val_accuracy: 0.9385 - val_loss: 0.5073\n",
      "Epoch 1305/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2859e-05 - val_accuracy: 0.9386 - val_loss: 0.5072\n",
      "Epoch 1306/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0673e-05 - val_accuracy: 0.9385 - val_loss: 0.5072\n",
      "Epoch 1307/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.7503e-05 - val_accuracy: 0.9386 - val_loss: 0.5071\n",
      "Epoch 1308/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6987e-05 - val_accuracy: 0.9387 - val_loss: 0.5070\n",
      "Epoch 1309/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2081e-05 - val_accuracy: 0.9387 - val_loss: 0.5069\n",
      "Epoch 1310/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.3533e-05 - val_accuracy: 0.9387 - val_loss: 0.5067\n",
      "Epoch 1311/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.4319e-05 - val_accuracy: 0.9387 - val_loss: 0.5067\n",
      "Epoch 1312/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.1594e-05 - val_accuracy: 0.9387 - val_loss: 0.5067\n",
      "Epoch 1313/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1247e-05 - val_accuracy: 0.9387 - val_loss: 0.5067\n",
      "Epoch 1314/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7494e-05 - val_accuracy: 0.9387 - val_loss: 0.5067\n",
      "Epoch 1315/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4113e-05 - val_accuracy: 0.9387 - val_loss: 0.5069\n",
      "Epoch 1316/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1088e-05 - val_accuracy: 0.9386 - val_loss: 0.5068\n",
      "Epoch 1317/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5668e-05 - val_accuracy: 0.9387 - val_loss: 0.5069\n",
      "Epoch 1318/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6192e-05 - val_accuracy: 0.9387 - val_loss: 0.5070\n",
      "Epoch 1319/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1880e-05 - val_accuracy: 0.9386 - val_loss: 0.5068\n",
      "Epoch 1320/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8989e-05 - val_accuracy: 0.9386 - val_loss: 0.5068\n",
      "Epoch 1321/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.4927e-05 - val_accuracy: 0.9386 - val_loss: 0.5068\n",
      "Epoch 1322/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.9524e-05 - val_accuracy: 0.9386 - val_loss: 0.5066\n",
      "Epoch 1323/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2906e-05 - val_accuracy: 0.9386 - val_loss: 0.5069\n",
      "Epoch 1324/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.9532e-05 - val_accuracy: 0.9387 - val_loss: 0.5066\n",
      "Epoch 1325/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6972e-05 - val_accuracy: 0.9387 - val_loss: 0.5063\n",
      "Epoch 1326/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.2198e-05 - val_accuracy: 0.9388 - val_loss: 0.5064\n",
      "Epoch 1327/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.0528e-05 - val_accuracy: 0.9388 - val_loss: 0.5063\n",
      "Epoch 1328/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7836e-05 - val_accuracy: 0.9388 - val_loss: 0.5063\n",
      "Epoch 1329/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.2043e-05 - val_accuracy: 0.9388 - val_loss: 0.5062\n",
      "Epoch 1330/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.1155e-05 - val_accuracy: 0.9388 - val_loss: 0.5062\n",
      "Epoch 1331/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7383e-05 - val_accuracy: 0.9388 - val_loss: 0.5061\n",
      "Epoch 1332/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2507e-05 - val_accuracy: 0.9388 - val_loss: 0.5059\n",
      "Epoch 1333/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8122e-05 - val_accuracy: 0.9387 - val_loss: 0.5058\n",
      "Epoch 1334/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.9733e-05 - val_accuracy: 0.9388 - val_loss: 0.5057\n",
      "Epoch 1335/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5396e-05 - val_accuracy: 0.9387 - val_loss: 0.5056\n",
      "Epoch 1336/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.3085e-05 - val_accuracy: 0.9387 - val_loss: 0.5054\n",
      "Epoch 1337/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7232e-05 - val_accuracy: 0.9387 - val_loss: 0.5054\n",
      "Epoch 1338/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7145e-05 - val_accuracy: 0.9387 - val_loss: 0.5051\n",
      "Epoch 1339/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.8511e-05 - val_accuracy: 0.9387 - val_loss: 0.5050\n",
      "Epoch 1340/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9153e-05 - val_accuracy: 0.9387 - val_loss: 0.5049\n",
      "Epoch 1341/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6196e-05 - val_accuracy: 0.9387 - val_loss: 0.5045\n",
      "Epoch 1342/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.5606e-05 - val_accuracy: 0.9387 - val_loss: 0.5044\n",
      "Epoch 1343/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5258e-05 - val_accuracy: 0.9387 - val_loss: 0.5043\n",
      "Epoch 1344/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.0383e-05 - val_accuracy: 0.9387 - val_loss: 0.5039\n",
      "Epoch 1345/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6268e-05 - val_accuracy: 0.9387 - val_loss: 0.5038\n",
      "Epoch 1346/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4944e-05 - val_accuracy: 0.9387 - val_loss: 0.5040\n",
      "Epoch 1347/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6756e-05 - val_accuracy: 0.9387 - val_loss: 0.5039\n",
      "Epoch 1348/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.4461e-05 - val_accuracy: 0.9388 - val_loss: 0.5037\n",
      "Epoch 1349/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8454e-05 - val_accuracy: 0.9389 - val_loss: 0.5036\n",
      "Epoch 1350/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6184e-05 - val_accuracy: 0.9389 - val_loss: 0.5037\n",
      "Epoch 1351/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2691e-05 - val_accuracy: 0.9390 - val_loss: 0.5036\n",
      "Epoch 1352/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8281e-05 - val_accuracy: 0.9390 - val_loss: 0.5035\n",
      "Epoch 1353/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.8585e-05 - val_accuracy: 0.9390 - val_loss: 0.5036\n",
      "Epoch 1354/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6838e-05 - val_accuracy: 0.9390 - val_loss: 0.5034\n",
      "Epoch 1355/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6283e-05 - val_accuracy: 0.9390 - val_loss: 0.5033\n",
      "Epoch 1356/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5387e-05 - val_accuracy: 0.9390 - val_loss: 0.5031\n",
      "Epoch 1357/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8283e-05 - val_accuracy: 0.9390 - val_loss: 0.5029\n",
      "Epoch 1358/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.6906e-05 - val_accuracy: 0.9390 - val_loss: 0.5029\n",
      "Epoch 1359/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7094e-05 - val_accuracy: 0.9391 - val_loss: 0.5027\n",
      "Epoch 1360/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3869e-05 - val_accuracy: 0.9390 - val_loss: 0.5027\n",
      "Epoch 1361/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5920e-05 - val_accuracy: 0.9390 - val_loss: 0.5028\n",
      "Epoch 1362/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.6447e-05 - val_accuracy: 0.9390 - val_loss: 0.5030\n",
      "Epoch 1363/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.5942e-05 - val_accuracy: 0.9390 - val_loss: 0.5029\n",
      "Epoch 1364/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.4272e-05 - val_accuracy: 0.9390 - val_loss: 0.5029\n",
      "Epoch 1365/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.6927e-05 - val_accuracy: 0.9390 - val_loss: 0.5027\n",
      "Epoch 1366/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.4704e-05 - val_accuracy: 0.9390 - val_loss: 0.5028\n",
      "Epoch 1367/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.6043e-05 - val_accuracy: 0.9390 - val_loss: 0.5026\n",
      "Epoch 1368/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3646e-05 - val_accuracy: 0.9390 - val_loss: 0.5025\n",
      "Epoch 1369/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7205e-05 - val_accuracy: 0.9390 - val_loss: 0.5023\n",
      "Epoch 1370/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2548e-05 - val_accuracy: 0.9390 - val_loss: 0.5022\n",
      "Epoch 1371/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3982e-05 - val_accuracy: 0.9390 - val_loss: 0.5023\n",
      "Epoch 1372/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.1805e-05 - val_accuracy: 0.9390 - val_loss: 0.5022\n",
      "Epoch 1373/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4602e-05 - val_accuracy: 0.9390 - val_loss: 0.5020\n",
      "Epoch 1374/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.6928e-05 - val_accuracy: 0.9392 - val_loss: 0.5018\n",
      "Epoch 1375/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6459e-05 - val_accuracy: 0.9392 - val_loss: 0.5018\n",
      "Epoch 1376/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1867e-05 - val_accuracy: 0.9391 - val_loss: 0.5019\n",
      "Epoch 1377/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.5648e-05 - val_accuracy: 0.9391 - val_loss: 0.5019\n",
      "Epoch 1378/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.6222e-05 - val_accuracy: 0.9391 - val_loss: 0.5019\n",
      "Epoch 1379/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.3034e-05 - val_accuracy: 0.9391 - val_loss: 0.5017\n",
      "Epoch 1380/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.3606e-05 - val_accuracy: 0.9391 - val_loss: 0.5016\n",
      "Epoch 1381/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7432e-05 - val_accuracy: 0.9392 - val_loss: 0.5015\n",
      "Epoch 1382/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4011e-05 - val_accuracy: 0.9391 - val_loss: 0.5015\n",
      "Epoch 1383/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.4576e-05 - val_accuracy: 0.9391 - val_loss: 0.5015\n",
      "Epoch 1384/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0742e-05 - val_accuracy: 0.9391 - val_loss: 0.5014\n",
      "Epoch 1385/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3744e-05 - val_accuracy: 0.9392 - val_loss: 0.5010\n",
      "Epoch 1386/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.2349e-05 - val_accuracy: 0.9393 - val_loss: 0.5010\n",
      "Epoch 1387/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1531e-05 - val_accuracy: 0.9393 - val_loss: 0.5010\n",
      "Epoch 1388/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0247e-05 - val_accuracy: 0.9394 - val_loss: 0.5008\n",
      "Epoch 1389/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.5222e-05 - val_accuracy: 0.9394 - val_loss: 0.5006\n",
      "Epoch 1390/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1226e-05 - val_accuracy: 0.9396 - val_loss: 0.5005\n",
      "Epoch 1391/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3935e-05 - val_accuracy: 0.9396 - val_loss: 0.5004\n",
      "Epoch 1392/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.4463e-05 - val_accuracy: 0.9396 - val_loss: 0.5005\n",
      "Epoch 1393/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.8038e-05 - val_accuracy: 0.9397 - val_loss: 0.5007\n",
      "Epoch 1394/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3744e-05 - val_accuracy: 0.9396 - val_loss: 0.5004\n",
      "Epoch 1395/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0909e-05 - val_accuracy: 0.9397 - val_loss: 0.5006\n",
      "Epoch 1396/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1909e-05 - val_accuracy: 0.9397 - val_loss: 0.5006\n",
      "Epoch 1397/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0939e-05 - val_accuracy: 0.9397 - val_loss: 0.5004\n",
      "Epoch 1398/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.9534e-05 - val_accuracy: 0.9396 - val_loss: 0.5004\n",
      "Epoch 1399/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.8292e-05 - val_accuracy: 0.9397 - val_loss: 0.5004\n",
      "Epoch 1400/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.1927e-05 - val_accuracy: 0.9396 - val_loss: 0.5001\n",
      "Epoch 1401/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0561e-05 - val_accuracy: 0.9396 - val_loss: 0.5003\n",
      "Epoch 1402/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2738e-05 - val_accuracy: 0.9397 - val_loss: 0.5002\n",
      "Epoch 1403/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7115e-05 - val_accuracy: 0.9397 - val_loss: 0.5000\n",
      "Epoch 1404/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.5228e-05 - val_accuracy: 0.9397 - val_loss: 0.5001\n",
      "Epoch 1405/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1680e-05 - val_accuracy: 0.9397 - val_loss: 0.4999\n",
      "Epoch 1406/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.3509e-05 - val_accuracy: 0.9397 - val_loss: 0.4996\n",
      "Epoch 1407/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2973e-05 - val_accuracy: 0.9398 - val_loss: 0.4996\n",
      "Epoch 1408/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.2189e-05 - val_accuracy: 0.9398 - val_loss: 0.4993\n",
      "Epoch 1409/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.1235e-05 - val_accuracy: 0.9398 - val_loss: 0.4993\n",
      "Epoch 1410/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2254e-05 - val_accuracy: 0.9398 - val_loss: 0.4992\n",
      "Epoch 1411/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.1965e-05 - val_accuracy: 0.9397 - val_loss: 0.4989\n",
      "Epoch 1412/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8813e-05 - val_accuracy: 0.9398 - val_loss: 0.4990\n",
      "Epoch 1413/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.3456e-05 - val_accuracy: 0.9398 - val_loss: 0.4989\n",
      "Epoch 1414/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9901e-05 - val_accuracy: 0.9396 - val_loss: 0.4987\n",
      "Epoch 1415/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.1461e-05 - val_accuracy: 0.9397 - val_loss: 0.4986\n",
      "Epoch 1416/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9245e-05 - val_accuracy: 0.9397 - val_loss: 0.4985\n",
      "Epoch 1417/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8573e-05 - val_accuracy: 0.9398 - val_loss: 0.4984\n",
      "Epoch 1418/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1644e-05 - val_accuracy: 0.9399 - val_loss: 0.4982\n",
      "Epoch 1419/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1544e-05 - val_accuracy: 0.9400 - val_loss: 0.4982\n",
      "Epoch 1420/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4500e-05 - val_accuracy: 0.9399 - val_loss: 0.4980\n",
      "Epoch 1421/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.7642e-05 - val_accuracy: 0.9399 - val_loss: 0.4978\n",
      "Epoch 1422/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2940e-05 - val_accuracy: 0.9399 - val_loss: 0.4979\n",
      "Epoch 1423/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0324e-05 - val_accuracy: 0.9399 - val_loss: 0.4978\n",
      "Epoch 1424/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.0443e-05 - val_accuracy: 0.9400 - val_loss: 0.4978\n",
      "Epoch 1425/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.3381e-05 - val_accuracy: 0.9400 - val_loss: 0.4978\n",
      "Epoch 1426/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0321e-05 - val_accuracy: 0.9400 - val_loss: 0.4978\n",
      "Epoch 1427/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3104e-05 - val_accuracy: 0.9400 - val_loss: 0.4975\n",
      "Epoch 1428/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0673e-05 - val_accuracy: 0.9400 - val_loss: 0.4975\n",
      "Epoch 1429/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.0918e-05 - val_accuracy: 0.9400 - val_loss: 0.4975\n",
      "Epoch 1430/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8009e-05 - val_accuracy: 0.9401 - val_loss: 0.4972\n",
      "Epoch 1431/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1594e-05 - val_accuracy: 0.9401 - val_loss: 0.4973\n",
      "Epoch 1432/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4543e-05 - val_accuracy: 0.9401 - val_loss: 0.4973\n",
      "Epoch 1433/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.1783e-05 - val_accuracy: 0.9401 - val_loss: 0.4971\n",
      "Epoch 1434/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1259e-05 - val_accuracy: 0.9401 - val_loss: 0.4970\n",
      "Epoch 1435/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0817e-05 - val_accuracy: 0.9401 - val_loss: 0.4968\n",
      "Epoch 1436/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9747e-05 - val_accuracy: 0.9401 - val_loss: 0.4968\n",
      "Epoch 1437/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9678e-05 - val_accuracy: 0.9401 - val_loss: 0.4968\n",
      "Epoch 1438/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.0216e-05 - val_accuracy: 0.9402 - val_loss: 0.4968\n",
      "Epoch 1439/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9743e-05 - val_accuracy: 0.9401 - val_loss: 0.4965\n",
      "Epoch 1440/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0389e-05 - val_accuracy: 0.9401 - val_loss: 0.4965\n",
      "Epoch 1441/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8259e-05 - val_accuracy: 0.9402 - val_loss: 0.4965\n",
      "Epoch 1442/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8311e-05 - val_accuracy: 0.9401 - val_loss: 0.4962\n",
      "Epoch 1443/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9371e-05 - val_accuracy: 0.9400 - val_loss: 0.4962\n",
      "Epoch 1444/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7898e-05 - val_accuracy: 0.9401 - val_loss: 0.4961\n",
      "Epoch 1445/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8610e-05 - val_accuracy: 0.9402 - val_loss: 0.4961\n",
      "Epoch 1446/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8514e-05 - val_accuracy: 0.9402 - val_loss: 0.4961\n",
      "Epoch 1447/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6825e-05 - val_accuracy: 0.9402 - val_loss: 0.4960\n",
      "Epoch 1448/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7449e-05 - val_accuracy: 0.9402 - val_loss: 0.4959\n",
      "Epoch 1449/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9236e-05 - val_accuracy: 0.9402 - val_loss: 0.4959\n",
      "Epoch 1450/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9155e-05 - val_accuracy: 0.9402 - val_loss: 0.4957\n",
      "Epoch 1451/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6626e-05 - val_accuracy: 0.9401 - val_loss: 0.4955\n",
      "Epoch 1452/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8864e-05 - val_accuracy: 0.9401 - val_loss: 0.4954\n",
      "Epoch 1453/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8721e-05 - val_accuracy: 0.9401 - val_loss: 0.4953\n",
      "Epoch 1454/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7821e-05 - val_accuracy: 0.9402 - val_loss: 0.4952\n",
      "Epoch 1455/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7236e-05 - val_accuracy: 0.9402 - val_loss: 0.4950\n",
      "Epoch 1456/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7743e-05 - val_accuracy: 0.9403 - val_loss: 0.4952\n",
      "Epoch 1457/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.0201e-05 - val_accuracy: 0.9403 - val_loss: 0.4951\n",
      "Epoch 1458/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.1513e-05 - val_accuracy: 0.9402 - val_loss: 0.4952\n",
      "Epoch 1459/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.0694e-05 - val_accuracy: 0.9403 - val_loss: 0.4950\n",
      "Epoch 1460/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9213e-05 - val_accuracy: 0.9404 - val_loss: 0.4949\n",
      "Epoch 1461/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8666e-05 - val_accuracy: 0.9403 - val_loss: 0.4946\n",
      "Epoch 1462/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8292e-05 - val_accuracy: 0.9403 - val_loss: 0.4945\n",
      "Epoch 1463/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8210e-05 - val_accuracy: 0.9404 - val_loss: 0.4946\n",
      "Epoch 1464/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.9035e-05 - val_accuracy: 0.9404 - val_loss: 0.4944\n",
      "Epoch 1465/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.8279e-05 - val_accuracy: 0.9404 - val_loss: 0.4944\n",
      "Epoch 1466/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7461e-05 - val_accuracy: 0.9403 - val_loss: 0.4941\n",
      "Epoch 1467/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4426e-05 - val_accuracy: 0.9404 - val_loss: 0.4944\n",
      "Epoch 1468/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8715e-05 - val_accuracy: 0.9404 - val_loss: 0.4945\n",
      "Epoch 1469/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5167e-05 - val_accuracy: 0.9405 - val_loss: 0.4944\n",
      "Epoch 1470/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8801e-05 - val_accuracy: 0.9405 - val_loss: 0.4944\n",
      "Epoch 1471/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7818e-05 - val_accuracy: 0.9405 - val_loss: 0.4942\n",
      "Epoch 1472/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.7622e-05 - val_accuracy: 0.9404 - val_loss: 0.4939\n",
      "Epoch 1473/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.9806e-05 - val_accuracy: 0.9404 - val_loss: 0.4938\n",
      "Epoch 1474/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7221e-05 - val_accuracy: 0.9405 - val_loss: 0.4941\n",
      "Epoch 1475/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.7903e-05 - val_accuracy: 0.9405 - val_loss: 0.4940\n",
      "Epoch 1476/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.4443e-05 - val_accuracy: 0.9405 - val_loss: 0.4939\n",
      "Epoch 1477/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6301e-05 - val_accuracy: 0.9405 - val_loss: 0.4939\n",
      "Epoch 1478/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5360e-05 - val_accuracy: 0.9405 - val_loss: 0.4936\n",
      "Epoch 1479/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5890e-05 - val_accuracy: 0.9405 - val_loss: 0.4939\n",
      "Epoch 1480/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.6282e-05 - val_accuracy: 0.9405 - val_loss: 0.4939\n",
      "Epoch 1481/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6441e-05 - val_accuracy: 0.9405 - val_loss: 0.4935\n",
      "Epoch 1482/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.6325e-05 - val_accuracy: 0.9405 - val_loss: 0.4938\n",
      "Epoch 1483/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.6618e-05 - val_accuracy: 0.9405 - val_loss: 0.4938\n",
      "Epoch 1484/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7298e-05 - val_accuracy: 0.9405 - val_loss: 0.4935\n",
      "Epoch 1485/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6102e-05 - val_accuracy: 0.9405 - val_loss: 0.4935\n",
      "Epoch 1486/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6966e-05 - val_accuracy: 0.9405 - val_loss: 0.4937\n",
      "Epoch 1487/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5784e-05 - val_accuracy: 0.9405 - val_loss: 0.4936\n",
      "Epoch 1488/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.6849e-05 - val_accuracy: 0.9405 - val_loss: 0.4934\n",
      "Epoch 1489/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5757e-05 - val_accuracy: 0.9405 - val_loss: 0.4933\n",
      "Epoch 1490/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5158e-05 - val_accuracy: 0.9405 - val_loss: 0.4931\n",
      "Epoch 1491/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.7691e-05 - val_accuracy: 0.9405 - val_loss: 0.4929\n",
      "Epoch 1492/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7012e-05 - val_accuracy: 0.9405 - val_loss: 0.4927\n",
      "Epoch 1493/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6966e-05 - val_accuracy: 0.9405 - val_loss: 0.4925\n",
      "Epoch 1494/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9265e-05 - val_accuracy: 0.9405 - val_loss: 0.4928\n",
      "Epoch 1495/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6608e-05 - val_accuracy: 0.9405 - val_loss: 0.4927\n",
      "Epoch 1496/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5346e-05 - val_accuracy: 0.9405 - val_loss: 0.4925\n",
      "Epoch 1497/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4550e-05 - val_accuracy: 0.9405 - val_loss: 0.4926\n",
      "Epoch 1498/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6255e-05 - val_accuracy: 0.9406 - val_loss: 0.4924\n",
      "Epoch 1499/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7384e-05 - val_accuracy: 0.9406 - val_loss: 0.4924\n",
      "Epoch 1500/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6380e-05 - val_accuracy: 0.9406 - val_loss: 0.4923\n",
      "Epoch 1501/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4341e-05 - val_accuracy: 0.9406 - val_loss: 0.4921\n",
      "Epoch 1502/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.7224e-05 - val_accuracy: 0.9406 - val_loss: 0.4918\n",
      "Epoch 1503/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5551e-05 - val_accuracy: 0.9406 - val_loss: 0.4918\n",
      "Epoch 1504/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2963e-05 - val_accuracy: 0.9407 - val_loss: 0.4914\n",
      "Epoch 1505/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4172e-05 - val_accuracy: 0.9407 - val_loss: 0.4914\n",
      "Epoch 1506/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4405e-05 - val_accuracy: 0.9407 - val_loss: 0.4915\n",
      "Epoch 1507/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4541e-05 - val_accuracy: 0.9407 - val_loss: 0.4912\n",
      "Epoch 1508/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5559e-05 - val_accuracy: 0.9407 - val_loss: 0.4912\n",
      "Epoch 1509/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3939e-05 - val_accuracy: 0.9407 - val_loss: 0.4911\n",
      "Epoch 1510/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3670e-05 - val_accuracy: 0.9407 - val_loss: 0.4911\n",
      "Epoch 1511/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2075e-05 - val_accuracy: 0.9407 - val_loss: 0.4910\n",
      "Epoch 1512/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.4217e-05 - val_accuracy: 0.9407 - val_loss: 0.4909\n",
      "Epoch 1513/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.3526e-05 - val_accuracy: 0.9407 - val_loss: 0.4907\n",
      "Epoch 1514/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6926e-05 - val_accuracy: 0.9407 - val_loss: 0.4910\n",
      "Epoch 1515/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6980e-05 - val_accuracy: 0.9407 - val_loss: 0.4910\n",
      "Epoch 1516/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4645e-05 - val_accuracy: 0.9407 - val_loss: 0.4909\n",
      "Epoch 1517/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5014e-05 - val_accuracy: 0.9407 - val_loss: 0.4909\n",
      "Epoch 1518/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4045e-05 - val_accuracy: 0.9407 - val_loss: 0.4906\n",
      "Epoch 1519/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6391e-05 - val_accuracy: 0.9408 - val_loss: 0.4904\n",
      "Epoch 1520/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5928e-05 - val_accuracy: 0.9408 - val_loss: 0.4906\n",
      "Epoch 1521/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5504e-05 - val_accuracy: 0.9408 - val_loss: 0.4904\n",
      "Epoch 1522/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1901e-05 - val_accuracy: 0.9408 - val_loss: 0.4904\n",
      "Epoch 1523/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.3994e-05 - val_accuracy: 0.9408 - val_loss: 0.4905\n",
      "Epoch 1524/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.6387e-05 - val_accuracy: 0.9408 - val_loss: 0.4905\n",
      "Epoch 1525/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3454e-05 - val_accuracy: 0.9408 - val_loss: 0.4904\n",
      "Epoch 1526/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3171e-05 - val_accuracy: 0.9408 - val_loss: 0.4901\n",
      "Epoch 1527/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2706e-05 - val_accuracy: 0.9408 - val_loss: 0.4899\n",
      "Epoch 1528/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1693e-05 - val_accuracy: 0.9408 - val_loss: 0.4900\n",
      "Epoch 1529/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2348e-05 - val_accuracy: 0.9408 - val_loss: 0.4901\n",
      "Epoch 1530/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5458e-05 - val_accuracy: 0.9408 - val_loss: 0.4897\n",
      "Epoch 1531/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3721e-05 - val_accuracy: 0.9408 - val_loss: 0.4897\n",
      "Epoch 1532/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5984e-05 - val_accuracy: 0.9408 - val_loss: 0.4901\n",
      "Epoch 1533/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2760e-05 - val_accuracy: 0.9408 - val_loss: 0.4900\n",
      "Epoch 1534/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3077e-05 - val_accuracy: 0.9408 - val_loss: 0.4900\n",
      "Epoch 1535/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3417e-05 - val_accuracy: 0.9408 - val_loss: 0.4899\n",
      "Epoch 1536/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3836e-05 - val_accuracy: 0.9409 - val_loss: 0.4897\n",
      "Epoch 1537/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1674e-05 - val_accuracy: 0.9409 - val_loss: 0.4897\n",
      "Epoch 1538/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2683e-05 - val_accuracy: 0.9409 - val_loss: 0.4897\n",
      "Epoch 1539/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4229e-05 - val_accuracy: 0.9409 - val_loss: 0.4895\n",
      "Epoch 1540/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2320e-05 - val_accuracy: 0.9409 - val_loss: 0.4893\n",
      "Epoch 1541/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3722e-05 - val_accuracy: 0.9409 - val_loss: 0.4892\n",
      "Epoch 1542/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4253e-05 - val_accuracy: 0.9410 - val_loss: 0.4887\n",
      "Epoch 1543/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2118e-05 - val_accuracy: 0.9410 - val_loss: 0.4887\n",
      "Epoch 1544/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2641e-05 - val_accuracy: 0.9410 - val_loss: 0.4886\n",
      "Epoch 1545/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4694e-05 - val_accuracy: 0.9410 - val_loss: 0.4885\n",
      "Epoch 1546/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3487e-05 - val_accuracy: 0.9411 - val_loss: 0.4884\n",
      "Epoch 1547/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2307e-05 - val_accuracy: 0.9411 - val_loss: 0.4884\n",
      "Epoch 1548/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1064e-05 - val_accuracy: 0.9411 - val_loss: 0.4884\n",
      "Epoch 1549/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1515e-05 - val_accuracy: 0.9410 - val_loss: 0.4886\n",
      "Epoch 1550/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1965e-05 - val_accuracy: 0.9410 - val_loss: 0.4885\n",
      "Epoch 1551/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.2308e-05 - val_accuracy: 0.9411 - val_loss: 0.4885\n",
      "Epoch 1552/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.4715e-05 - val_accuracy: 0.9411 - val_loss: 0.4886\n",
      "Epoch 1553/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2611e-05 - val_accuracy: 0.9410 - val_loss: 0.4885\n",
      "Epoch 1554/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3528e-05 - val_accuracy: 0.9412 - val_loss: 0.4884\n",
      "Epoch 1555/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.3738e-05 - val_accuracy: 0.9413 - val_loss: 0.4882\n",
      "Epoch 1556/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1822e-05 - val_accuracy: 0.9412 - val_loss: 0.4884\n",
      "Epoch 1557/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3234e-05 - val_accuracy: 0.9413 - val_loss: 0.4882\n",
      "Epoch 1558/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1602e-05 - val_accuracy: 0.9413 - val_loss: 0.4881\n",
      "Epoch 1559/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2580e-05 - val_accuracy: 0.9413 - val_loss: 0.4880\n",
      "Epoch 1560/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2741e-05 - val_accuracy: 0.9413 - val_loss: 0.4878\n",
      "Epoch 1561/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1945e-05 - val_accuracy: 0.9413 - val_loss: 0.4877\n",
      "Epoch 1562/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2455e-05 - val_accuracy: 0.9413 - val_loss: 0.4876\n",
      "Epoch 1563/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1611e-05 - val_accuracy: 0.9413 - val_loss: 0.4878\n",
      "Epoch 1564/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1847e-05 - val_accuracy: 0.9413 - val_loss: 0.4877\n",
      "Epoch 1565/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2682e-05 - val_accuracy: 0.9413 - val_loss: 0.4875\n",
      "Epoch 1566/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.9067e-06 - val_accuracy: 0.9413 - val_loss: 0.4876\n",
      "Epoch 1567/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2615e-05 - val_accuracy: 0.9413 - val_loss: 0.4876\n",
      "Epoch 1568/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2262e-05 - val_accuracy: 0.9412 - val_loss: 0.4877\n",
      "Epoch 1569/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2620e-05 - val_accuracy: 0.9413 - val_loss: 0.4875\n",
      "Epoch 1570/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1755e-05 - val_accuracy: 0.9413 - val_loss: 0.4876\n",
      "Epoch 1571/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2032e-05 - val_accuracy: 0.9413 - val_loss: 0.4875\n",
      "Epoch 1572/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1925e-05 - val_accuracy: 0.9413 - val_loss: 0.4874\n",
      "Epoch 1573/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0549e-05 - val_accuracy: 0.9414 - val_loss: 0.4874\n",
      "Epoch 1574/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0737e-05 - val_accuracy: 0.9413 - val_loss: 0.4874\n",
      "Epoch 1575/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0610e-05 - val_accuracy: 0.9414 - val_loss: 0.4872\n",
      "Epoch 1576/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3397e-05 - val_accuracy: 0.9414 - val_loss: 0.4871\n",
      "Epoch 1577/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.3127e-05 - val_accuracy: 0.9414 - val_loss: 0.4870\n",
      "Epoch 1578/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1420e-05 - val_accuracy: 0.9414 - val_loss: 0.4867\n",
      "Epoch 1579/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1429e-05 - val_accuracy: 0.9414 - val_loss: 0.4870\n",
      "Epoch 1580/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1663e-05 - val_accuracy: 0.9414 - val_loss: 0.4870\n",
      "Epoch 1581/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2171e-05 - val_accuracy: 0.9414 - val_loss: 0.4869\n",
      "Epoch 1582/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.2317e-05 - val_accuracy: 0.9414 - val_loss: 0.4868\n",
      "Epoch 1583/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1322e-05 - val_accuracy: 0.9415 - val_loss: 0.4864\n",
      "Epoch 1584/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.2626e-05 - val_accuracy: 0.9415 - val_loss: 0.4864\n",
      "Epoch 1585/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1006e-05 - val_accuracy: 0.9414 - val_loss: 0.4862\n",
      "Epoch 1586/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1625e-05 - val_accuracy: 0.9414 - val_loss: 0.4863\n",
      "Epoch 1587/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1217e-05 - val_accuracy: 0.9415 - val_loss: 0.4860\n",
      "Epoch 1588/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1452e-05 - val_accuracy: 0.9414 - val_loss: 0.4862\n",
      "Epoch 1589/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.8780e-06 - val_accuracy: 0.9415 - val_loss: 0.4861\n",
      "Epoch 1590/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.1873e-05 - val_accuracy: 0.9415 - val_loss: 0.4861\n",
      "Epoch 1591/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1176e-05 - val_accuracy: 0.9414 - val_loss: 0.4861\n",
      "Epoch 1592/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.9711e-06 - val_accuracy: 0.9414 - val_loss: 0.4860\n",
      "Epoch 1593/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.6732e-06 - val_accuracy: 0.9415 - val_loss: 0.4859\n",
      "Epoch 1594/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 9.3055e-06 - val_accuracy: 0.9416 - val_loss: 0.4858\n",
      "Epoch 1595/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1526e-05 - val_accuracy: 0.9415 - val_loss: 0.4858\n",
      "Epoch 1596/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1449e-05 - val_accuracy: 0.9416 - val_loss: 0.4855\n",
      "Epoch 1597/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2517e-05 - val_accuracy: 0.9417 - val_loss: 0.4854\n",
      "Epoch 1598/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0143e-05 - val_accuracy: 0.9417 - val_loss: 0.4855\n",
      "Epoch 1599/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0307e-05 - val_accuracy: 0.9418 - val_loss: 0.4853\n",
      "Epoch 1600/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0607e-05 - val_accuracy: 0.9416 - val_loss: 0.4857\n",
      "Epoch 1601/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0402e-05 - val_accuracy: 0.9416 - val_loss: 0.4856\n",
      "Epoch 1602/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1103e-05 - val_accuracy: 0.9416 - val_loss: 0.4855\n",
      "Epoch 1603/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1423e-05 - val_accuracy: 0.9417 - val_loss: 0.4854\n",
      "Epoch 1604/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0347e-05 - val_accuracy: 0.9417 - val_loss: 0.4853\n",
      "Epoch 1605/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.0495e-05 - val_accuracy: 0.9417 - val_loss: 0.4850\n",
      "Epoch 1606/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.9141e-06 - val_accuracy: 0.9417 - val_loss: 0.4848\n",
      "Epoch 1607/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1087e-05 - val_accuracy: 0.9417 - val_loss: 0.4847\n",
      "Epoch 1608/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.0904e-05 - val_accuracy: 0.9417 - val_loss: 0.4847\n",
      "Epoch 1609/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1023e-05 - val_accuracy: 0.9417 - val_loss: 0.4845\n",
      "Epoch 1610/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0724e-05 - val_accuracy: 0.9418 - val_loss: 0.4842\n",
      "Epoch 1611/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1280e-05 - val_accuracy: 0.9417 - val_loss: 0.4842\n",
      "Epoch 1612/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1726e-05 - val_accuracy: 0.9418 - val_loss: 0.4840\n",
      "Epoch 1613/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0660e-05 - val_accuracy: 0.9418 - val_loss: 0.4839\n",
      "Epoch 1614/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.9618e-06 - val_accuracy: 0.9417 - val_loss: 0.4843\n",
      "Epoch 1615/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0466e-05 - val_accuracy: 0.9418 - val_loss: 0.4843\n",
      "Epoch 1616/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.9786e-06 - val_accuracy: 0.9417 - val_loss: 0.4840\n",
      "Epoch 1617/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.7388e-06 - val_accuracy: 0.9418 - val_loss: 0.4842\n",
      "Epoch 1618/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0799e-05 - val_accuracy: 0.9418 - val_loss: 0.4841\n",
      "Epoch 1619/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0439e-05 - val_accuracy: 0.9418 - val_loss: 0.4840\n",
      "Epoch 1620/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.5899e-06 - val_accuracy: 0.9418 - val_loss: 0.4838\n",
      "Epoch 1621/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.9957e-06 - val_accuracy: 0.9417 - val_loss: 0.4839\n",
      "Epoch 1622/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0160e-05 - val_accuracy: 0.9416 - val_loss: 0.4835\n",
      "Epoch 1623/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.8385e-06 - val_accuracy: 0.9417 - val_loss: 0.4837\n",
      "Epoch 1624/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.1598e-06 - val_accuracy: 0.9417 - val_loss: 0.4838\n",
      "Epoch 1625/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.5961e-06 - val_accuracy: 0.9417 - val_loss: 0.4838\n",
      "Epoch 1626/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 9.0434e-06 - val_accuracy: 0.9417 - val_loss: 0.4836\n",
      "Epoch 1627/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.4244e-06 - val_accuracy: 0.9416 - val_loss: 0.4834\n",
      "Epoch 1628/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0216e-05 - val_accuracy: 0.9416 - val_loss: 0.4834\n",
      "Epoch 1629/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 9.9334e-06 - val_accuracy: 0.9417 - val_loss: 0.4832\n",
      "Epoch 1630/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.3076e-06 - val_accuracy: 0.9418 - val_loss: 0.4831\n",
      "Epoch 1631/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.0002e-05 - val_accuracy: 0.9417 - val_loss: 0.4832\n",
      "Epoch 1632/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0455e-05 - val_accuracy: 0.9417 - val_loss: 0.4832\n",
      "Epoch 1633/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.3580e-06 - val_accuracy: 0.9418 - val_loss: 0.4832\n",
      "Epoch 1634/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7445e-06 - val_accuracy: 0.9417 - val_loss: 0.4830\n",
      "Epoch 1635/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 9.6274e-06 - val_accuracy: 0.9419 - val_loss: 0.4829\n",
      "Epoch 1636/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.9199e-06 - val_accuracy: 0.9419 - val_loss: 0.4827\n",
      "Epoch 1637/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.6366e-06 - val_accuracy: 0.9418 - val_loss: 0.4829\n",
      "Epoch 1638/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.1004e-06 - val_accuracy: 0.9417 - val_loss: 0.4828\n",
      "Epoch 1639/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.6843e-06 - val_accuracy: 0.9418 - val_loss: 0.4828\n",
      "Epoch 1640/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.7773e-06 - val_accuracy: 0.9418 - val_loss: 0.4827\n",
      "Epoch 1641/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.2890e-06 - val_accuracy: 0.9418 - val_loss: 0.4825\n",
      "Epoch 1642/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.7851e-06 - val_accuracy: 0.9419 - val_loss: 0.4823\n",
      "Epoch 1643/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.1585e-06 - val_accuracy: 0.9420 - val_loss: 0.4821\n",
      "Epoch 1644/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.7536e-06 - val_accuracy: 0.9419 - val_loss: 0.4822\n",
      "Epoch 1645/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0089e-05 - val_accuracy: 0.9421 - val_loss: 0.4821\n",
      "Epoch 1646/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.8709e-06 - val_accuracy: 0.9420 - val_loss: 0.4820\n",
      "Epoch 1647/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.6915e-06 - val_accuracy: 0.9419 - val_loss: 0.4822\n",
      "Epoch 1648/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.2499e-06 - val_accuracy: 0.9419 - val_loss: 0.4821\n",
      "Epoch 1649/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.8805e-06 - val_accuracy: 0.9420 - val_loss: 0.4821\n",
      "Epoch 1650/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.6276e-06 - val_accuracy: 0.9423 - val_loss: 0.4816\n",
      "Epoch 1651/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0437e-06 - val_accuracy: 0.9423 - val_loss: 0.4818\n",
      "Epoch 1652/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.8850e-06 - val_accuracy: 0.9421 - val_loss: 0.4818\n",
      "Epoch 1653/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.8575e-06 - val_accuracy: 0.9421 - val_loss: 0.4817\n",
      "Epoch 1654/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.0221e-06 - val_accuracy: 0.9421 - val_loss: 0.4816\n",
      "Epoch 1655/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.6912e-06 - val_accuracy: 0.9423 - val_loss: 0.4813\n",
      "Epoch 1656/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.0504e-06 - val_accuracy: 0.9423 - val_loss: 0.4813\n",
      "Epoch 1657/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.3053e-06 - val_accuracy: 0.9424 - val_loss: 0.4811\n",
      "Epoch 1658/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.6208e-06 - val_accuracy: 0.9424 - val_loss: 0.4811\n",
      "Epoch 1659/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0074e-05 - val_accuracy: 0.9424 - val_loss: 0.4812\n",
      "Epoch 1660/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0962e-06 - val_accuracy: 0.9424 - val_loss: 0.4811\n",
      "Epoch 1661/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.7996e-06 - val_accuracy: 0.9424 - val_loss: 0.4809\n",
      "Epoch 1662/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.7330e-06 - val_accuracy: 0.9424 - val_loss: 0.4809\n",
      "Epoch 1663/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.2286e-06 - val_accuracy: 0.9423 - val_loss: 0.4810\n",
      "Epoch 1664/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.8028e-06 - val_accuracy: 0.9424 - val_loss: 0.4809\n",
      "Epoch 1665/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.8348e-06 - val_accuracy: 0.9424 - val_loss: 0.4808\n",
      "Epoch 1666/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.3069e-06 - val_accuracy: 0.9424 - val_loss: 0.4807\n",
      "Epoch 1667/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.0084e-06 - val_accuracy: 0.9424 - val_loss: 0.4805\n",
      "Epoch 1668/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.5145e-06 - val_accuracy: 0.9423 - val_loss: 0.4808\n",
      "Epoch 1669/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.7738e-06 - val_accuracy: 0.9423 - val_loss: 0.4808\n",
      "Epoch 1670/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.4287e-06 - val_accuracy: 0.9424 - val_loss: 0.4807\n",
      "Epoch 1671/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.7622e-06 - val_accuracy: 0.9423 - val_loss: 0.4806\n",
      "Epoch 1672/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.7186e-06 - val_accuracy: 0.9424 - val_loss: 0.4805\n",
      "Epoch 1673/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.5078e-06 - val_accuracy: 0.9425 - val_loss: 0.4803\n",
      "Epoch 1674/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5534e-06 - val_accuracy: 0.9425 - val_loss: 0.4802\n",
      "Epoch 1675/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0448e-06 - val_accuracy: 0.9424 - val_loss: 0.4802\n",
      "Epoch 1676/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.2187e-06 - val_accuracy: 0.9425 - val_loss: 0.4801\n",
      "Epoch 1677/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.8221e-06 - val_accuracy: 0.9424 - val_loss: 0.4801\n",
      "Epoch 1678/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.7560e-06 - val_accuracy: 0.9425 - val_loss: 0.4798\n",
      "Epoch 1679/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.5901e-06 - val_accuracy: 0.9425 - val_loss: 0.4796\n",
      "Epoch 1680/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.1246e-06 - val_accuracy: 0.9425 - val_loss: 0.4798\n",
      "Epoch 1681/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.4445e-06 - val_accuracy: 0.9425 - val_loss: 0.4794\n",
      "Epoch 1682/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.9039e-06 - val_accuracy: 0.9424 - val_loss: 0.4794\n",
      "Epoch 1683/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.8948e-06 - val_accuracy: 0.9424 - val_loss: 0.4793\n",
      "Epoch 1684/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.6100e-06 - val_accuracy: 0.9424 - val_loss: 0.4791\n",
      "Epoch 1685/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.7488e-06 - val_accuracy: 0.9425 - val_loss: 0.4791\n",
      "Epoch 1686/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.9286e-06 - val_accuracy: 0.9426 - val_loss: 0.4791\n",
      "Epoch 1687/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 8.0695e-06 - val_accuracy: 0.9426 - val_loss: 0.4790\n",
      "Epoch 1688/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.2908e-06 - val_accuracy: 0.9426 - val_loss: 0.4790\n",
      "Epoch 1689/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.3908e-06 - val_accuracy: 0.9426 - val_loss: 0.4792\n",
      "Epoch 1690/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 7.4205e-06 - val_accuracy: 0.9427 - val_loss: 0.4791\n",
      "Epoch 1691/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.0262e-06 - val_accuracy: 0.9426 - val_loss: 0.4789\n",
      "Epoch 1692/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3577e-06 - val_accuracy: 0.9427 - val_loss: 0.4789\n",
      "Epoch 1693/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.8696e-06 - val_accuracy: 0.9427 - val_loss: 0.4789\n",
      "Epoch 1694/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.0713e-06 - val_accuracy: 0.9427 - val_loss: 0.4789\n",
      "Epoch 1695/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9107e-06 - val_accuracy: 0.9427 - val_loss: 0.4788\n",
      "Epoch 1696/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.6157e-06 - val_accuracy: 0.9427 - val_loss: 0.4787\n",
      "Epoch 1697/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.1914e-06 - val_accuracy: 0.9427 - val_loss: 0.4786\n",
      "Epoch 1698/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.8788e-06 - val_accuracy: 0.9428 - val_loss: 0.4786\n",
      "Epoch 1699/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.4089e-06 - val_accuracy: 0.9428 - val_loss: 0.4782\n",
      "Epoch 1700/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.8340e-06 - val_accuracy: 0.9429 - val_loss: 0.4784\n",
      "Epoch 1701/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.6665e-06 - val_accuracy: 0.9427 - val_loss: 0.4783\n",
      "Epoch 1702/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.2451e-06 - val_accuracy: 0.9427 - val_loss: 0.4783\n",
      "Epoch 1703/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.4202e-06 - val_accuracy: 0.9427 - val_loss: 0.4782\n",
      "Epoch 1704/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7507e-06 - val_accuracy: 0.9427 - val_loss: 0.4780\n",
      "Epoch 1705/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.0452e-06 - val_accuracy: 0.9429 - val_loss: 0.4778\n",
      "Epoch 1706/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.1607e-06 - val_accuracy: 0.9430 - val_loss: 0.4777\n",
      "Epoch 1707/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9559e-06 - val_accuracy: 0.9430 - val_loss: 0.4777\n",
      "Epoch 1708/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.7449e-06 - val_accuracy: 0.9429 - val_loss: 0.4778\n",
      "Epoch 1709/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.0967e-06 - val_accuracy: 0.9430 - val_loss: 0.4777\n",
      "Epoch 1710/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.3359e-06 - val_accuracy: 0.9430 - val_loss: 0.4779\n",
      "Epoch 1711/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.8501e-06 - val_accuracy: 0.9430 - val_loss: 0.4778\n",
      "Epoch 1712/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.5409e-06 - val_accuracy: 0.9430 - val_loss: 0.4777\n",
      "Epoch 1713/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.7838e-06 - val_accuracy: 0.9431 - val_loss: 0.4774\n",
      "Epoch 1714/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.6105e-06 - val_accuracy: 0.9431 - val_loss: 0.4774\n",
      "Epoch 1715/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.2229e-06 - val_accuracy: 0.9430 - val_loss: 0.4777\n",
      "Epoch 1716/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.8885e-06 - val_accuracy: 0.9430 - val_loss: 0.4776\n",
      "Epoch 1717/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.3376e-06 - val_accuracy: 0.9430 - val_loss: 0.4776\n",
      "Epoch 1718/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.4909e-06 - val_accuracy: 0.9430 - val_loss: 0.4776\n",
      "Epoch 1719/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.0296e-06 - val_accuracy: 0.9430 - val_loss: 0.4774\n",
      "Epoch 1720/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.5740e-06 - val_accuracy: 0.9430 - val_loss: 0.4774\n",
      "Epoch 1721/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.3751e-06 - val_accuracy: 0.9430 - val_loss: 0.4775\n",
      "Epoch 1722/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3401e-06 - val_accuracy: 0.9430 - val_loss: 0.4774\n",
      "Epoch 1723/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 6.2447e-06 - val_accuracy: 0.9429 - val_loss: 0.4775\n",
      "Epoch 1724/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.6635e-06 - val_accuracy: 0.9430 - val_loss: 0.4773\n",
      "Epoch 1725/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.8086e-06 - val_accuracy: 0.9431 - val_loss: 0.4770\n",
      "Epoch 1726/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.3536e-06 - val_accuracy: 0.9430 - val_loss: 0.4771\n",
      "Epoch 1727/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.6486e-06 - val_accuracy: 0.9431 - val_loss: 0.4770\n",
      "Epoch 1728/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2680e-06 - val_accuracy: 0.9431 - val_loss: 0.4770\n",
      "Epoch 1729/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.6433e-06 - val_accuracy: 0.9431 - val_loss: 0.4768\n",
      "Epoch 1730/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.2388e-06 - val_accuracy: 0.9431 - val_loss: 0.4768\n",
      "Epoch 1731/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.1292e-06 - val_accuracy: 0.9431 - val_loss: 0.4768\n",
      "Epoch 1732/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2412e-06 - val_accuracy: 0.9431 - val_loss: 0.4767\n",
      "Epoch 1733/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.2587e-06 - val_accuracy: 0.9431 - val_loss: 0.4765\n",
      "Epoch 1734/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3461e-06 - val_accuracy: 0.9431 - val_loss: 0.4765\n",
      "Epoch 1735/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.9461e-06 - val_accuracy: 0.9431 - val_loss: 0.4763\n",
      "Epoch 1736/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.8161e-06 - val_accuracy: 0.9431 - val_loss: 0.4763\n",
      "Epoch 1737/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2858e-06 - val_accuracy: 0.9431 - val_loss: 0.4762\n",
      "Epoch 1738/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.2056e-06 - val_accuracy: 0.9431 - val_loss: 0.4762\n",
      "Epoch 1739/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9468e-06 - val_accuracy: 0.9431 - val_loss: 0.4762\n",
      "Epoch 1740/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.9595e-06 - val_accuracy: 0.9431 - val_loss: 0.4760\n",
      "Epoch 1741/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 7.0438e-06 - val_accuracy: 0.9431 - val_loss: 0.4762\n",
      "Epoch 1742/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.9114e-06 - val_accuracy: 0.9432 - val_loss: 0.4762\n",
      "Epoch 1743/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.2813e-06 - val_accuracy: 0.9431 - val_loss: 0.4760\n",
      "Epoch 1744/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.2316e-06 - val_accuracy: 0.9433 - val_loss: 0.4759\n",
      "Epoch 1745/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0812e-06 - val_accuracy: 0.9432 - val_loss: 0.4759\n",
      "Epoch 1746/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.4885e-06 - val_accuracy: 0.9433 - val_loss: 0.4760\n",
      "Epoch 1747/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2075e-06 - val_accuracy: 0.9433 - val_loss: 0.4759\n",
      "Epoch 1748/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.2552e-06 - val_accuracy: 0.9433 - val_loss: 0.4758\n",
      "Epoch 1749/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.8439e-06 - val_accuracy: 0.9433 - val_loss: 0.4758\n",
      "Epoch 1750/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.9982e-06 - val_accuracy: 0.9434 - val_loss: 0.4758\n",
      "Epoch 1751/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5121e-06 - val_accuracy: 0.9434 - val_loss: 0.4757\n",
      "Epoch 1752/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.4506e-06 - val_accuracy: 0.9434 - val_loss: 0.4754\n",
      "Epoch 1753/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.0664e-06 - val_accuracy: 0.9434 - val_loss: 0.4755\n",
      "Epoch 1754/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.7471e-06 - val_accuracy: 0.9434 - val_loss: 0.4753\n",
      "Epoch 1755/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9974e-06 - val_accuracy: 0.9434 - val_loss: 0.4754\n",
      "Epoch 1756/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 7.0964e-06 - val_accuracy: 0.9434 - val_loss: 0.4754\n",
      "Epoch 1757/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0503e-06 - val_accuracy: 0.9434 - val_loss: 0.4753\n",
      "Epoch 1758/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0709e-06 - val_accuracy: 0.9434 - val_loss: 0.4750\n",
      "Epoch 1759/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.1298e-06 - val_accuracy: 0.9434 - val_loss: 0.4754\n",
      "Epoch 1760/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.1351e-06 - val_accuracy: 0.9434 - val_loss: 0.4754\n",
      "Epoch 1761/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.8421e-06 - val_accuracy: 0.9434 - val_loss: 0.4753\n",
      "Epoch 1762/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.9272e-06 - val_accuracy: 0.9434 - val_loss: 0.4753\n",
      "Epoch 1763/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.7952e-06 - val_accuracy: 0.9433 - val_loss: 0.4753\n",
      "Epoch 1764/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.1809e-06 - val_accuracy: 0.9434 - val_loss: 0.4751\n",
      "Epoch 1765/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.7981e-06 - val_accuracy: 0.9434 - val_loss: 0.4747\n",
      "Epoch 1766/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.4940e-06 - val_accuracy: 0.9434 - val_loss: 0.4746\n",
      "Epoch 1767/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9503e-06 - val_accuracy: 0.9434 - val_loss: 0.4746\n",
      "Epoch 1768/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.5103e-06 - val_accuracy: 0.9434 - val_loss: 0.4744\n",
      "Epoch 1769/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.5292e-06 - val_accuracy: 0.9434 - val_loss: 0.4745\n",
      "Epoch 1770/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.4511e-06 - val_accuracy: 0.9434 - val_loss: 0.4745\n",
      "Epoch 1771/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2749e-06 - val_accuracy: 0.9434 - val_loss: 0.4742\n",
      "Epoch 1772/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.9241e-06 - val_accuracy: 0.9434 - val_loss: 0.4744\n",
      "Epoch 1773/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.5659e-06 - val_accuracy: 0.9434 - val_loss: 0.4744\n",
      "Epoch 1774/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.1394e-06 - val_accuracy: 0.9434 - val_loss: 0.4742\n",
      "Epoch 1775/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.5919e-06 - val_accuracy: 0.9434 - val_loss: 0.4742\n",
      "Epoch 1776/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.2123e-06 - val_accuracy: 0.9434 - val_loss: 0.4740\n",
      "Epoch 1777/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.0394e-06 - val_accuracy: 0.9434 - val_loss: 0.4740\n",
      "Epoch 1778/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.5571e-06 - val_accuracy: 0.9434 - val_loss: 0.4739\n",
      "Epoch 1779/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.0188e-06 - val_accuracy: 0.9434 - val_loss: 0.4740\n",
      "Epoch 1780/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.9998e-06 - val_accuracy: 0.9434 - val_loss: 0.4737\n",
      "Epoch 1781/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.4265e-06 - val_accuracy: 0.9434 - val_loss: 0.4738\n",
      "Epoch 1782/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0643e-06 - val_accuracy: 0.9434 - val_loss: 0.4738\n",
      "Epoch 1783/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3727e-06 - val_accuracy: 0.9435 - val_loss: 0.4738\n",
      "Epoch 1784/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.7797e-06 - val_accuracy: 0.9436 - val_loss: 0.4739\n",
      "Epoch 1785/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.7099e-06 - val_accuracy: 0.9436 - val_loss: 0.4738\n",
      "Epoch 1786/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2188e-06 - val_accuracy: 0.9436 - val_loss: 0.4737\n",
      "Epoch 1787/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.2788e-06 - val_accuracy: 0.9435 - val_loss: 0.4735\n",
      "Epoch 1788/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.6158e-06 - val_accuracy: 0.9435 - val_loss: 0.4734\n",
      "Epoch 1789/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.6641e-06 - val_accuracy: 0.9435 - val_loss: 0.4734\n",
      "Epoch 1790/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.8285e-06 - val_accuracy: 0.9435 - val_loss: 0.4735\n",
      "Epoch 1791/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9220e-06 - val_accuracy: 0.9436 - val_loss: 0.4736\n",
      "Epoch 1792/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.8040e-06 - val_accuracy: 0.9436 - val_loss: 0.4737\n",
      "Epoch 1793/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.2450e-06 - val_accuracy: 0.9436 - val_loss: 0.4736\n",
      "Epoch 1794/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7716e-06 - val_accuracy: 0.9436 - val_loss: 0.4734\n",
      "Epoch 1795/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8408e-06 - val_accuracy: 0.9437 - val_loss: 0.4734\n",
      "Epoch 1796/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.3245e-06 - val_accuracy: 0.9438 - val_loss: 0.4733\n",
      "Epoch 1797/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3775e-06 - val_accuracy: 0.9439 - val_loss: 0.4732\n",
      "Epoch 1798/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5423e-06 - val_accuracy: 0.9438 - val_loss: 0.4732\n",
      "Epoch 1799/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9940e-06 - val_accuracy: 0.9439 - val_loss: 0.4730\n",
      "Epoch 1800/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.7309e-06 - val_accuracy: 0.9439 - val_loss: 0.4733\n",
      "Epoch 1801/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9451e-06 - val_accuracy: 0.9439 - val_loss: 0.4731\n",
      "Epoch 1802/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.5136e-06 - val_accuracy: 0.9439 - val_loss: 0.4730\n",
      "Epoch 1803/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.4198e-06 - val_accuracy: 0.9439 - val_loss: 0.4731\n",
      "Epoch 1804/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8007e-06 - val_accuracy: 0.9438 - val_loss: 0.4733\n",
      "Epoch 1805/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 5.3132e-06 - val_accuracy: 0.9438 - val_loss: 0.4732\n",
      "Epoch 1806/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.1388e-06 - val_accuracy: 0.9438 - val_loss: 0.4730\n",
      "Epoch 1807/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0592e-06 - val_accuracy: 0.9439 - val_loss: 0.4730\n",
      "Epoch 1808/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0363e-06 - val_accuracy: 0.9439 - val_loss: 0.4727\n",
      "Epoch 1809/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0343e-06 - val_accuracy: 0.9439 - val_loss: 0.4726\n",
      "Epoch 1810/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.1094e-06 - val_accuracy: 0.9439 - val_loss: 0.4726\n",
      "Epoch 1811/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.2028e-06 - val_accuracy: 0.9439 - val_loss: 0.4724\n",
      "Epoch 1812/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.1866e-06 - val_accuracy: 0.9439 - val_loss: 0.4725\n",
      "Epoch 1813/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1807e-06 - val_accuracy: 0.9439 - val_loss: 0.4724\n",
      "Epoch 1814/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.3362e-06 - val_accuracy: 0.9439 - val_loss: 0.4724\n",
      "Epoch 1815/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.9071e-06 - val_accuracy: 0.9440 - val_loss: 0.4721\n",
      "Epoch 1816/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.3886e-06 - val_accuracy: 0.9440 - val_loss: 0.4721\n",
      "Epoch 1817/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.3252e-06 - val_accuracy: 0.9440 - val_loss: 0.4717\n",
      "Epoch 1818/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.3246e-06 - val_accuracy: 0.9441 - val_loss: 0.4717\n",
      "Epoch 1819/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.3857e-06 - val_accuracy: 0.9441 - val_loss: 0.4719\n",
      "Epoch 1820/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.7714e-06 - val_accuracy: 0.9441 - val_loss: 0.4719\n",
      "Epoch 1821/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.6105e-06 - val_accuracy: 0.9442 - val_loss: 0.4719\n",
      "Epoch 1822/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.3036e-06 - val_accuracy: 0.9442 - val_loss: 0.4718\n",
      "Epoch 1823/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.5099e-06 - val_accuracy: 0.9443 - val_loss: 0.4715\n",
      "Epoch 1824/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9502e-06 - val_accuracy: 0.9443 - val_loss: 0.4716\n",
      "Epoch 1825/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1974e-06 - val_accuracy: 0.9443 - val_loss: 0.4715\n",
      "Epoch 1826/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7145e-06 - val_accuracy: 0.9443 - val_loss: 0.4713\n",
      "Epoch 1827/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.9798e-06 - val_accuracy: 0.9443 - val_loss: 0.4714\n",
      "Epoch 1828/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8344e-06 - val_accuracy: 0.9443 - val_loss: 0.4713\n",
      "Epoch 1829/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.3574e-06 - val_accuracy: 0.9444 - val_loss: 0.4713\n",
      "Epoch 1830/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7578e-06 - val_accuracy: 0.9444 - val_loss: 0.4712\n",
      "Epoch 1831/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8357e-06 - val_accuracy: 0.9444 - val_loss: 0.4710\n",
      "Epoch 1832/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9946e-06 - val_accuracy: 0.9444 - val_loss: 0.4709\n",
      "Epoch 1833/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5489e-06 - val_accuracy: 0.9444 - val_loss: 0.4710\n",
      "Epoch 1834/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.8141e-06 - val_accuracy: 0.9445 - val_loss: 0.4710\n",
      "Epoch 1835/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.6077e-06 - val_accuracy: 0.9445 - val_loss: 0.4710\n",
      "Epoch 1836/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.0853e-06 - val_accuracy: 0.9445 - val_loss: 0.4711\n",
      "Epoch 1837/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.6201e-06 - val_accuracy: 0.9445 - val_loss: 0.4708\n",
      "Epoch 1838/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.0631e-06 - val_accuracy: 0.9445 - val_loss: 0.4707\n",
      "Epoch 1839/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.2222e-06 - val_accuracy: 0.9445 - val_loss: 0.4706\n",
      "Epoch 1840/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.3901e-06 - val_accuracy: 0.9445 - val_loss: 0.4701\n",
      "Epoch 1841/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7376e-06 - val_accuracy: 0.9445 - val_loss: 0.4701\n",
      "Epoch 1842/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.0840e-06 - val_accuracy: 0.9445 - val_loss: 0.4701\n",
      "Epoch 1843/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.2745e-06 - val_accuracy: 0.9446 - val_loss: 0.4702\n",
      "Epoch 1844/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.3533e-06 - val_accuracy: 0.9446 - val_loss: 0.4702\n",
      "Epoch 1845/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.1534e-06 - val_accuracy: 0.9446 - val_loss: 0.4704\n",
      "Epoch 1846/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8528e-06 - val_accuracy: 0.9446 - val_loss: 0.4702\n",
      "Epoch 1847/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.4422e-06 - val_accuracy: 0.9446 - val_loss: 0.4699\n",
      "Epoch 1848/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.6789e-06 - val_accuracy: 0.9446 - val_loss: 0.4698\n",
      "Epoch 1849/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4248e-06 - val_accuracy: 0.9445 - val_loss: 0.4697\n",
      "Epoch 1850/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9800e-06 - val_accuracy: 0.9445 - val_loss: 0.4699\n",
      "Epoch 1851/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.2841e-06 - val_accuracy: 0.9444 - val_loss: 0.4699\n",
      "Epoch 1852/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9464e-06 - val_accuracy: 0.9445 - val_loss: 0.4697\n",
      "Epoch 1853/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9597e-06 - val_accuracy: 0.9446 - val_loss: 0.4696\n",
      "Epoch 1854/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.8217e-06 - val_accuracy: 0.9447 - val_loss: 0.4696\n",
      "Epoch 1855/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4652e-06 - val_accuracy: 0.9447 - val_loss: 0.4694\n",
      "Epoch 1856/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0614e-06 - val_accuracy: 0.9446 - val_loss: 0.4694\n",
      "Epoch 1857/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.9394e-06 - val_accuracy: 0.9447 - val_loss: 0.4695\n",
      "Epoch 1858/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.7233e-06 - val_accuracy: 0.9446 - val_loss: 0.4696\n",
      "Epoch 1859/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.1777e-06 - val_accuracy: 0.9447 - val_loss: 0.4695\n",
      "Epoch 1860/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6812e-06 - val_accuracy: 0.9446 - val_loss: 0.4695\n",
      "Epoch 1861/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.7845e-06 - val_accuracy: 0.9445 - val_loss: 0.4696\n",
      "Epoch 1862/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.5221e-06 - val_accuracy: 0.9447 - val_loss: 0.4694\n",
      "Epoch 1863/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.1280e-06 - val_accuracy: 0.9445 - val_loss: 0.4694\n",
      "Epoch 1864/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.8161e-06 - val_accuracy: 0.9448 - val_loss: 0.4690\n",
      "Epoch 1865/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8699e-06 - val_accuracy: 0.9447 - val_loss: 0.4692\n",
      "Epoch 1866/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.0836e-06 - val_accuracy: 0.9446 - val_loss: 0.4694\n",
      "Epoch 1867/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9522e-06 - val_accuracy: 0.9446 - val_loss: 0.4697\n",
      "Epoch 1868/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5876e-06 - val_accuracy: 0.9447 - val_loss: 0.4696\n",
      "Epoch 1869/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9928e-06 - val_accuracy: 0.9450 - val_loss: 0.4693\n",
      "Epoch 1870/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2397e-06 - val_accuracy: 0.9448 - val_loss: 0.4693\n",
      "Epoch 1871/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9450e-06 - val_accuracy: 0.9448 - val_loss: 0.4692\n",
      "Epoch 1872/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.9334e-06 - val_accuracy: 0.9450 - val_loss: 0.4691\n",
      "Epoch 1873/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8452e-06 - val_accuracy: 0.9448 - val_loss: 0.4690\n",
      "Epoch 1874/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7615e-06 - val_accuracy: 0.9448 - val_loss: 0.4690\n",
      "Epoch 1875/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.7087e-06 - val_accuracy: 0.9448 - val_loss: 0.4689\n",
      "Epoch 1876/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.6785e-06 - val_accuracy: 0.9448 - val_loss: 0.4690\n",
      "Epoch 1877/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.8760e-06 - val_accuracy: 0.9448 - val_loss: 0.4687\n",
      "Epoch 1878/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8152e-06 - val_accuracy: 0.9448 - val_loss: 0.4688\n",
      "Epoch 1879/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4862e-06 - val_accuracy: 0.9448 - val_loss: 0.4688\n",
      "Epoch 1880/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.9296e-06 - val_accuracy: 0.9448 - val_loss: 0.4683\n",
      "Epoch 1881/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.9124e-06 - val_accuracy: 0.9451 - val_loss: 0.4684\n",
      "Epoch 1882/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.8842e-06 - val_accuracy: 0.9451 - val_loss: 0.4683\n",
      "Epoch 1883/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6691e-06 - val_accuracy: 0.9451 - val_loss: 0.4683\n",
      "Epoch 1884/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.8010e-06 - val_accuracy: 0.9450 - val_loss: 0.4683\n",
      "Epoch 1885/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.5578e-06 - val_accuracy: 0.9451 - val_loss: 0.4682\n",
      "Epoch 1886/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6986e-06 - val_accuracy: 0.9451 - val_loss: 0.4684\n",
      "Epoch 1887/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8120e-06 - val_accuracy: 0.9452 - val_loss: 0.4683\n",
      "Epoch 1888/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.9874e-06 - val_accuracy: 0.9451 - val_loss: 0.4683\n",
      "Epoch 1889/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6071e-06 - val_accuracy: 0.9451 - val_loss: 0.4683\n",
      "Epoch 1890/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.4298e-06 - val_accuracy: 0.9451 - val_loss: 0.4680\n",
      "Epoch 1891/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.6338e-06 - val_accuracy: 0.9453 - val_loss: 0.4679\n",
      "Epoch 1892/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6530e-06 - val_accuracy: 0.9452 - val_loss: 0.4680\n",
      "Epoch 1893/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.8652e-06 - val_accuracy: 0.9454 - val_loss: 0.4678\n",
      "Epoch 1894/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.4143e-06 - val_accuracy: 0.9454 - val_loss: 0.4679\n",
      "Epoch 1895/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9453e-06 - val_accuracy: 0.9453 - val_loss: 0.4678\n",
      "Epoch 1896/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7419e-06 - val_accuracy: 0.9455 - val_loss: 0.4676\n",
      "Epoch 1897/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5961e-06 - val_accuracy: 0.9454 - val_loss: 0.4676\n",
      "Epoch 1898/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.7031e-06 - val_accuracy: 0.9454 - val_loss: 0.4675\n",
      "Epoch 1899/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1720e-06 - val_accuracy: 0.9454 - val_loss: 0.4674\n",
      "Epoch 1900/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1202e-06 - val_accuracy: 0.9453 - val_loss: 0.4675\n",
      "Epoch 1901/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.9288e-06 - val_accuracy: 0.9454 - val_loss: 0.4673\n",
      "Epoch 1902/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.5040e-06 - val_accuracy: 0.9455 - val_loss: 0.4672\n",
      "Epoch 1903/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.2158e-06 - val_accuracy: 0.9454 - val_loss: 0.4673\n",
      "Epoch 1904/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4729e-06 - val_accuracy: 0.9455 - val_loss: 0.4674\n",
      "Epoch 1905/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.4760e-06 - val_accuracy: 0.9455 - val_loss: 0.4675\n",
      "Epoch 1906/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8433e-06 - val_accuracy: 0.9455 - val_loss: 0.4674\n",
      "Epoch 1907/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4567e-06 - val_accuracy: 0.9455 - val_loss: 0.4671\n",
      "Epoch 1908/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5513e-06 - val_accuracy: 0.9456 - val_loss: 0.4669\n",
      "Epoch 1909/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1487e-06 - val_accuracy: 0.9455 - val_loss: 0.4671\n",
      "Epoch 1910/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.4123e-06 - val_accuracy: 0.9456 - val_loss: 0.4670\n",
      "Epoch 1911/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9172e-06 - val_accuracy: 0.9456 - val_loss: 0.4668\n",
      "Epoch 1912/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.7203e-06 - val_accuracy: 0.9455 - val_loss: 0.4670\n",
      "Epoch 1913/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2196e-06 - val_accuracy: 0.9456 - val_loss: 0.4669\n",
      "Epoch 1914/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1697e-06 - val_accuracy: 0.9455 - val_loss: 0.4671\n",
      "Epoch 1915/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.6388e-06 - val_accuracy: 0.9454 - val_loss: 0.4669\n",
      "Epoch 1916/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.5516e-06 - val_accuracy: 0.9456 - val_loss: 0.4668\n",
      "Epoch 1917/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5942e-06 - val_accuracy: 0.9456 - val_loss: 0.4666\n",
      "Epoch 1918/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.4321e-06 - val_accuracy: 0.9456 - val_loss: 0.4664\n",
      "Epoch 1919/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2363e-06 - val_accuracy: 0.9456 - val_loss: 0.4664\n",
      "Epoch 1920/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.2123e-06 - val_accuracy: 0.9456 - val_loss: 0.4665\n",
      "Epoch 1921/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.7254e-06 - val_accuracy: 0.9455 - val_loss: 0.4667\n",
      "Epoch 1922/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.0002e-06 - val_accuracy: 0.9456 - val_loss: 0.4666\n",
      "Epoch 1923/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.9237e-06 - val_accuracy: 0.9456 - val_loss: 0.4664\n",
      "Epoch 1924/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.7376e-06 - val_accuracy: 0.9455 - val_loss: 0.4665\n",
      "Epoch 1925/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1685e-06 - val_accuracy: 0.9456 - val_loss: 0.4664\n",
      "Epoch 1926/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.1505e-06 - val_accuracy: 0.9457 - val_loss: 0.4664\n",
      "Epoch 1927/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.9707e-06 - val_accuracy: 0.9457 - val_loss: 0.4664\n",
      "Epoch 1928/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.6448e-06 - val_accuracy: 0.9457 - val_loss: 0.4664\n",
      "Epoch 1929/10000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.7367e-06 - val_accuracy: 0.9458 - val_loss: 0.4664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a002baf350>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(X_train_small, y_train_small,validation_data=(X_val, y_val), epochs=10000, batch_size=32, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練時間：617.21 秒\n"
     ]
    }
   ],
   "source": [
    "# 記錄結束時間\n",
    "end_time = time.time()\n",
    "\n",
    "# 計算訓練時間（秒）\n",
    "training_time = end_time - start_time\n",
    "print(f\"訓練時間：{training_time:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9444 - loss: 0.4683\n",
      "Evaluation on 90% unused data - Loss: 0.4856, Accuracy: 0.9458\n"
     ]
    }
   ],
   "source": [
    "# 使用剩餘的 90% 測試資料進行模型評估\n",
    "loss, accuracy = base_model.evaluate(X_test, y_test)\n",
    "print(f\"Evaluation on 90% unused data - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 預測\n",
    "# base_model.evaluate(X_test_scaled, y_test_numeric)  # 確保模型在測試模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-4',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '2-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-4',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-4',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-2',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '3-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-4',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '3-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-4',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-1',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '3-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '2-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '3-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-8',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-8',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '3-11',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-10',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '6-8',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " '1-11',\n",
       " ...]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 預測測試資料\n",
    "y_test_pred_numeric = base_model.predict(X_test_scaled)\n",
    "y_pred_classes = np.argmax(y_test_pred_numeric, axis=1)\n",
    "\n",
    "# 轉換為原本的 Label\n",
    "y_test_pred_labels = [label_mapping[str(num + 1)] for num in y_pred_classes]  # 補回 +1\n",
    "y_test_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>level_1</th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP2_Distance (mm)</th>\n",
       "      <th>AP3_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP2_StdDev (mm)</th>\n",
       "      <th>AP3_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>7075.00000</td>\n",
       "      <td>12054.000000</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>2406.000000</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>7192.00000</td>\n",
       "      <td>10518.000000</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>2197.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1</td>\n",
       "      <td>2</td>\n",
       "      <td>4116.000000</td>\n",
       "      <td>9155.00000</td>\n",
       "      <td>10440.000000</td>\n",
       "      <td>-303.0</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>1509.000000</td>\n",
       "      <td>1253.000000</td>\n",
       "      <td>1468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>6811.00000</td>\n",
       "      <td>10478.000000</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-65.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1161.000000</td>\n",
       "      <td>2386.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-1</td>\n",
       "      <td>4</td>\n",
       "      <td>4038.000000</td>\n",
       "      <td>6841.00000</td>\n",
       "      <td>10479.000000</td>\n",
       "      <td>-303.0</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>2075.000000</td>\n",
       "      <td>1131.000000</td>\n",
       "      <td>1509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19497</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19497</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>8218.00000</td>\n",
       "      <td>2588.000000</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>488.000000</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19498</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19498</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>8139.00000</td>\n",
       "      <td>2666.000000</td>\n",
       "      <td>4539.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19499</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19499</td>\n",
       "      <td>2085.000000</td>\n",
       "      <td>8335.00000</td>\n",
       "      <td>2588.000000</td>\n",
       "      <td>5057.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>1292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19500</td>\n",
       "      <td>2081.512821</td>\n",
       "      <td>8234.04359</td>\n",
       "      <td>2576.604113</td>\n",
       "      <td>4735.0</td>\n",
       "      <td>-55.335897</td>\n",
       "      <td>-65.969231</td>\n",
       "      <td>-50.969152</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>190.787179</td>\n",
       "      <td>488.812821</td>\n",
       "      <td>476.794344</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19501</th>\n",
       "      <td>9-11</td>\n",
       "      <td>19501</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>8257.00000</td>\n",
       "      <td>2549.000000</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>1105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19502 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  level_1  AP1_Distance (mm)  AP2_Distance (mm)  AP3_Distance (mm)  \\\n",
       "0       1-1        0        4385.000000         7075.00000       12054.000000   \n",
       "1       1-1        1        3999.000000         7192.00000       10518.000000   \n",
       "2       1-1        2        4116.000000         9155.00000       10440.000000   \n",
       "3       1-1        3        3999.000000         6811.00000       10478.000000   \n",
       "4       1-1        4        4038.000000         6841.00000       10479.000000   \n",
       "...     ...      ...                ...                ...                ...   \n",
       "19497  9-11    19497        2202.000000         8218.00000        2588.000000   \n",
       "19498  9-11    19498        2202.000000         8139.00000        2666.000000   \n",
       "19499  9-11    19499        2085.000000         8335.00000        2588.000000   \n",
       "19500  9-11    19500        2081.512821         8234.04359        2576.604113   \n",
       "19501  9-11    19501        1968.000000         8257.00000        2549.000000   \n",
       "\n",
       "       AP4_Distance (mm)   AP1_Rssi   AP2_Rssi   AP3_Rssi  AP4_Rssi  \\\n",
       "0                 -342.0 -53.000000 -71.000000 -60.000000     -47.0   \n",
       "1                 -342.0 -61.000000 -71.000000 -64.000000     -47.0   \n",
       "2                 -303.0 -60.000000 -71.000000 -64.000000     -45.0   \n",
       "3                 -342.0 -61.000000 -71.000000 -65.000000     -47.0   \n",
       "4                 -303.0 -61.000000 -71.000000 -64.000000     -47.0   \n",
       "...                  ...        ...        ...        ...       ...   \n",
       "19497             4617.0 -56.000000 -66.000000 -51.000000     -69.0   \n",
       "19498             4539.0 -56.000000 -66.000000 -51.000000     -69.0   \n",
       "19499             5057.0 -56.000000 -66.000000 -51.000000     -68.0   \n",
       "19500             4735.0 -55.335897 -65.969231 -50.969152     -68.0   \n",
       "19501             5145.0 -56.000000 -66.000000 -51.000000     -69.0   \n",
       "\n",
       "       AP1_StdDev (mm)  AP2_StdDev (mm)  AP3_StdDev (mm)  AP4_StdDev (mm)  \n",
       "0          2406.000000      1989.000000      1566.000000           1455.0  \n",
       "1          1083.000000      2197.000000      1001.000000           1488.0  \n",
       "2          1073.000000      1509.000000      1253.000000           1468.0  \n",
       "3          1161.000000      2386.000000      1177.000000           1531.0  \n",
       "4          1029.000000      2075.000000      1131.000000           1509.0  \n",
       "...                ...              ...              ...              ...  \n",
       "19497        88.000000       384.000000       488.000000            292.0  \n",
       "19498        88.000000       421.000000       419.000000            330.0  \n",
       "19499       142.000000       356.000000       442.000000           1292.0  \n",
       "19500       190.787179       488.812821       476.794344            217.0  \n",
       "19501       340.000000       401.000000       475.000000           1105.0  \n",
       "\n",
       "[19502 rows x 14 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取測試資料的實際 Label\n",
    "y_test_actual = test_data_imputed[target_column]\n",
    "test_data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data MDE report saved to: DNN 4 mcAPs BEST_2025_01_03.json\n",
      "\n",
      "Test Data Mean MDE: 0.0760 meters\n"
     ]
    }
   ],
   "source": [
    "# 取得預測與實際座標\n",
    "y_test_pred_coordinates = np.array([label_to_coordinates[label] for label in y_test_pred_labels])\n",
    "y_test_actual_coordinates = np.array([label_to_coordinates[label] for label in y_test_actual])\n",
    "\n",
    "# 計算 MDE (Mean Distance Error)\n",
    "distances = np.linalg.norm(y_test_pred_coordinates - y_test_actual_coordinates, axis=1)\n",
    "mean_mde = np.mean(distances)\n",
    "\n",
    "# 記錄每個 RP 的 MDE\n",
    "mde_report_test = {}\n",
    "for true_label, distance in zip(y_test_actual, distances):\n",
    "    if true_label not in mde_report_test:\n",
    "        mde_report_test[true_label] = []\n",
    "    mde_report_test[true_label].append(distance)\n",
    "\n",
    "# 計算測試資料的 MDE 平均值\n",
    "mde_report_test_avg = {label: {\"mde\": np.mean(dists), \"count\": len(dists)} for label, dists in mde_report_test.items()}\n",
    "\n",
    "# 儲存 MDE 結果到 JSON 檔案\n",
    "test_file_path = f\"{modelname}_{date_test}.json\"\n",
    "with open(test_file_path, \"w\") as f:\n",
    "    json.dump(mde_report_test_avg, f, indent=4)\n",
    "\n",
    "print(f\"Test Data MDE report saved to: {test_file_path}\")\n",
    "print(f\"\\nTest Data Mean MDE: {mean_mde:.4f} meters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "base_model.save(f\"DNN_best_model4mcAP_3week_to_4week_5dataPerRP.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
