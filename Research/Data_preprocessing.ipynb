{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepricessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 : txt to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2024_12_21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for input directory\n",
    "input_directory = \"txt_files_RAW_data\"  # Replace with your directory path\n",
    "output_directory = os.path.join(input_directory, f'{date}\\\\raw data')  # Output directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\10_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\11_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\12_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\13_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\14_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\15_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\16_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\17_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\18_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\19_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\1_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\20_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\21_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\22_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\23_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\24_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\25_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\26_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\27_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\28_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\29_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\2_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\30_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\31_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\32_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\33_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\34_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\35_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\36_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\37_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\38_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\39_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\3_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\40_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\41_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\42_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\43_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\44_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\45_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\46_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\47_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\48_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\49_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\4_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\5_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\6_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\7_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\8_rtt_log.csv\n",
      "File saved at: txt_files_RAW_data\\2024_12_21\\raw data\\9_rtt_log.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "\n",
    "# Regular expression pattern to match each line of data\n",
    "pattern = re.compile(\n",
    "    r\"Label: (.*?), Timestamp: (.*?), AP SSID: (.*?), BSSID: (.*?), Rssi: (-?\\d+), Distance: (-?\\d+) mm, StdDev: (\\d+) mm, timeStemp: (\\d+), mcOn: (true|false)\"\n",
    ")\n",
    "\n",
    "\n",
    "# Iterate through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".txt\"):  # Process only .txt files\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Generate output file name based on input file name (replace .txt with .csv)\n",
    "        output_file_name = filename.replace(\".txt\", \".csv\")\n",
    "        output_file_path = os.path.join(output_directory, output_file_name)\n",
    "        \n",
    "        # Open the input text file and corresponding output CSV file\n",
    "        with open(input_file_path, 'r') as infile, open(output_file_path, 'w', newline='') as outfile:\n",
    "            # Define the CSV writer\n",
    "            writer = csv.writer(outfile)\n",
    "\n",
    "            # Write the CSV header\n",
    "            writer.writerow([\"Label\", \"Timestamp\", \"AP SSID\", \"BSSID\", \"Rssi\", \"Distance (mm)\", \"StdDev (mm)\", \"timeStemp\", \"mcOn\"])\n",
    "\n",
    "            # Process each line\n",
    "            for line in infile:\n",
    "                match = pattern.match(line)\n",
    "                if match:\n",
    "                    # Extract data using groups\n",
    "                    writer.writerow(match.groups())\n",
    "                    \n",
    "        # Output the path to the saved CSV file\n",
    "        print(f\"File saved at: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : using timestamp to alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定來源資料夾和目標資料夾\n",
    "input_folder = output_directory  # 資料來源資料夾路徑\n",
    "output_folder = f'{date}\\\\timestamp allign data'  # 處理後檔案的存放資料夾路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_10_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_11_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_12_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_13_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_14_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_15_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_16_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_17_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_18_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_19_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_1_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_20_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_21_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_22_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_23_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_24_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_25_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_26_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_27_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_28_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_29_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_2_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_30_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_31_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_32_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_33_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_34_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_35_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_36_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_37_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_38_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_39_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_3_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_40_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_41_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_42_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_43_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_44_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_45_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_46_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_47_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_48_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_49_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_4_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_5_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_6_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_7_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_8_rtt_log.csv\n",
      "Processed and saved: 2024_12_21\\timestamp allign data\\processed_9_rtt_log.csv\n",
      "所有檔案處理完成！\n"
     ]
    }
   ],
   "source": [
    "# 確保目標資料夾存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 讀取資料夾中的所有檔案\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.csv'):  # 檢查是否為 CSV 檔案\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Step 1: 修改 BSSID 對應的 AP SSID\n",
    "        data.loc[data['BSSID'] == '24:29:34:e2:4c:36', 'AP SSID'] = 'AP1'\n",
    "        data.loc[data['BSSID'] == '24:29:34:e1:ef:d4', 'AP SSID'] = 'AP2'\n",
    "        data.loc[data['BSSID'] == 'e4:5e:1b:a0:5e:85', 'AP SSID'] = 'AP4'\n",
    "        data.loc[data['BSSID'] == 'b0:e4:d5:88:16:86', 'AP SSID'] = 'AP3'\n",
    "\n",
    "        # Step 2: 忽略 timeStemp 欄位的最後一位數\n",
    "        data['timeStemp'] = data['timeStemp'].astype(str).str[:-1]  # 刪除最後一位數\n",
    "        data['timeStemp'] = data['timeStemp'].astype(int)  # 轉回數字型別（如果需要）\n",
    "\n",
    "        # Step 3: Group by Timestamp 和 AP SSID，計算平均值\n",
    "        grouped_data = (\n",
    "            data.groupby(['timeStemp','Label' ,'AP SSID'])\n",
    "            .agg({\n",
    "                # 'Label': 'first',\n",
    "                'Distance (mm)': 'mean',\n",
    "                'Rssi': 'mean',\n",
    "                'StdDev (mm)': 'mean'\n",
    "            })\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Step 3: 將資料轉換成每個 Timestamp 一 row\n",
    "        pivoted_data = grouped_data.pivot(\n",
    "            \n",
    "            index=['timeStemp','Label'],\n",
    "            columns='AP SSID',\n",
    "            values=['Distance (mm)', 'Rssi', 'StdDev (mm)']\n",
    "        )\n",
    "\n",
    "        # 展平多層欄位名稱\n",
    "        pivoted_data.columns = [f\"{ap}_{metric}\" for metric, ap in pivoted_data.columns]\n",
    "        pivoted_data.reset_index(inplace=True)\n",
    "\n",
    "        # 將處理後的結果存成新的 CSV 檔案\n",
    "        output_file_path = os.path.join(output_folder, f\"processed_{file_name}\")\n",
    "        pivoted_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {output_file_path}\")\n",
    "\n",
    "print(\"所有檔案處理完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : Combine all csv to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有檔案已合併並儲存為: 2024_12_21\\timestamp_allignment_2024_12_21_rtt_logs.csv\n"
     ]
    }
   ],
   "source": [
    "# 指定資料夾路徑\n",
    "input_folder = output_folder  # 替換為你的資料夾路徑\n",
    "output_file = f'{date}\\\\timestamp_allignment_{date}_rtt_logs.csv'  # 合併後的輸出檔案名稱\n",
    "\n",
    "# 獲取資料夾內所有 CSV 檔案的路徑\n",
    "file_paths = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith('.csv')]\n",
    "\n",
    "# 合併所有 CSV 檔案\n",
    "combined_data = pd.concat([pd.read_csv(file_path) for file_path in file_paths], ignore_index=True)\n",
    "\n",
    "# 儲存合併後的檔案\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"所有檔案已合併並儲存為: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 : make all number of data in each RP the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timeStemp  Label  AP1_Distance (mm)  AP2_Distance (mm)  AP3_Distance (mm)  \\\n",
      "0  553370537     10             3256.0             7573.0              438.0   \n",
      "1  553370553     10             3217.0             7573.0              360.0   \n",
      "2  553370566     10             3256.0             7544.0              555.0   \n",
      "3  553370578     10             3178.0             8071.0             1102.0   \n",
      "4  553370594     10             3335.0            10708.0            -1045.0   \n",
      "\n",
      "   AP4_Distance (mm)  AP1_Rssi  AP2_Rssi  AP3_Rssi  AP4_Rssi  AP1_StdDev (mm)  \\\n",
      "0            10205.0     -59.0     -74.0     -59.0     -65.0            405.0   \n",
      "1            10166.0     -58.0     -73.0     -54.0     -65.0            477.0   \n",
      "2            10088.0     -59.0     -75.0     -59.0     -64.0            208.0   \n",
      "3            10205.0     -55.0     -72.0     -54.0     -62.0            680.0   \n",
      "4            10205.0     -59.0     -71.0     -51.0     -66.0            363.0   \n",
      "\n",
      "   AP2_StdDev (mm)  AP3_StdDev (mm)  AP4_StdDev (mm)  \n",
      "0           1909.0            123.0            142.0  \n",
      "1           1971.0            547.0           1640.0  \n",
      "2           1925.0            170.0            209.0  \n",
      "3           1890.0            613.0            432.0  \n",
      "4           1074.0            871.0            729.0  \n",
      "處理後的資料已儲存至 2024_12_21\\timestamp_allignment_Balanced_2024_12_21_rtt_logs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_7232\\77147034.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby('Label').apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# 讀取 Excel 檔案\n",
    "file_path = output_file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# 假設 label 的欄位名稱為 'label'\n",
    "# 計算每個 label 的資料筆數\n",
    "label_counts = df['Label'].value_counts()\n",
    "\n",
    "# 找出最少的資料筆數\n",
    "min_count = label_counts.min()\n",
    "max_count = label_counts.max()\n",
    "\n",
    "\n",
    "# 隨機抽取每個 label 的資料，使其數量等於 min_count\n",
    "df_balanced = df.groupby('Label').apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# 儲存處理後的資料\n",
    "output_path = f'{date}\\\\timestamp_allignment_Balanced_{date}_rtt_logs.csv'\n",
    "df_balanced.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"處理後的資料已儲存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 385\n",
      "Max: 546\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \" + str(min_count))\n",
    "print(\"Max: \" + str(max_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL finished\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
