{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4851\n",
      "\n",
      "=== Base Model (Same week held-out test) ===\n",
      "Base Test Accuracy: 0.9161\n",
      "Base Test MDE: 0.2258\n",
      "\n",
      "=== Cross-Week Test Result (2024_12_21) ===\n",
      "Cross Test Accuracy: 0.2117\n",
      "Cross Test MDE: 1.9980\n",
      "\n",
      "=== Cross-Week Test Result (2024_12_27) ===\n",
      "Cross Test Accuracy: 0.1512\n",
      "Cross Test MDE: 2.2101\n",
      "\n",
      "=== Cross-Week Test Result (2025_01_03) ===\n",
      "Cross Test Accuracy: 0.1135\n",
      "Cross Test MDE: 2.0307\n",
      "\n",
      "=== Cross-Week Test Result (2025_01_10) ===\n",
      "Cross Test Accuracy: 0.1142\n",
      "Cross Test MDE: 2.1273\n",
      "\n",
      "=== Cross-Week Test Result (2025_02_28) ===\n",
      "Cross Test Accuracy: 0.0939\n",
      "Cross Test MDE: 2.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\吳定洋\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\吳定洋\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\吳定洋\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- 參數設定 ---\n",
    "TRAIN_DATE = '2024_12_14'\n",
    "TEST_DATES = [\"2024_12_21\", \"2024_12_27\", \"2025_01_03\", \"2025_01_10\", \"2025_02_28\"]\n",
    "N_REMOVE = 1\n",
    "N_TRAIN = 300\n",
    "N_NEIGHBORS = 5\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    'AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi'\n",
    "]\n",
    "SELECTED_COLUMNS = ['Label'] + FEATURE_COLS\n",
    "LABEL_COL = 'Label'\n",
    "\n",
    "LABEL_TO_COORDINATES = {\n",
    "    \"1-1\": (0, 0), \"1-2\": (0.6, 0), \"1-3\": (1.2, 0), \"1-4\": (1.8, 0), \"1-5\": (2.4, 0), \"1-6\": (3.0, 0),\n",
    "    \"1-7\": (3.6, 0), \"1-8\": (4.2, 0), \"1-9\": (4.8, 0), \"1-10\": (5.4, 0), \"1-11\": (6.0, 0),\n",
    "    \"2-1\": (0, 0.6), \"2-11\": (6.0, 0.6),\n",
    "    \"3-1\": (0, 1.2), \"3-11\": (6.0, 1.2),\n",
    "    \"4-1\": (0, 1.8), \"4-11\": (6.0, 1.8),\n",
    "    \"5-1\": (0, 2.4), \"5-11\": (6.0, 2.4),\n",
    "    \"6-1\": (0, 3.0), \"6-2\": (0.6, 3.0), \"6-3\": (1.2, 3.0), \"6-4\": (1.8, 3.0), \"6-5\": (2.4, 3.0),\n",
    "    \"6-6\": (3.0, 3.0), \"6-7\": (3.6, 3.0), \"6-8\": (4.2, 3.0), \"6-9\": (4.8, 3.0), \"6-10\": (5.4, 3.0), \"6-11\": (6.0, 3.0),\n",
    "    \"7-1\": (0, 3.6), \"7-11\": (6.0, 3.6),\n",
    "    \"8-1\": (0, 4.2), \"8-11\": (6.0, 4.2),\n",
    "    \"9-1\": (0, 4.8), \"9-11\": (6.0, 4.8),\n",
    "    \"10-1\": (0, 5.4), \"10-11\": (6.0, 5.4),\n",
    "    \"11-1\": (0, 6.0), \"11-2\": (0.6, 6.0), \"11-3\": (1.2, 6.0), \"11-4\": (1.8, 6.0), \"11-5\": (2.4, 6.0),\n",
    "    \"11-6\": (3.0, 6.0), \"11-7\": (3.6, 6.0), \"11-8\": (4.2, 6.0), \"11-9\": (4.8, 6.0), \"11-10\": (5.4, 6.0), \"11-11\": (6.0, 6.0)\n",
    "}\n",
    "\n",
    "def preprocess_data(df, label_col, n_remove=1):\n",
    "    df = df.sort_values(by=label_col).reset_index(drop=True)\n",
    "    processed = []\n",
    "    for label, group in df.groupby(label_col):\n",
    "        if len(group) > 2 * n_remove:\n",
    "            group = group.iloc[n_remove:-n_remove]\n",
    "            processed.append(group)\n",
    "    if processed:\n",
    "        df = pd.concat(processed, ignore_index=True)\n",
    "        df = df.groupby(label_col).apply(lambda group: group.fillna(group.mean()))\n",
    "        df = df.reset_index(level=0)\n",
    "        df = df.reset_index(drop=True)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=df.columns)\n",
    "    return df\n",
    "\n",
    "def get_coords(labels):\n",
    "    return np.array([LABEL_TO_COORDINATES[l] for l in labels])\n",
    "\n",
    "def pointwise_mde_func(y_true, dists):\n",
    "    pointwise_mde = {}\n",
    "    for label in np.unique(y_true):\n",
    "        idx = np.where(np.array(y_true) == label)[0]\n",
    "        if len(idx) > 0:\n",
    "            pointwise_mde[label] = {\n",
    "                \"count\": len(idx),\n",
    "                \"MDE\": float(np.mean(dists[idx]))\n",
    "            }\n",
    "        else:\n",
    "            pointwise_mde[label] = {\n",
    "                \"count\": 0,\n",
    "                \"MDE\": None\n",
    "            }\n",
    "    return pointwise_mde\n",
    "\n",
    "# --- 載入並處理 base 週資料 ---\n",
    "base_df = pd.read_csv(f'timestamp_allignment_Balanced_{TRAIN_DATE}_rtt_logs.csv', usecols=SELECTED_COLUMNS)\n",
    "base_df = preprocess_data(base_df, LABEL_COL, n_remove=N_REMOVE)\n",
    "\n",
    "# --- Balanced train (每類 N_TRAIN 筆) ---\n",
    "train = base_df.groupby(LABEL_COL, group_keys=False).sample(n=N_TRAIN, replace=False, random_state=42)\n",
    "X_train = train[FEATURE_COLS].copy()\n",
    "y_train = train[LABEL_COL].copy()\n",
    "\n",
    "# --- 其餘資料作為 base test ---\n",
    "remaining = base_df.drop(train.index)\n",
    "X_base_test = remaining[FEATURE_COLS].copy()\n",
    "print(len(X_base_test))\n",
    "y_base_test = remaining[LABEL_COL].copy()\n",
    "\n",
    "# --- 用 base train fit scaler、KNN ---\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_base_test_scaled = scaler.transform(X_base_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS,weights='uniform',metric='euclidean')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Base test evaluation ---\n",
    "y_base_pred = knn.predict(X_base_test_scaled)\n",
    "base_acc = accuracy_score(y_base_test, y_base_pred)\n",
    "base_y_true_coords = get_coords(y_base_test)\n",
    "base_y_pred_coords = get_coords(y_base_pred)\n",
    "base_dists = np.linalg.norm(base_y_true_coords - base_y_pred_coords, axis=1)\n",
    "base_mde = np.mean(base_dists)\n",
    "base_pointwise_mde = pointwise_mde_func(y_base_test, base_dists)\n",
    "\n",
    "print(\"\\n=== Base Model (Same week held-out test) ===\")\n",
    "print(f\"Base Test Accuracy: {base_acc:.4f}\")\n",
    "print(f\"Base Test MDE: {base_mde:.4f}\")\n",
    "\n",
    "base_report = classification_report(y_base_test, y_base_pred, output_dict=True)\n",
    "base_report[\"Mean Distance Error (MDE)\"] = float(base_mde)\n",
    "base_report[\"accuracy\"] = float(base_acc)\n",
    "base_report[\"Pointwise MDE\"] = base_pointwise_mde\n",
    "with open(f'basemodel_{TRAIN_DATE}_base_test_{N_TRAIN}_each.json', \"w\") as f:\n",
    "    json.dump(base_report, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# --- Loop cross-week test ---\n",
    "for test_date in TEST_DATES:\n",
    "    cross_df = pd.read_csv(f'timestamp_allignment_Balanced_{test_date}_rtt_logs.csv', usecols=SELECTED_COLUMNS)\n",
    "    cross_df = preprocess_data(cross_df, LABEL_COL, n_remove=N_REMOVE)\n",
    "    X_cross_test = cross_df[FEATURE_COLS].copy()\n",
    "    y_cross_test = cross_df[LABEL_COL].copy()\n",
    "    X_cross_test_scaled = scaler.transform(X_cross_test)\n",
    "    y_cross_pred = knn.predict(X_cross_test_scaled)\n",
    "\n",
    "    cross_acc = accuracy_score(y_cross_test, y_cross_pred)\n",
    "    cross_y_true_coords = get_coords(y_cross_test)\n",
    "    cross_y_pred_coords = get_coords(y_cross_pred)\n",
    "    cross_dists = np.linalg.norm(cross_y_true_coords - cross_y_pred_coords, axis=1)\n",
    "    cross_mde = np.mean(cross_dists)\n",
    "    cross_pointwise_mde = pointwise_mde_func(y_cross_test, cross_dists)\n",
    "\n",
    "    print(f\"\\n=== Cross-Week Test Result ({test_date}) ===\")\n",
    "    print(f\"Cross Test Accuracy: {cross_acc:.4f}\")\n",
    "    print(f\"Cross Test MDE: {cross_mde:.4f}\")\n",
    "\n",
    "    cross_report = classification_report(y_cross_test, y_cross_pred, output_dict=True)\n",
    "    cross_report[\"Mean Distance Error (MDE)\"] = float(cross_mde)\n",
    "    cross_report[\"accuracy\"] = float(cross_acc)\n",
    "    cross_report[\"Pointwise MDE\"] = cross_pointwise_mde\n",
    "    with open(f'transfer_report_{TRAIN_DATE}_train_{test_date}_test_{N_TRAIN}_each.json', \"w\") as f:\n",
    "        json.dump(cross_report, f, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
