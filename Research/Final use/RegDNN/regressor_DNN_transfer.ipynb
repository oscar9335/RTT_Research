{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_coordinates = {\n",
    "    \"1-1\": (0, 0), \"1-2\": (0.6, 0), \"1-3\": (1.2, 0), \"1-4\": (1.8, 0), \"1-5\": (2.4, 0), \"1-6\": (3.0, 0),\"1-7\": (3.6, 0), \"1-8\": (4.2, 0), \"1-9\": (4.8, 0), \"1-10\": (5.4, 0), \"1-11\": (6.0, 0),\n",
    "    \"2-1\": (0, 0.6), \"2-11\": (6.0, 0.6),\n",
    "    \"3-1\": (0, 1.2), \"3-11\": (6.0, 1.2),\n",
    "    \"4-1\": (0, 1.8), \"4-11\": (6.0, 1.8),\n",
    "    \"5-1\": (0, 2.4), \"5-11\": (6.0, 2.4),\n",
    "    \"6-1\": (0, 3.0), \"6-2\": (0.6, 3.0), \"6-3\": (1.2, 3.0), \"6-4\": (1.8, 3.0), \"6-5\": (2.4, 3.0),\"6-6\": (3.0, 3.0), \"6-7\": (3.6, 3.0), \"6-8\": (4.2, 3.0), \"6-9\": (4.8, 3.0), \"6-10\": (5.4, 3.0), \"6-11\": (6.0, 3.0),\n",
    "    \"7-1\": (0, 3.6), \"7-11\": (6.0, 3.6),\n",
    "    \"8-1\": (0, 4.2), \"8-11\": (6.0, 4.2),\n",
    "    \"9-1\": (0, 4.8), \"9-11\": (6.0, 4.8),\n",
    "    \"10-1\": (0, 5.4), \"10-11\": (6.0, 5.4),\n",
    "    \"11-1\": (0, 6.0), \"11-2\": (0.6, 6.0), \"11-3\": (1.2, 6.0), \"11-4\": (1.8, 6.0), \"11-5\": (2.4, 6.0),\"11-6\": (3.0, 6.0), \"11-7\": (3.6, 6.0), \"11-8\": (4.2, 6.0), \"11-9\": (4.8, 6.0), \"11-10\": (5.4, 6.0), \"11-11\": (6.0, 6.0)\n",
    "}\n",
    "label_mapping = {\n",
    "    '11': '1-1','10': '1-2','9': '1-3','8': '1-4','7': '1-5','6': '1-6','5': '1-7','4': '1-8','3': '1-9','2': '1-10','1': '1-11',\n",
    "    '12': '2-1','30': '2-11',\n",
    "    '13': '3-1','29': '3-11',\n",
    "    '14': '4-1','28': '4-11',\n",
    "    '15': '5-1','27': '5-11',\n",
    "    '16': '6-1','17': '6-2','18': '6-3','19': '6-4','20': '6-5','21': '6-6','22': '6-7','23': '6-8','24': '6-9','25': '6-10','26': '6-11',\n",
    "    '49': '7-1','31': '7-11',\n",
    "    '48': '8-1','32': '8-11',\n",
    "    '47': '9-1','33': '9-11',\n",
    "    '46': '10-1','34': '10-11',\n",
    "    '45': '11-1','44': '11-2','43': '11-3','42': '11-4','41': '11-5','40': '11-6','39': '11-7','38': '11-8','37': '11-9','36': '11-10','35': '11-11'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import joblib  # 用於保存模型\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Label',\n",
    "                    'AP1_Distance (mm)','AP4_Distance (mm)',\n",
    "                    'AP1_StdDev (mm)', 'AP4_StdDev (mm)',\n",
    "                    'AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi']  \n",
    "\n",
    "scaler_columns = ['AP1_Distance (mm)', 'AP4_Distance (mm)', \n",
    "                  'AP1_StdDev (mm)', 'AP4_StdDev (mm)', \n",
    "                  'AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi',\n",
    "                  'AP2_Distance_predicted', 'AP3_Distance_predicted']\n",
    "\n",
    "label_column = 'Label'\n",
    "target_column = 'Label'\n",
    "\n",
    "\n",
    "#  'AP1_Rssi','AP2_Rssi','AP3_Rssi','AP4_Rssi'\n",
    "# 'AP1_Distance (mm)','AP2_Distance (mm)','AP3_Distance (mm)','AP4_Distance (mm)',\n",
    "# 'AP1_StdDev (mm)','AP2_StdDev (mm)','AP3_StdDev (mm)','AP4_StdDev (mm)',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = 'AP1&AP4'\n",
    "root = 'AP1 AP4 best (MDE_0.0107Accuracy_0.9917 )'\n",
    "\n",
    "dataamount = 20\n",
    "N_val = 4\n",
    "\n",
    "N_train = dataamount # 訓練集每個類別至少要有 N_train 筆資料\n",
    "test_val_ratio = 1  # 剩餘資料中，50% 作為驗證集，50% 作為測試集\n",
    "\n",
    "weekrepresent = [['0','0'],['0','1'],['1','2'],['2','3'],['3','4'],['4','5']]\n",
    "alldatadate = ['2024_12_21','2024_12_27','2025_01_03','2025_01_10','2025_02_28']\n",
    "number_of_week = len(alldatadate)\n",
    "\n",
    "ALL_trainingtime = []\n",
    "ALL_loss = []\n",
    "ALL_accuracy = []\n",
    "ALL_mean_mde = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,185</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)             │         \u001b[38;5;34m3,185\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,467</span> (79.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,467\u001b[0m (79.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,185</span> (12.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,185\u001b[0m (12.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,280</span> (67.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,280\u001b[0m (67.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Label', 'level_1', 'AP1_Distance (mm)', 'AP4_Distance (mm)',\n",
      "       'AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi', 'AP1_StdDev (mm)',\n",
      "       'AP4_StdDev (mm)'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>444.0</td>\n",
       "      <td>7366.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>444.0</td>\n",
       "      <td>7444.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>327.0</td>\n",
       "      <td>7353.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>483.0</td>\n",
       "      <td>6987.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>483.0</td>\n",
       "      <td>7353.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16769</th>\n",
       "      <td>6313.0</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16647</th>\n",
       "      <td>5903.0</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16719</th>\n",
       "      <td>6343.0</td>\n",
       "      <td>7822.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16567</th>\n",
       "      <td>6313.0</td>\n",
       "      <td>7588.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16838</th>\n",
       "      <td>6050.0</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AP1_Distance (mm)  AP4_Distance (mm)  AP1_Rssi  AP2_Rssi  AP3_Rssi  \\\n",
       "1038               444.0             7366.0     -60.0     -71.0     -64.0   \n",
       "1020               444.0             7444.0     -59.0     -71.0     -62.0   \n",
       "1125               327.0             7353.0     -59.0     -71.0     -63.0   \n",
       "1102               483.0             6987.0     -59.0     -71.0     -62.0   \n",
       "826                483.0             7353.0     -60.0     -71.0     -56.0   \n",
       "...                  ...                ...       ...       ...       ...   \n",
       "16769             6313.0             7666.0     -71.0     -74.0     -60.0   \n",
       "16647             5903.0             7666.0     -70.0     -76.0     -58.0   \n",
       "16719             6343.0             7822.0     -71.0     -75.0     -59.0   \n",
       "16567             6313.0             7588.0     -72.0     -74.0     -61.0   \n",
       "16838             6050.0             7744.0     -73.0     -73.0     -59.0   \n",
       "\n",
       "       AP4_Rssi  AP1_StdDev (mm)  AP4_StdDev (mm)  label  \n",
       "1038      -52.0            791.0            381.0      0  \n",
       "1020      -49.0            905.0            295.0      0  \n",
       "1125      -50.0            757.0            792.0      0  \n",
       "1102      -50.0            743.0           1011.0      0  \n",
       "826       -54.0            729.0            410.0      0  \n",
       "...         ...              ...              ...    ...  \n",
       "16769     -61.0            946.0            756.0     48  \n",
       "16647     -60.0           1071.0            731.0     48  \n",
       "16719     -60.0            892.0            707.0     48  \n",
       "16567     -61.0            929.0            751.0     48  \n",
       "16838     -60.0           1116.0            657.0     48  \n",
       "\n",
       "[980 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入 regressor\n",
    "base_model_reg = joblib.load(f'{root}/regressor_model_{ap}_best_{weekrepresent[0][0]}week_to_{weekrepresent[0][1]}week_{dataamount}dataPerRP.pkl')\n",
    "# 載入 regressor dnn\n",
    "base_model_dnn = load_model(f'{root}/regressor_dnn_{ap}_best_{weekrepresent[0][0]}week_to_{weekrepresent[0][1]}week_{dataamount}dataPerRP.h5')\n",
    "# 載入 scaler\n",
    "scaler = joblib.load(f'{root}/scaler_regressor_dnn_{ap}_best_0.pkl')\n",
    "\n",
    "# 讀取測試資料 2024_12_21   2024_12_27   2025_01_03   2025_01_10   2025_02_28\n",
    "test_file_path = f\"timestamp_allignment_Balanced_{alldatadate[0]}_rtt_logs.csv\"  # 測試資料的檔案名稱\n",
    "date_test = f\"{alldatadate[0]}\"\n",
    "modelname = f\"regressor_DNN {ap}s BEST_{dataamount}data_{alldatadate[0]}\"\n",
    "data = pd.read_csv(test_file_path, usecols=selected_columns)\n",
    "\n",
    "\n",
    "# DNN transfer learnging 凍結所有層\n",
    "for layer in base_model_dnn.layers[:-1]:  # 除了最後一層 (Output Layer)\n",
    "    layer.trainable = False\n",
    "\n",
    "# 確認哪些層可訓練\n",
    "base_model_dnn.summary()\n",
    "\n",
    "base_model_dnn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "data_imputed = data.groupby(label_column).apply(\n",
    "    lambda group: group.fillna(group.mean())\n",
    ").reset_index()\n",
    "\n",
    "print(data_imputed.columns)\n",
    "\n",
    "\n",
    "reverse_label_mapping = {v: int(k) - 1 for k, v in label_mapping.items()}  # 讓數字標籤 -1\n",
    "\n",
    "y = data_imputed[target_column]\n",
    "\n",
    "y_numeric = y.map(reverse_label_mapping)\n",
    "y_numeric\n",
    "\n",
    "# 把label部分拿掉\n",
    "X = data_imputed.drop(columns=['level_1','Label'])\n",
    "# print(X.head())\n",
    "\n",
    "# 轉為 DataFrame 方便操作\n",
    "data = pd.DataFrame(X)\n",
    "data['label'] = y_numeric  # 加入 label 欄位\n",
    "\n",
    "train_data_full = data.groupby('label', group_keys=False).sample(n=N_train, replace=False, random_state=42)\n",
    "train_data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP1_Distance (mm)</th>\n",
       "      <th>AP4_Distance (mm)</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>AP1_StdDev (mm)</th>\n",
       "      <th>AP4_StdDev (mm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>102.0</td>\n",
       "      <td>8408.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>2475.0</td>\n",
       "      <td>9079.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>4038.0</td>\n",
       "      <td>4541.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>-746.0</td>\n",
       "      <td>6181.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504</th>\n",
       "      <td>3999.0</td>\n",
       "      <td>6728.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>-102.0</td>\n",
       "      <td>7354.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>2827.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>1655.0</td>\n",
       "      <td>6377.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16821</th>\n",
       "      <td>6255.0</td>\n",
       "      <td>7861.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5229</th>\n",
       "      <td>5478.0</td>\n",
       "      <td>6768.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AP1_Distance (mm)  AP4_Distance (mm)  AP1_Rssi  AP2_Rssi  AP3_Rssi  \\\n",
       "3532               102.0             8408.0     -61.0     -69.0     -59.0   \n",
       "1961              2475.0             9079.0     -59.0     -69.0     -51.0   \n",
       "7003              4038.0             4541.0     -69.0     -53.0     -65.0   \n",
       "10745             -746.0             6181.0     -53.0     -71.0     -63.0   \n",
       "14504             3999.0             6728.0     -60.0     -69.0     -53.0   \n",
       "...                  ...                ...       ...       ...       ...   \n",
       "4011              -102.0             7354.0     -57.0     -76.0     -52.0   \n",
       "6139              2827.0              908.0     -59.0     -70.0     -57.0   \n",
       "14637             1655.0             6377.0     -59.0     -65.0     -54.0   \n",
       "16821             6255.0             7861.0     -76.0     -74.0     -61.0   \n",
       "5229              5478.0             6768.0     -63.0     -59.0     -62.0   \n",
       "\n",
       "       AP4_Rssi  AP1_StdDev (mm)  AP4_StdDev (mm)  label  \n",
       "3532      -58.0            263.0           1133.0      3  \n",
       "1961      -55.0           1335.0            572.0      7  \n",
       "7003      -58.0           2301.0           1164.0     41  \n",
       "10745     -54.0           1460.0            308.0     28  \n",
       "14504     -57.0           1221.0            463.0     18  \n",
       "...         ...              ...              ...    ...  \n",
       "4011      -65.0            220.0            685.0      2  \n",
       "6139      -51.0            336.0            716.0     34  \n",
       "14637     -58.0           1470.0            353.0     19  \n",
       "16821     -60.0            745.0            418.0     48  \n",
       "5229      -58.0           1290.0            121.0     44  \n",
       "\n",
       "[784 rows x 9 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if N_val > 0:\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=N_val / N_train) # , random_state=42\n",
    "    train_index, val_index = next(sss.split(train_data_full.drop(columns=['label']), train_data_full['label']))\n",
    "    train_data = train_data_full.iloc[train_index]\n",
    "    val_data = train_data_full.iloc[val_index]\n",
    "    \n",
    "else:\n",
    "    val_data = pd.DataFrame(columns=data.columns)  # 若沒有 validation data，建立空 DataFrame\\\n",
    "    train_data = train_data_full\n",
    "\n",
    "# 剩下的資料（未被抽入 train_data_full 的部分）直接作為 test set\n",
    "remaining_data = data.drop(train_data_full.index)\n",
    "train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新後模型的係數： [-261.6538974] 截距： [-11595.57222957]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AP1 AP4 best (MDE_0.0107Accuracy_0.9917 )/regressor_model_AP1&AP4_best_0week_to_1week_20dataPerRP.pkl']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練 regressor 並儲存\n",
    "ap1_data = train_data[['AP1_Rssi', 'AP1_Distance (mm)']].dropna().rename(\n",
    "    columns={'AP1_Rssi': 'Rssi', 'AP1_Distance (mm)': 'Distance'}\n",
    ")\n",
    "ap4_data = train_data[['AP4_Rssi', 'AP4_Distance (mm)']].dropna().rename(\n",
    "    columns={'AP4_Rssi': 'Rssi', 'AP4_Distance (mm)': 'Distance'}\n",
    ")\n",
    "\n",
    "train_data_reg = pd.concat([ap1_data, ap4_data], ignore_index=True)\n",
    "\n",
    "\n",
    "X_train_reg = train_data_reg[['Rssi']]\n",
    "y_train_reg = train_data_reg['Distance']\n",
    "\n",
    "# 重新訓練模型（fine tuning）\n",
    "model_reg_finetuned = base_model_reg\n",
    "model_reg_finetuned.partial_fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# 檢查更新後的係數與截距\n",
    "print(\"更新後模型的係數：\", model_reg_finetuned.coef_, \"截距：\", model_reg_finetuned.intercept_)\n",
    "\n",
    "# 儲存更新後的模型\n",
    "joblib.dump(model_reg_finetuned,f'{root}/regressor_model_{ap}_best_{weekrepresent[1][0]}week_to_{weekrepresent[1][1]}week_{dataamount}dataPerRP.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_16044\\3008064601.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['AP2_Distance_predicted'] = np.nan\n",
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_16044\\3008064601.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['AP3_Distance_predicted'] = np.nan\n",
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_16044\\3008064601.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['AP2_Distance_predicted'] = np.nan\n",
      "C:\\Users\\吳定洋\\AppData\\Local\\Temp\\ipykernel_16044\\3008064601.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['AP3_Distance_predicted'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "### train data\n",
    "train_data['AP2_Distance_predicted'] = np.nan\n",
    "train_data['AP3_Distance_predicted'] = np.nan\n",
    "\n",
    "# 利用 AP2_Rssi 預測 AP2_Distance_predicted\n",
    "mask_ap2 = train_data['AP2_Rssi'].notna()\n",
    "train_data.loc[mask_ap2, 'AP2_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    train_data.loc[mask_ap2, ['AP2_Rssi']].rename(columns={'AP2_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 利用 AP3_Rssi 預測 AP3_Distance_predicted\n",
    "mask_ap3 = train_data['AP3_Rssi'].notna()\n",
    "train_data.loc[mask_ap3, 'AP3_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    train_data.loc[mask_ap3, ['AP3_Rssi']].rename(columns={'AP3_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "### val data\n",
    "val_data['AP2_Distance_predicted'] = np.nan\n",
    "val_data['AP3_Distance_predicted'] = np.nan\n",
    "\n",
    "# 利用 AP2_Rssi 預測 AP2_Distance_predicted\n",
    "mask_ap2 = val_data['AP2_Rssi'].notna()\n",
    "val_data.loc[mask_ap2, 'AP2_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    val_data.loc[mask_ap2, ['AP2_Rssi']].rename(columns={'AP2_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 利用 AP3_Rssi 預測 AP3_Distance_predicted\n",
    "mask_ap3 = val_data['AP3_Rssi'].notna()\n",
    "val_data.loc[mask_ap3, 'AP3_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    val_data.loc[mask_ap3, ['AP3_Rssi']].rename(columns={'AP3_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "### remaining data\n",
    "remaining_data['AP2_Distance_predicted'] = np.nan\n",
    "remaining_data['AP3_Distance_predicted'] = np.nan\n",
    "\n",
    "# 利用 AP2_Rssi 預測 AP2_Distance_predicted\n",
    "mask_ap2 = remaining_data['AP2_Rssi'].notna()\n",
    "remaining_data.loc[mask_ap2, 'AP2_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    remaining_data.loc[mask_ap2, ['AP2_Rssi']].rename(columns={'AP2_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 利用 AP3_Rssi 預測 AP3_Distance_predicted\n",
    "mask_ap3 = remaining_data['AP3_Rssi'].notna()\n",
    "remaining_data.loc[mask_ap3, 'AP3_Distance_predicted'] = model_reg_finetuned.predict(\n",
    "    remaining_data.loc[mask_ap3, ['AP3_Rssi']].rename(columns={'AP3_Rssi': 'Rssi'})\n",
    ")\n",
    "\n",
    "# 更新 DNN 模型用的特徵欄位，將 regressor 預測值加入\n",
    "selected_columns_dnn = selected_columns + ['AP2_Distance_predicted', 'AP3_Distance_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AP1_Distance (mm)', 'AP4_Distance (mm)', 'AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi', 'AP1_StdDev (mm)', 'AP4_StdDev (mm)', 'label', 'AP2_Distance_predicted', 'AP3_Distance_predicted']\n"
     ]
    }
   ],
   "source": [
    "print(list(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料數量： 784\n",
      "驗證資料數量： 196\n",
      "測試資料數量： 17885\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 準備 DNN 模型的輸入\n",
    "# 這邊重點：保留 DataFrame 結構，依據 scaler_columns 選取正確欄位，再進行 scaler.transform\n",
    "# -------------------------------\n",
    "# 選取訓練、驗證、測試集中的 scaler_columns（順序需與訓練時一致）\n",
    "X_train_df = train_data[scaler_columns].copy()\n",
    "y_train = train_data['label'].values\n",
    "\n",
    "X_val_df = val_data[scaler_columns].copy()\n",
    "y_val = val_data['label'].values\n",
    "\n",
    "X_test_df = remaining_data[scaler_columns].copy()\n",
    "y_test = remaining_data['label'].values\n",
    "\n",
    "# 使用預先訓練的 scaler 進行標準化\n",
    "X_scaled_train = scaler.transform(X_train_df)\n",
    "X_scaled_val = scaler.transform(X_val_df)\n",
    "X_scaled_test = scaler.transform(X_test_df)\n",
    "\n",
    "print(\"訓練資料數量：\", len(X_scaled_train))\n",
    "print(\"驗證資料數量：\", len(X_scaled_val))\n",
    "print(\"測試資料數量：\", len(X_scaled_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "      <th>Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training Set  Validation Set  Test Set\n",
       "0             16               4       365\n",
       "1             16               4       365\n",
       "2             16               4       365\n",
       "3             16               4       365\n",
       "4             16               4       365\n",
       "5             16               4       365\n",
       "6             16               4       365\n",
       "7             16               4       365\n",
       "8             16               4       365\n",
       "9             16               4       365\n",
       "10            16               4       365\n",
       "11            16               4       365\n",
       "12            16               4       365\n",
       "13            16               4       365\n",
       "14            16               4       365\n",
       "15            16               4       365\n",
       "16            16               4       365\n",
       "17            16               4       365\n",
       "18            16               4       365\n",
       "19            16               4       365\n",
       "20            16               4       365\n",
       "21            16               4       365\n",
       "22            16               4       365\n",
       "23            16               4       365\n",
       "24            16               4       365\n",
       "25            16               4       365\n",
       "26            16               4       365\n",
       "27            16               4       365\n",
       "28            16               4       365\n",
       "29            16               4       365\n",
       "30            16               4       365\n",
       "31            16               4       365\n",
       "32            16               4       365\n",
       "33            16               4       365\n",
       "34            16               4       365\n",
       "35            16               4       365\n",
       "36            16               4       365\n",
       "37            16               4       365\n",
       "38            16               4       365\n",
       "39            16               4       365\n",
       "40            16               4       365\n",
       "41            16               4       365\n",
       "42            16               4       365\n",
       "43            16               4       365\n",
       "44            16               4       365\n",
       "45            16               4       365\n",
       "46            16               4       365\n",
       "47            16               4       365\n",
       "48            16               4       365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# **轉換為 NumPy 陣列**\n",
    "X_train, y_train = train_data.drop(columns=['label']).values, train_data['label'].values\n",
    "X_val, y_val = val_data.drop(columns=['label']).values, val_data['label'].values\n",
    "X_test, y_test = remaining_data.drop(columns=['label']).values, remaining_data['label'].values\n",
    "\n",
    "\n",
    "# **計算每個 Set 內各 Label 的資料數量**\n",
    "train_label_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "val_label_counts = pd.Series(y_val).value_counts().sort_index()\n",
    "test_label_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "# **確保所有 Labels 都有出現在三個 Set 裡**\n",
    "all_labels = sorted(set(train_label_counts.index) | set(val_label_counts.index) | set(test_label_counts.index))\n",
    "label_distribution = pd.DataFrame(index=all_labels)\n",
    "\n",
    "label_distribution[\"Training Set\"] = train_label_counts\n",
    "label_distribution[\"Validation Set\"] = val_label_counts\n",
    "label_distribution[\"Test Set\"] = test_label_counts\n",
    "\n",
    "# **用 0 填補缺失值（表示該 Label 在該 Set 中沒有數據）**\n",
    "label_distribution = label_distribution.fillna(0).astype(int)\n",
    "\n",
    "from IPython.display import display\n",
    "display(label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2682 - loss: 9.0840 - val_accuracy: 0.3520 - val_loss: 6.3776\n",
      "Epoch 2/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3737 - loss: 5.5995 - val_accuracy: 0.4337 - val_loss: 4.3996\n",
      "Epoch 3/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4783 - loss: 3.8537 - val_accuracy: 0.5000 - val_loss: 3.2321\n",
      "Epoch 4/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5788 - loss: 2.5740 - val_accuracy: 0.5612 - val_loss: 2.4387\n",
      "Epoch 5/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 2.0576 - val_accuracy: 0.6122 - val_loss: 1.8767\n",
      "Epoch 6/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 1.6950 - val_accuracy: 0.6735 - val_loss: 1.5218\n",
      "Epoch 7/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 1.0842 - val_accuracy: 0.7041 - val_loss: 1.2805\n",
      "Epoch 8/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7548 - loss: 0.9613 - val_accuracy: 0.7704 - val_loss: 1.0947\n",
      "Epoch 9/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.8659 - val_accuracy: 0.8010 - val_loss: 0.9695\n",
      "Epoch 10/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 0.5891 - val_accuracy: 0.8469 - val_loss: 0.8796\n",
      "Epoch 11/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.5071 - val_accuracy: 0.8520 - val_loss: 0.8158\n",
      "Epoch 12/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8656 - loss: 0.5394 - val_accuracy: 0.8724 - val_loss: 0.7576\n",
      "Epoch 13/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.4139 - val_accuracy: 0.8673 - val_loss: 0.7157\n",
      "Epoch 14/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.4423 - val_accuracy: 0.8776 - val_loss: 0.6869\n",
      "Epoch 15/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.3977 - val_accuracy: 0.8929 - val_loss: 0.6566\n",
      "Epoch 16/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.3521 - val_accuracy: 0.8929 - val_loss: 0.6258\n",
      "Epoch 17/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.3041 - val_accuracy: 0.9082 - val_loss: 0.6106\n",
      "Epoch 18/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.2640 - val_accuracy: 0.9031 - val_loss: 0.5817\n",
      "Epoch 19/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.2759 - val_accuracy: 0.9235 - val_loss: 0.5709\n",
      "Epoch 20/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9342 - loss: 0.2538 - val_accuracy: 0.9133 - val_loss: 0.5514\n",
      "Epoch 21/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.2378 - val_accuracy: 0.9235 - val_loss: 0.5376\n",
      "Epoch 22/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.1846 - val_accuracy: 0.9235 - val_loss: 0.5233\n",
      "Epoch 23/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1865 - val_accuracy: 0.9286 - val_loss: 0.5194\n",
      "Epoch 24/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.2263 - val_accuracy: 0.9286 - val_loss: 0.5037\n",
      "Epoch 25/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.1690 - val_accuracy: 0.9286 - val_loss: 0.4995\n",
      "Epoch 26/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9603 - loss: 0.1995 - val_accuracy: 0.9337 - val_loss: 0.4891\n",
      "Epoch 27/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1615 - val_accuracy: 0.9286 - val_loss: 0.4839\n",
      "Epoch 28/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9637 - loss: 0.1697 - val_accuracy: 0.9337 - val_loss: 0.4791\n",
      "Epoch 29/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.1381 - val_accuracy: 0.9439 - val_loss: 0.4721\n",
      "Epoch 30/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.1341 - val_accuracy: 0.9490 - val_loss: 0.4720\n",
      "Epoch 31/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.1458 - val_accuracy: 0.9490 - val_loss: 0.4612\n",
      "Epoch 32/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.1630 - val_accuracy: 0.9541 - val_loss: 0.4596\n",
      "Epoch 33/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1637 - val_accuracy: 0.9439 - val_loss: 0.4561\n",
      "Epoch 34/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.1292 - val_accuracy: 0.9490 - val_loss: 0.4502\n",
      "Epoch 35/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.1149 - val_accuracy: 0.9490 - val_loss: 0.4459\n",
      "Epoch 36/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.1218 - val_accuracy: 0.9490 - val_loss: 0.4438\n",
      "Epoch 37/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1139 - val_accuracy: 0.9490 - val_loss: 0.4405\n",
      "Epoch 38/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0852 - val_accuracy: 0.9439 - val_loss: 0.4359\n",
      "Epoch 39/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.0813 - val_accuracy: 0.9490 - val_loss: 0.4319\n",
      "Epoch 40/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0944 - val_accuracy: 0.9490 - val_loss: 0.4326\n",
      "Epoch 41/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1096 - val_accuracy: 0.9541 - val_loss: 0.4302\n",
      "Epoch 42/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0743 - val_accuracy: 0.9490 - val_loss: 0.4259\n",
      "Epoch 43/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0685 - val_accuracy: 0.9541 - val_loss: 0.4252\n",
      "Epoch 44/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.0783 - val_accuracy: 0.9541 - val_loss: 0.4225\n",
      "Epoch 45/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0736 - val_accuracy: 0.9541 - val_loss: 0.4219\n",
      "Epoch 46/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0608 - val_accuracy: 0.9541 - val_loss: 0.4184\n",
      "Epoch 47/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0481 - val_accuracy: 0.9490 - val_loss: 0.4211\n",
      "Epoch 48/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0432 - val_accuracy: 0.9541 - val_loss: 0.4188\n",
      "Epoch 49/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0520 - val_accuracy: 0.9592 - val_loss: 0.4159\n",
      "Epoch 50/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0616 - val_accuracy: 0.9490 - val_loss: 0.4156\n",
      "Epoch 51/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0592 - val_accuracy: 0.9490 - val_loss: 0.4128\n",
      "Epoch 52/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0429 - val_accuracy: 0.9541 - val_loss: 0.4150\n",
      "Epoch 53/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0484 - val_accuracy: 0.9541 - val_loss: 0.4095\n",
      "Epoch 54/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0442 - val_accuracy: 0.9541 - val_loss: 0.4090\n",
      "Epoch 55/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0393 - val_accuracy: 0.9643 - val_loss: 0.4091\n",
      "Epoch 56/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0400 - val_accuracy: 0.9541 - val_loss: 0.4078\n",
      "Epoch 57/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0409 - val_accuracy: 0.9592 - val_loss: 0.4061\n",
      "Epoch 58/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0428 - val_accuracy: 0.9643 - val_loss: 0.4070\n",
      "Epoch 59/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0327 - val_accuracy: 0.9643 - val_loss: 0.4022\n",
      "Epoch 60/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0372 - val_accuracy: 0.9643 - val_loss: 0.4049\n",
      "Epoch 61/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0423 - val_accuracy: 0.9643 - val_loss: 0.4013\n",
      "Epoch 62/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0310 - val_accuracy: 0.9643 - val_loss: 0.4013\n",
      "Epoch 63/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0311 - val_accuracy: 0.9643 - val_loss: 0.4003\n",
      "Epoch 64/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0289 - val_accuracy: 0.9643 - val_loss: 0.4008\n",
      "Epoch 65/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0272 - val_accuracy: 0.9643 - val_loss: 0.3963\n",
      "Epoch 66/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0369 - val_accuracy: 0.9643 - val_loss: 0.3996\n",
      "Epoch 67/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0289 - val_accuracy: 0.9643 - val_loss: 0.3973\n",
      "Epoch 68/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0274 - val_accuracy: 0.9643 - val_loss: 0.3983\n",
      "Epoch 69/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0300 - val_accuracy: 0.9643 - val_loss: 0.3955\n",
      "Epoch 70/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0258 - val_accuracy: 0.9643 - val_loss: 0.3957\n",
      "Epoch 71/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0281 - val_accuracy: 0.9643 - val_loss: 0.3931\n",
      "Epoch 72/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0275 - val_accuracy: 0.9643 - val_loss: 0.3950\n",
      "Epoch 73/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0251 - val_accuracy: 0.9643 - val_loss: 0.3917\n",
      "Epoch 74/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0280 - val_accuracy: 0.9643 - val_loss: 0.3934\n",
      "Epoch 75/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0261 - val_accuracy: 0.9643 - val_loss: 0.3922\n",
      "Epoch 76/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0246 - val_accuracy: 0.9643 - val_loss: 0.3928\n",
      "Epoch 77/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0206 - val_accuracy: 0.9643 - val_loss: 0.3935\n",
      "Epoch 78/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0235 - val_accuracy: 0.9643 - val_loss: 0.3906\n",
      "Epoch 79/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.9643 - val_loss: 0.3905\n",
      "Epoch 80/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0218 - val_accuracy: 0.9643 - val_loss: 0.3907\n",
      "Epoch 81/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0243 - val_accuracy: 0.9643 - val_loss: 0.3885\n",
      "Epoch 82/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0191 - val_accuracy: 0.9643 - val_loss: 0.3895\n",
      "Epoch 83/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0178 - val_accuracy: 0.9643 - val_loss: 0.3874\n",
      "Epoch 84/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9694 - val_loss: 0.3919\n",
      "Epoch 85/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.9643 - val_loss: 0.3880\n",
      "Epoch 86/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.9643 - val_loss: 0.3893\n",
      "Epoch 87/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.9745 - val_loss: 0.3882\n",
      "Epoch 88/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0203 - val_accuracy: 0.9745 - val_loss: 0.3863\n",
      "Epoch 89/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.9745 - val_loss: 0.3877\n",
      "Epoch 90/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.9745 - val_loss: 0.3879\n",
      "Epoch 91/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.9745 - val_loss: 0.3872\n",
      "Epoch 92/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9745 - val_loss: 0.3875\n",
      "Epoch 93/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9745 - val_loss: 0.3866\n",
      "Epoch 94/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.9745 - val_loss: 0.3865\n",
      "Epoch 95/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.9745 - val_loss: 0.3872\n",
      "Epoch 96/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9745 - val_loss: 0.3868\n",
      "Epoch 97/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9745 - val_loss: 0.3855\n",
      "Epoch 98/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9745 - val_loss: 0.3856\n",
      "Epoch 99/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9745 - val_loss: 0.3863\n",
      "Epoch 100/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9745 - val_loss: 0.3858\n",
      "Epoch 101/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9745 - val_loss: 0.3857\n",
      "Epoch 102/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.9745 - val_loss: 0.3848\n",
      "Epoch 103/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.9694 - val_loss: 0.3852\n",
      "Epoch 104/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9745 - val_loss: 0.3851\n",
      "Epoch 105/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9745 - val_loss: 0.3860\n",
      "Epoch 106/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.9745 - val_loss: 0.3830\n",
      "Epoch 107/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.9745 - val_loss: 0.3844\n",
      "Epoch 108/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9745 - val_loss: 0.3841\n",
      "Epoch 109/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9745 - val_loss: 0.3842\n",
      "Epoch 110/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9745 - val_loss: 0.3840\n",
      "Epoch 111/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9745 - val_loss: 0.3843\n",
      "Epoch 112/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9745 - val_loss: 0.3843\n",
      "Epoch 113/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9745 - val_loss: 0.3846\n",
      "Epoch 114/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9745 - val_loss: 0.3839\n",
      "Epoch 115/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9745 - val_loss: 0.3844\n",
      "Epoch 116/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9745 - val_loss: 0.3849\n"
     ]
    }
   ],
   "source": [
    "if N_val > 0:\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    base_model_dnn.fit(X_scaled_train, y_train,\n",
    "                       validation_data=(X_scaled_val, y_val),\n",
    "                       epochs=10000, batch_size=min(32, max(8, len(X_scaled_train) // 2)),\n",
    "                       callbacks=[early_stop])\n",
    "else:\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "    base_model_dnn.fit(X_scaled_train, y_train,\n",
    "                       epochs=10000, batch_size=min(32, max(8, len(X_scaled_train) // 2)),\n",
    "                       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練時間：13.87 秒\n"
     ]
    }
   ],
   "source": [
    "training_time = end_time - start_time\n",
    "print(f\"訓練時間：{training_time:.2f} 秒\")\n",
    "ALL_trainingtime.append(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.9665 - loss: 0.2579\n",
      "Evaluation on 90% unused data - Loss: 0.2349, Accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "loss, accuracy = base_model_dnn.evaluate(X_scaled_test, y_test)\n",
    "print(f\"Evaluation on 90% unused data - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "ALL_loss.append(loss)\n",
    "ALL_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data MDE report saved to: AP1 AP4 best (MDE_0.0107Accuracy_0.9917 )/regressor_DNN AP1&AP4s BEST_20data_2024_12_21.json\n",
      "\n",
      "Test Data Mean MDE: 0.0547 meters\n"
     ]
    }
   ],
   "source": [
    "# MDE\n",
    "# 預測測試資料\n",
    "y_test_pred_numeric = base_model_dnn.predict(X_scaled_test)\n",
    "y_pred_classes = np.argmax(y_test_pred_numeric, axis=1)\n",
    "\n",
    "# 轉換為原本的 Label\n",
    "y_test_pred_labels = [label_mapping[str(num + 1)] for num in y_pred_classes]  # 補回 +1\n",
    "\n",
    "# 讀取測試資料的實際 Label\n",
    "y_test_actual = [label_mapping[str(num + 1)] for num in y_test]  # 補回 +1\n",
    "\n",
    "# 取得預測與實際座標\n",
    "y_test_pred_coordinates = np.array([label_to_coordinates[label] for label in y_test_pred_labels])\n",
    "y_test_actual_coordinates = np.array([label_to_coordinates[label] for label in y_test_actual])\n",
    "\n",
    "# 計算 MDE (Mean Distance Error)\n",
    "distances = np.linalg.norm(y_test_pred_coordinates - y_test_actual_coordinates, axis=1)\n",
    "mean_mde = np.mean(distances)\n",
    "\n",
    "# 記錄每個 RP 的 MDE\n",
    "mde_report_test = {}\n",
    "for true_label, distance in zip(y_test_actual, distances):\n",
    "    if true_label not in mde_report_test:\n",
    "        mde_report_test[true_label] = []\n",
    "    mde_report_test[true_label].append(distance)\n",
    "\n",
    "# 計算測試資料的 MDE 平均值\n",
    "mde_report_test_avg = {label: {\"mde\": np.mean(dists), \"count\": len(dists)} for label, dists in mde_report_test.items()}\n",
    "\n",
    "# 儲存 MDE 結果到 JSON 檔案\n",
    "test_file_path = f\"{root}/{modelname}.json\"\n",
    "with open(test_file_path, \"w\") as f:\n",
    "    json.dump(mde_report_test_avg, f, indent=4)\n",
    "\n",
    "# Needsave\n",
    "print(f\"Test Data MDE report saved to: {test_file_path}\")\n",
    "print(f\"\\nTest Data Mean MDE: {mean_mde:.4f} meters\")\n",
    "ALL_mean_mde.append(mean_mde)\n",
    "\n",
    "\n",
    "base_model_dnn.save(f'{root}/regressor_dnn_{ap}_best_{weekrepresent[0][0]}week_to_{weekrepresent[0][1]}week_{dataamount}dataPerRP.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
